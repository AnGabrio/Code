---
title: "Conducting trial-based cost-effectiveness analyses:"
subtitle: "A tutorial"
format: 
  beamer: 
    navigation: horizontal
    theme: Boadilla
    colortheme: whale
#highlight-style: monochrome
code-block-bg: '#FFFFFF'
code-block-border-left: '#FFFFFF'
code-line-numbers: false
keep-tex: false
toc: true
author: 
  - \textbf{Andrea Gabrio}\newline\newline
  - \small Department of Methodology and Statistics, FHML (UM)
institute: 
  - \scriptsize \olive \href{https://www.maastrichtuniversity.nl/gabrio}{\texttt{a.gabrio@maastrichtuniversity.nl}}
  - \href{https://github.com/AnGabrio}{\texttt{https://github.com/AnGabrio}}
  - \href{https://angabrio.github.io}{\texttt{https://angabrio.github.io}}
#date-format: full
#date: 21 October 2025
#top-level-division: part
bibliography: references_HSR2025.bib
csl: apa.csl
nocite: |
  @*
header-includes: 
- \logo{\ifnum\thepage>1\includegraphics[height=.47cm]{UM_logo.png}\fi}
- \titlegraphic{\centering\vspace*{-0.8cm}\hspace*{1.5cm}\includegraphics[height=1cm]{UM_logo.jpg}\;\;\; \includegraphics[height=1cm]{mu_sigma.jpg}\newline\newline \scriptsize HSR department seminar, 25 Oct 2025 - Maastricht}
- \newcommand\hideit[1]{\only<0| handout:1>{\mbox{}}\invisible<0| handout:1>{#1}}
- \usefonttheme[onlymath]{serif}
- \setbeamertemplate{itemize item}{$\bullet$} 
- \setbeamertemplate{itemize subitem}{--} 
- \setbeamertemplate{navigation symbols}{}
- \setbeamertemplate{page number in head/foot}{}
- \newcommand{\UM}{\logo{\includegraphics[height=.37cm]{UM_logo.png}}\setbeamertemplate{sidebar right}{\vfill\llap{\insertlogo\hskip0.0cm}\vskip0.015cm}}\newcommand{\nologo}{\logo{}}
- \makeatother\setbeamertemplate{footline}{
  \leavevmode
  \hbox{
  \begin{beamercolorbox}[wd=.2\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}
    \usebeamerfont{author in head/foot}A. Gabrio (UM)
  \end{beamercolorbox}
  \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}
    Conducting CEA \hspace*{1ex}
  \end{beamercolorbox}
  \begin{beamercolorbox}[wd=.5\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}
    HSR seminar, 21 Oct 2025 \hspace*{1ex}
  \end{beamercolorbox}}
  \vskip0pt}\makeatletter
- \setbeamertemplate{navigation symbols}{}
- \definecolor{darkgreen}{rgb}{0.0,0.2,0.13}
- \definecolor{yellowgreen}{rgb}{0.6,0.8,0.2}
- \definecolor{myred}{rgb}{0.9 0.17 0.31}
- \definecolor{myblue}{rgb}{0.14 0.34 0.55}
- \definecolor{mypurple}{rgb}{0.53 0.0 0.69}
- \definecolor{olive}{rgb}{.2 .31 .09}
- \definecolor{orange}{rgb}{1 0.5 0}
- \definecolor{mygrey}{rgb}{.94 .94 .94}
- \definecolor{amber}{rgb}{1.0, 0.75, 0.0}
- \definecolor{spanishred}{RGB}{198 11 30}
- \definecolor{spanishyellow}{RGB}{255 196 0}
- \definecolor{nedred}{RGB}{200 16 46}
- \definecolor{nedwhite}{RGB}{255 255 255}
- \definecolor{nedblue}{RGB}{0 61 165}
- \newcommand\myred{\color{myred}}
- \newcommand\myblue{\color{myblue}}
- \newcommand\mypurple{\color{mypurple}}
- \newcommand\olive{\color{olive}}
- \newcommand\orange{\color{orange}}
- \newcommand\mygrey{\color{mygrey}}
- \newcommand\amber{\color{amber}}
- \newcommand\red{\color{red}}
- \newcommand\blue{\color{blue}}
- \newcommand\black{\color{black}}
- \newcommand\white{\color{white}}
- \newcommand\magenta{\color{magenta}}
- \usepackage{etex}
- \usepackage{graphicx,hyperref,epsfig,bm,xspace}
- \usepackage{xcolor}
- \usepackage{tikz,verbatim,listings}
- \usetikzlibrary{shapes,arrows,decorations.pathreplacing,positioning,calc}
- \lstset{basicstyle=\ttfamily\fontsize{6}{7}\selectfont\textcolor[rgb]{0.345,0.345,0.345},breaklines=true,tabsize=2,keywords={},linewidth=1\textwidth,backgroundcolor=\color{black!5},moredelim=[is][\color{red}]{~_}{~_},moredelim=[is][\textbf]{**}{**},moredelim=[is][\color{blue}]{*!}{*!},moredelim=[is][\color{green!60!black!80}]{'+}{'+},moredelim=[is][\color{red}]{_+}{_+},moredelim=[is][\color{green}]{'_}{'_}}
- \usepackage[position=top]{subfig}
- \usepackage{multirow}
- \usepackage{booktabs}
- \usepackage{bigdelim}
- \usepackage{longtable}
- \usepackage{makecell}
- \usepackage{siunitx}
- \usepackage{hyperref}
- \usepackage{graphicx}
- \usepackage{multirow}
- \usepackage{amsmath,amssymb}
- \usepackage{hyperref}
- \usepackage[capitalise,noabbrev]{cleveref}
---

```{r, include=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
library(knitr)
opts_chunk$set(prompt = TRUE, highlight = F, background = '#FFFFFF')
```


# Introduction \& Modelling in HTA

```{r, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
#library(missingHE)
library(tidyverse)
library(kableExtra)
```

## Something about me

- Phd in Statistics \@UCL (University College London) with thesis on stat methods to handle missing data in HTA

. . .

- Experience as trial stat/health economist \@PRIMENT CTU (UCL) 

. . .

- Collaborated on methodological/applied HTA projects with collegaues in both UK and NL 

  + \scriptsize Prof. Baio, Gomes, Leurent (Stat Sci \@UCL) \& Prof. Manca (Centre for HE \@York)
  + \scriptsize Prof. Evers, Hiligsmann, Mastrigt (HSR \@UM) \& Prof. Joore (\@KEMTA)
  + \scriptsize Prof. Bosmans (Health Sciences \@VU) \& El Alili (\@ZIN)

. . .

- \myblue \textbf{Personal goal} \black to facilitate uptake of methods in HTA via software:

  + I am a bit of a \myblue \texttt{R} \black enthusiast
  + I am a bit of a \myred \texttt{Excel} \black hater (for statistical analyses)

## Disclaimer ...

Before I begin:

```{=latex}
\begin{itemize}
\setlength\itemsep{1em}
\item \textbf{\olive Statistics} is an all-encompassing discipline: \textit{Statisticians are unified not by the subject matter they work in, but the methodology used to address problems that arise in diverse fields}
\pause
\item The \textbf{\olive success} of Statistics relies on developing skills to make it easier for colleagues in other disciplines to appreciate our contribution
\pause
\item My \textbf{\myblue personal} view of the world: \begin{quote}Statisticians should be in charge of everything.\end{quote}
\pause
\item So I probably will be very annoying throughout the presentation\footnote<.(1)->{But luckily no non-Statistician has been harmed in the making of these slides}
\end{itemize}
```

## Health technology assessment (HTA)

- \textbf{Objective}: Combine \red costs \black \& \blue benefits \black of a given intervention into a rational scheme for allocating resources

```{=latex}
\begin{tikzpicture}%[->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin]

\onslide<2->{\draw(-5,-1) node[align=center,rectangle,rounded corners=2ex,draw,fill=red,font=\sffamily\fontsize{9}{10}\selectfont,minimum width=2.2cm,minimum height=1cm](1){Statistical\\ model};
}
\onslide<3->{
\draw(0,-1) node[align=center,rectangle,rounded corners=2ex,draw,fill=gray,font=\sffamily\fontsize{9}{10}\selectfont,minimum width=2.2cm,minimum height=1cm](2){Economic\\ model};
}
\onslide<4->{
\draw(4,-1) node[align=center,rectangle,rounded corners=2ex,draw,fill=orange,font=\sffamily\fontsize{9}{10}\selectfont,minimum width=2.2cm,minimum height=1cm](3){Decision\\ analysis};
}
\onslide<5->{
\draw(-2.5,2) node[align=center,rectangle,rounded corners=2ex,draw,fill=blue!40,font=\sffamily\fontsize{9}{10}\selectfont,minimum width=2.2cm,minimum height=1cm](4){Uncertainty\\ analysis};
}
\onslide<2->{
\draw(-5.2,-2.7) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\tiny,text width=3cm](5){
\begin{itemize}
\item Estimates relevant parameters $\theta$
\item Varies with the type of data (\& statistical approach!)
\end{itemize}
};
}
\onslide<3->{
\draw(-0.2,-2.65) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\tiny,text width=3.5cm](6){
\begin{itemize}
\item Combines parameters to obtain average measure for costs and effects
\item Varies with the type of data \& statistical model used
\end{itemize}
};
}
\onslide<4->{
\draw(3.8,-2.8) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\tiny,text width=3.4cm](7){
\begin{itemize}
\item Computes suitable measures of ``cost-effectiveness''
\item Dictates the best course of actions
\item Standardised process
\end{itemize}
};
}
\onslide<5->{
\draw(0.7,2.05) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\tiny,text width=4.1cm](8){
\begin{itemize}
\item Assesses the impact of uncertainty on the results
\item Mandatory in many jurisdictions (e.g. ZIN in NL)
\end{itemize}
};
}
\onslide<5->{
\draw [dashed,->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (1.40) -- (4.220);
\draw [dashed,->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (4.320) -- (2.140);
}
\onslide<3->{
\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (1.east) -- (2.west);
}
\onslide<4->{
\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (2.east) -- (3.west);
}

\onslide<3->{
\draw(0.4,.15) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\tiny,text width=3.5cm](func1){
\begin{itemize}
\item[] $\myblue \Delta_e=f_e(\theta)$
\item[] $\myblue \Delta_c=f_c(\theta)$
\item[] $\white \ldots$
\end{itemize}
};
}

\onslide<4->{
\draw(4.1,.15) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\tiny,text width=3.5cm](func2){
\begin{itemize}
\item[] $\myblue \mbox{ICER}=g(\Delta_e,\Delta_c)$
\item[] $\myblue \mbox{INB}=h(\Delta_e,\Delta_c;k)$
\item[] $\myblue \qquad \qquad \ldots$
\end{itemize}
};
}
\end{tikzpicture}
```


## Statistical modelling for model-based analyses

```{=latex}
\begin{enumerate}
\item \small Build a \textbf{\olive population level model} (eg decision tree/Markov model)
\scalebox{.6}{
\begin{tikzpicture}
\draw(-6,1) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}
{8}\selectfont](1){Prophylactic NIs?};

\draw(-3,-1) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}{9}\selectfont](2){No};

\draw(-3,3) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}{9}\selectfont](3){Yes};

\draw(0,4) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}{9}\selectfont](4){Yes \\$(p_1)$};

\draw(0,2) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}{9}\selectfont](5){No \\$(1-p_1)$};

\draw(3,4) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}{9}\selectfont](6){Cost with NIs + cost influenza};

\draw(3,2) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}{9}\selectfont](7){Cost with NIs};

\draw(0,0) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}{9}\selectfont](8){Yes \\$(p_0)$};

\draw(0,-2) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}{9}\selectfont](9){No \\$(1-p_0)$};

\draw(3,0) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}{9}\selectfont](10){Cost influenza};

\draw(3,-2) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}{9}\selectfont](11){Cost with no NIs};

\draw(3,4.8) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{8}{9}\selectfont](12){\underline{Outcomes}};

\node [rectangle,minimum size=1.5mm,inner sep=0pt,outer sep=3pt,fill=black] at (-4.75,1) (dec1){};
\node [circle,minimum size=1.5mm,inner sep=0pt,outer sep=3pt,fill=black] at (-2.65,3) (rand2){};
\node [circle,minimum size=1.5mm,inner sep=0pt,outer sep=3pt,fill=black] at (-2.68,-1) (rand3){};

\draw(-10.7,0) node[align=left,draw=none,font=\fontsize{8}{9}\selectfont,color=myblue](13){$\mu_{e1}=-lp_1$};
\draw(-10.7,-.5) node[align=left,draw=none,font=\fontsize{8}{9}\selectfont,color=myblue](14){$\mu_{e0}=-lp_0$};
\draw(-9.1,-1) node[align=left,draw=none,font=\fontsize{8}{9}\selectfont,color=myblue](15){$\mu_{c1}=\left(c^{\rm{\it NI}}+c^{\rm{\it Inf}}\right)p_1 + c^{\rm{\it NI}}(1-p_1)$};
\draw(-9.1,-1.5) node[align=left,draw=none,font=\fontsize{8}{9}\selectfont,color=myblue](16){$\mu_{c0}=\left(c^{\rm{\it NI}}+c^{\rm{\it Inf}}\right)p_0 + c^{\rm{\it NI}}(1-p_0)$};

\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (1.east) |- (2.west);
\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (1.east) |- (3.west);
\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (3.east) |- (4.west);
\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (3.east) |- (5.west);
\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (2.east) |- (8.west);
\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (2.east) |- (9.west);
\end{tikzpicture}
}

\small \textbf{NB}: ``data'' are represented by summary statistics for  $\myblue \theta=(p_0,p_1,l,\ldots)$
\pause\vspace{5pt}
\item Use point estimates for the parameters to build the ``base-case'' (average) evaluation
\pause\vspace{-5pt}
\item Use resampling methods (eg bootstrap) to propage uncertainty in the point estimates and perform uncertainty analysis
\end{enumerate}
```

## Statistical modelling for empirical analyses 

```{=latex}
\begin{center}
\hspace{-1cm}
\scalebox{.5}{
\centering
\begin{tabular}{ccccccccccccccccc}
\hline\\[-7pt]
 & & \multicolumn{3}{c}{\orange \textbf{Demographics}} & \multicolumn{4}{c}{\blue \textbf{HRQL data}} & \multicolumn{4}{c}{\red \textbf{Resource use data}} &  \multicolumn{4}{c}{\olive \textbf{Clinical outcome}} \\
\textbf{ID} & \textbf{Trt} & \orange Sex & \orange Age & $\orange \ldots$ & \blue $u_0$ & \blue $u_1$ & $\blue \ldots$ & $\blue u_J$ & $\red c_0$ & $\red c_1$ & \red\ldots & $\red c_J$ & $\olive y_0$ & $\olive y_1$ & \olive\ldots & $\olive y_J$\\[2pt]
\hline\\[-7pt]
1 & 1 & \orange M & \orange 23 & $\orange \ldots$ & \blue 0.32 & \blue 0.66 & $\blue \ldots$ & \blue 0.44 & \red 103 & \red 241 & \red\ldots & \red 80 & \olive $y_{10}$ & \olive $y_{11}$ & \olive\ldots & \olive $y_{1J}$ \\
2 & 1 & \orange M & \orange 21 & $\orange \ldots$ & \blue 0.12 & \blue 0.16 & $\blue \ldots$ & \blue 0.38 & \red 1\,204 & \red 1\,808 & \red\ldots & \red 877 & \olive $y_{20}$ & \olive $y_{21}$ & \olive\ldots & \olive $y_{2J}$ \\
3 & 2 & \orange F & \orange 19 & $\orange \ldots$ & \blue 0.49 & \blue 0.55 & $\blue \ldots$ & \blue 0.88 & \red 16 & \red 12 & \red\ldots & \red 22 & \olive $y_{30}$ & \olive $y_{31}$ & \olive\ldots & \olive $y_{3J}$\\
$\ldots$ & $\ldots$ & $\orange \ldots$ & $\orange \ldots$ & $\orange \ldots$ & $\blue \ldots$ & $\blue \ldots$ & $\blue \ldots$ & $\blue \ldots$ & $\red \ldots$ & $\red\ldots$ & $\red\ldots$ & \red\ldots & \olive\ldots & \olive\ldots & \olive\ldots & \olive\ldots \\
\hline\\[-7pt]
\multicolumn{17}{l}{$\olive y_{ij} =$ Survival time, event indicator (eg CVD), number of events, continuous measurement (eg blood pressure), \ldots}\\
\multicolumn{17}{l}{$\blue u_{ij} =$  Utility-based score to value health (eg EQ-5D, SF-36, Hospital Anxiety \& Depression Scale, \ldots)}\\
\multicolumn{17}{l}{$\red c_{ij} =$  Use of resources (drugs, hospital, GP appointments, \ldots)}
\end{tabular}}
\end{center}
\vspace{-5pt}
\begin{enumerate}
\item<2-> \small Compute \blue QALYs \black and \red total costs \black as \myblue 
$$\hspace{-0cm} e_i = \displaystyle\sum_{j=1}^{J} \left(u_{ij}+u_{i\hspace{.5pt}j-1}\right) \frac{\delta_{j}}{2} \quad \mbox{\black and} \quad c_i = \sum_{j=1}^J c_{ij}\black, \qquad {\scalebox{.8}{$\left[\mbox{with: }\myblue \displaystyle\delta_j=\frac{\mbox{Time}_j-\mbox{Time}_{j-1}}{\mbox{Unit of time}}\black\right]$}}$$ 
%%
\only<2|handout:1>{
\begin{tikzpicture}
\node[draw, white] at (-0.5, -2.7) {\includegraphics[scale=.27]{figure/QALYs}};
\draw [decorate, decoration={brace, amplitude=6pt, raise=.3pt},color=olive, xshift=1.4cm,yshift=-1cm] (0,-.44) -- (.96,-.44) node [olive, midway, sloped, above=0.18cm, xshift=0cm,yshift=0cm] {\fontsize{5}{6}\selectfont $\delta_j$};
\draw [decorate, decoration={brace, amplitude=4pt, raise=.3pt},color=orange, xshift=1.4cm,yshift=-1cm] (.965,-.44) -- (.965,-1.03) node [orange, midway, sloped, above=1,right=-0.04cm,rotate=90, xshift=0cm,yshift=0cm] {\fontsize{5}{6}\selectfont $\frac{u_{ij}+u_{i\hspace{.5pt}j-1}}{2}$};
\draw(4,.6) node[align=left,draw=none,font=\sffamily\fontsize{7}{8}\selectfont, , xshift=1.4cm,yshift=-1cm](1){$\mbox{QALY}_{i}=\mbox{``Area under the curve''}$};
\end{tikzpicture}
}
%%
\black \vspace{-5pt}
\item<3-|handout:2> \small (Often implicitly) assume normality and linearity and model \textbf{\olive independently} individual QALYs and total costs by controlling for baseline~values \myblue
\begin{eqnarray*}
e_i & = & \alpha_{e0} + \alpha_{e1} u_{0i} + \alpha_{e2} \mbox{Trt}_i + \varepsilon_{ei}\, [+ \ldots], \qquad \varepsilon_{ei} \sim \mbox{Normal}(0,\sigma_e) \\
c_i & = & \alpha_{c0} + \alpha_{c1} c_{0i} + \alpha_{c2} \mbox{Trt}_i + \varepsilon_{ci}\, [+ \ldots], \qquad\hspace{2pt} \varepsilon_{ci} \sim \mbox{Normal}(0,\sigma_c) 
\end{eqnarray*} \black  \vspace{-10pt}
\item<4|handout:2> \small Estimate population average cost and effectiveness differentials and use \olive \textbf{bootstrap} \black to quantify uncertainty
\end{enumerate}
```

## ``Two-stage" approach to HTA

```{=latex}
\hspace{-0.9cm}
\begin{tikzpicture}%[->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin]
\hspace{-.5cm}
\onslide<1->{\draw(-5,-1) node[align=center,rectangle,rounded corners=2ex,draw,fill=red,font=\sffamily\fontsize{9}{10}\selectfont,minimum width=2.2cm,minimum height=1cm](1){Statistical\\ model};
}
\onslide<1->{

\draw(0.5,-1) node[align=center,rectangle,rounded corners=2ex,draw,fill=gray,font=\sffamily\fontsize{9}{10}\selectfont,minimum width=2.2cm,minimum height=1cm](2){Economic\\ model};
}
\onslide<1->{
\draw(4,-1) node[align=center,rectangle,rounded corners=2ex,draw,fill=orange,font=\sffamily\fontsize{9}{10}\selectfont,minimum width=2.2cm,minimum height=1cm](3){Decision\\ analysis};
}
\onslide<1->{
\draw(-5,2) node[align=center,rectangle,rounded corners=2ex,draw,fill=blue!40,font=\sffamily\fontsize{9}{10}\selectfont,minimum width=2.2cm,minimum height=1cm](4){Uncertainty\\ analysis};
}
\onslide<1->{
\draw(-5.2,-2.75) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\tiny,text width=3cm](5){
\begin{itemize}
\item Estimates relevant parameters $\theta$
\item Varies with the type of data (\& statistical approach!)
\end{itemize}
};
}
\onslide<1->{
\draw(0.3,-2.7) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\tiny,text width=3.5cm](6){
\begin{itemize}
\item Combines the parameters to obtain a population average measure for costs and effects
\item Varies with the type of data \& statistical model used
\end{itemize}
};
}
\onslide<1->{
\draw(3.8,-2.85) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\tiny,text width=3.5cm](7){
\begin{itemize}
\item Computes suitable measures of ``cost-effectiveness''
\item Dictates the best course of actions
\item Standardised process
\end{itemize}
};
}
\onslide<1->{
\draw(-2.15,2.05) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\tiny,text width=3.7cm](8){
\begin{itemize}
\item Assesses the impact of uncertainty on the results
\item Mandatory in many jurisdictions (eg ZIN)
\end{itemize}
};
}
\onslide<1->{
\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,thin] (1.north) -- (4.south);
}
\onslide<1->{
%\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (1.east) -- (2.west);
}
\onslide<1->{
\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (2.east) -- (3.west);
}

\onslide<1->{
\draw(1.0,3.5) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{6}{7}\selectfont]{\olive 1.\ Estimation (base-case)};
%\draw(4.3,3.5) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{6}{7}\selectfont]{\olive 2.\ Probabilistic sensitivity analysis};
\draw(1.8,3) node[align=center,draw,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{6}{7}\selectfont](9){$\theta$};
\draw(1.8,1) node[align=center,circle,draw,fill=none,font=\sffamily\fontsize{6}{7}\selectfont](10){$y$};
\draw(.5,1) node[align=center,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{6}{7}\selectfont](11){$p(y\mid \theta)$};
\draw(.5,3) node[align=center,draw,ellipse,double,fill=none,minimum width=.3cm,minimum height=.25cm,font=\sffamily\fontsize{6}{7}\selectfont](12){$\hat\theta=f(Y)$};

\onslide<2>{
\draw(-3.5,-4.0) node[align=center,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{5}{6}\selectfont](){\textit{``Two-stage approach'' (Spiegelhalter, Abrams \& Myles, 2004)}};
}


\draw [->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (9.south) -- (10.north);
\draw [dashed,->,>=latex,shorten >=0pt,auto,node distance=3cm,ultra thin] (11.north) -- (12.south);
\draw [dashed,->,>=latex,shorten >=0pt,auto,node distance=3cm,thin,red!60] (12.220) to [out=220,in=130] (2.120);
}

\onslide<2>{
\draw(4.3,3.5) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{6}{7}\selectfont]{\olive 2.\ Probabilistic sensitivity analysis};
\draw(2.9,2.0) node[align=center,draw=none,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{6}{7}\selectfont,color=red]{$\Rightarrow$};
\draw(5.4,3) node[align=center,circle,draw,fill=none,font=\sffamily\fontsize{6}{7}\selectfont](13){$\theta$};
\draw(4.2,3) node[align=center,fill=none,minimum width=.5cm,minimum height=.5cm,font=\sffamily\fontsize{6}{7}\selectfont](14){$p(\theta)\red\leftrightsquigarrow\black g(\hat\theta)$};
\draw [dashed,->,>=latex,shorten >=0pt,auto,node distance=3cm,thin,blue!40] (13.south) to [out=270,in=45] (2.60);
}
\end{tikzpicture}
```

## Decision + Uncertainty* analysis 

```{=latex}
\vspace{7cm}
\begin{tikzpicture}[remember picture,overlay]
\only<1-2|handout:1-2>{
\draw(0,4) node[align=center,rectangle,rounded corners,draw=none,text width=4.1cm, xshift=5cm,yshift=3.5cm](1){\fontsize{8}{8}\selectfont Cost-effectiveness plane};
}

\only<1|handout:1>{
\node{\includegraphics[scale=.55]{figure/CEPlane_ICER}};
}
\only<1-2>{
\draw(3.5,-.1) node[align=center,rectangle,rounded corners,draw=none,text width=4.1cm,xshift=3.6cm,yshift=3.4cm](8){\fontsize{8}{8}\selectfont $\Delta_e$};
\draw(-.9,3.2) node[align=center,rectangle,rounded corners,draw=none,text width=4.1cm,xshift=3.6cm,yshift=3.4cm](8){\fontsize{8}{8}\selectfont $\Delta_c$};
}

\only<1|handout:1>{
\draw(4.5,3.5) node[align=center,rectangle,rounded corners,draw=none,text width=4.1cm,xshift=4.5cm,yshift=3.5cm](8){\fontsize{7}{8}\selectfont $\myblue \Delta_e=\color{red} \underbrace{\myblue\mbox{E}[e \mid \hat{\theta}_1]}_{\hat\mu_{e1}} \myblue - \color{red} \underbrace{\myblue\mbox{E}[e \mid \hat{\theta}_0]}_{\hat\mu_{e0}}$};
\draw(4.5,2.6) node[align=center,rectangle,rounded corners,draw=none,text width=4.1cm,xshift=4.5cm,yshift=3.5cm](8){\fontsize{7}{8}\selectfont $\myblue \Delta_c=\color{red} \underbrace{\myblue\mbox{E}[c \mid \hat{\theta}_1]}_{\hat\mu_{c1}} \myblue - \color{red} \underbrace{\myblue\mbox{E}[c \mid \hat{\theta}_0]}_{\hat\mu_{c0}}$};
\draw(2.0,1.5) node[align=center,rectangle,rounded corners,draw=none,text width=6.0cm,xshift=4cm,yshift=3.5cm](8){\fontsize{8}{8}\selectfont 
\begin{eqnarray*}
\mbox{ICER}&\!\!\!\!=\!\!\!\!&\frac{\mbox{E$[\Delta_c]$}}{\mbox{E$[\Delta_e]$}}=\frac{\hat\mu_{c1}-\hat\mu_{c0}}{\hat\mu_{e1}-\hat\mu_{e0}} \\
&\!\!\!\!=\!\!\!\!&\mbox{Cost per outcome}\end{eqnarray*}};
}

\only<2|handout:2>{
\node{\includegraphics[scale=.55]{figure/CEPlane_empty}};
\draw(4.5,3.5) node[align=center,rectangle,rounded corners,draw=none,text width=4.1cm,xshift=4.5cm,yshift=3.5cm](8){\fontsize{7}{8}\selectfont $\myblue \Delta_e=\red\underbrace{\myblue\mbox{E}[e \mid \theta_1]}_{\mu_{e1}} \myblue - \red\underbrace{\myblue\mbox{E}[e \mid \theta_0]}_{\mu_{e0}}$};
\draw(4.5,2.6) node[align=center,rectangle,rounded corners,draw=none,text width=4.1cm,xshift=4.5cm,yshift=3.5cm](8){\fontsize{7}{8}\selectfont $\myblue \Delta_c=\red\underbrace{\myblue\mbox{E}[c \mid \theta_1]}_{\mu_{c1}} \myblue - \red\underbrace{\myblue\mbox{E}[c \mid \theta_0]}_{\mu_{c0}}$};
\draw(.08,1.42) node[align=center,rectangle,rounded corners,draw=none,text width=4.1cm,xshift=3.7cm,yshift=3.5cm](8){\fontsize{5}{6}\selectfont $\red \bullet$};
\draw(-4.5,-2.6) node[align=center,rectangle,rounded corners,draw=none,text width=4.1cm,xshift=6cm,yshift=3.5cm](8){\fontsize{7}{8}\selectfont $^*$Induced by $\myblue g(\hat{\theta}_0), g(\hat{\theta}_1)$};
}
\end{tikzpicture}
```

# Zorginstituut Nederland (ZIN) 2024 guidelines

## ZIN 2024 guidelines: summary

```{=latex}
\begin{itemize}
\item Cost-effectiveness in the Netherlands has become more and more important in reimbursement decisions of the \textit{National Health Care Institute} over the years
\item \olive \textbf{Standardise} \black analyses to improve comparability and enhance quality
\item Revision of elements for the ``\myblue\textbf{Reference Case}\black" to which all economic evaluations \textit{have to comply with}
\pause
\begin{enumerate}
\item \black \textbf{Perspective} \black of the analysis
\only<2>{
\begin{itemize}
\item[-] Default: \myblue \textbf{Societal} \black - \textit{all societal costs and benefits irrespective of who are the beneficiaries/payers} 
\item[-] Alternative perspectives may be presented as \orange \textbf{scenario analyses}
\end{itemize}
}
\pause
\item \black \textbf{PICOTS} \black criteria
\only<3>{
\begin{itemize}
\item[-] Patient, Intervention, Comparison \& Setting: \olive \textbf{Dutch practice} \black - \textit{relevant to current clinical practice at the time} 
\item[-] Outcomes: \myred \textbf{Costs} \black (healthcare, P\&F, other sectors) \& \myblue \textbf{QALYs} \black (EQ-5D-5L)
\item[-] Time horizon: \orange \textbf{lifelong} \black (if possible) 
\end{itemize}
}
\pause
\item \black \textbf{Type} \black of evaluation
\only<4>{
\begin{itemize}
\item[-] Default: \myblue \textbf{CUA} \black - \textit{allows comparison across populations and inteventions} 
\item[-] A \orange \textbf{CEA} \black may also be conducted in addition 
\end{itemize}
}
\pause
\item \black \textbf{Data} \black (effectiveness, costs and QoL)
\only<5>{
\begin{itemize}
\item[-] Litertaure data assessed via \orange \textbf{systematic literature review} \black 
\item[-] Costs $=$ volume (unit) $\times$ price (per unit) --> \myred \textbf{Costing Manual}\black
\item[-] QoL as ``utilities" via EQ-5D-5L  --> \myblue \textbf{QALY and QoL Manual}\black
\end{itemize}
}
\pause
\item \myred \textbf{Methods}\black
\only<6>{
\begin{itemize}
\item[-] MB: Discount, Extrapolation, Subgroup, Uncertainty, Validation
\item[-] \myred \textbf{EMP}\black: \myred Missingness, Adjustment, Uncertainty
\end{itemize}
}
\pause
\item \myred \textbf{Reporting} \black
\only<7>{
\begin{itemize}
\item[-] \myred \textbf{Data}\black, \myred \textbf{Methods}\black, \myred \textbf{Results}\black
\end{itemize}
}
\end{enumerate}
\end{itemize}
```

## Analysis Methods in HTA

- **Study Design**:

  + \myred \textbf{Empirical} \black - *costs \& effects at patient level from a controlled study*
  + Model-based - *expected costs \& effects estimated via simulation*

. . .

- **Choice of methods** depends on the study design:

  + Account for patient-level data \myred \textbf{complexities} \black (e.g. *imbalance*, *missingnes*, *skewness*, *correlation*, *clustering*)
  + In simulation, choice of model type and inputs should be based on the *research question* and *nature of the disease* 

. . . 

- Focus on \myred \textbf{recommended methods} \black in the context of a *RCT with a 1-year follow-up and homogeneous population*:

  + \scriptsize No *selection bias* due to lack of randomisation
  + No *discounting* for costs \& effects
  + No *extrapolation* of results beyond end of trial
  + No *subgroup* or *Value of Information* analysis
  + No *validation* of source data  
  

## Statistical ``issues" in analyses (El Alili et al. 2022)

\small

- \olive \textbf{Imbalances} \black in mean baseline effects/costs between arms, if not accounted for, may distort CE results (Manca et al. 2005, Asselt van et al. 2009)

. . .

- Ignoring the \olive \textbf{correlation} \black between effects \& costs is inappropriate and will lead to a loss in efficiency for the estimates (Willan et al. 2004)

. . .

- \olive \textbf{Skewness} \black in effects/costs in small samples undermines the validity of asymptotic tests and may lead to incorrect results (Barber et al. 2004)

. . .

- \olive \textbf{Clustering} \black of data linked to treatment (eg cluster RCTs) invalidates the assumptions of standard methods (eg OLS), underestimates variance and possibly bias results (Gomes et al. 2012)

. . .

- \olive \textbf{Missing} \black effects/costs during follow-up are common and may introduce bias. Methods that appropriately account for missing data uncertainty and assess the sensitivity of results are needed (Gabrio et al. 2017, Leurent et a. 2018)  


## How do we deal with all of this?

![](figure\meloni4b.jpg){width=70% fig-align="center"}

# Methods to handle statistical issues in CEA

## Baseline imbalances

- Randomisation ensures that baseline variables are *balanced* between arms but **SOME** differences will inevitably occur 

. . .

- This is particularly an issue for \myblue \textbf{baseline utilities} \black because:

  + they are used in the *computation of QALYs* through AUC method
  + they are likely to be *predictive* of utilities during follow-up

. . .

- Even small changes in $\Delta_{e}$ have consequences on *ICER* and *CE results* 

- This is true **regardless** of whether the difference in baseline values is statistically significant or not

- This is also true for any baseline variable that is **strongly predictive** of follow-up outcome values (eg \myred \textbf{baseline costs}\black) 

## Baseline imbalances - an example

\only<1>{
- \small Old : \myred $\text{QALY}_{\text{old}}=\left[\frac{0.63+0.63}{2}\times\frac{6}{12} + \frac{0.63+0.67}{2}\times\frac{6}{12} \right]=\textbf{0.64}$\black
}

\only<2>{
- \small New : \myblue $\text{QALY}_{\text{new}}=\left[\frac{0.55+0.63}{2}\times\frac{6}{12} + \frac{0.63+0.67}{2}\times\frac{6}{12} \right]=\textbf{0.62}$\black
}

\only<3>{
- \small $\Delta_e=$ New - Old : \mypurple $\text{QALY}_{\text{new}} - \text{QALY}_{\text{old}} =\textbf{0.62} - \textbf{0.64}=\textbf{-0.02}$\black
}

```{=latex}
\begin{tikzpicture}

\draw[thick,->] (0,0) -- (7,0) node[anchor=north west] {time};
\draw[thick,->] (0,0) -- (0,4.5) node[anchor=south east] {utility};
\draw(0,-0.3) node[align=center] {\scriptsize Baseline};
\draw(3,-0.3) node[align=center] {\scriptsize 6 months};
\draw(6,-0.3) node[align=center] {\scriptsize 12 months};
\draw(-0.5,1.8) node[align=center] {\scriptsize 0.55};
\draw(-0.5,2.6) node[align=center] {\scriptsize 0.63};
\draw(-0.5,3) node[align=center] {\scriptsize 0.67};
\only<1>{\draw[thick,red,fill=red!30] (0,2.6) -- (3,2.6) -- (6,3) -- (6,0) -- (0,0) -- cycle;}
\only<2>{\draw[thick,blue,fill=blue!30] (0,1.8) -- (3,2.6) -- (6,3) -- (6,0) -- (0,0) -- cycle;}
\only<3>{
\draw[thick,violet,fill=violet!30] (0,1.8) -- (3,2.6) -- (0,2.6) -- cycle;
}

\end{tikzpicture}
```

## Baseline imbalances - unadjusted estimates

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 


##| label: tbl-ex1
#generate data
library(mvtnorm)
n0 <- n1 <- 2000
time <- 3
mu0 <- c(0.63,0.63,0.67)
Sigma0 <- diag(3) 
diag(Sigma0) <- c(0.1^2,0.1^2,0.1^2)
rho0 <- 0.85
Sigma0[1,2] <- Sigma0[2,1] <- rho0*0.1*0.1
Sigma0[3,1] <- Sigma0[1,3] <- rho0*0.1*0.1
Sigma0[3,2] <- Sigma0[2,3] <- rho0*0.1*0.1
mu1 <- c(0.55,0.63,0.67)
Sigma1 <- diag(3) 
diag(Sigma1) <- c(0.1^2,0.1^2,0.1^2) 
rho1 <- 0.85
Sigma1[1,2] <- Sigma1[2,1] <- rho1*0.1*0.1
Sigma1[3,1] <- Sigma1[1,3] <- rho1*0.1*0.1
Sigma1[3,2] <- Sigma1[2,3] <- rho1*0.1*0.1
set.seed(2345)
u0 <- rmvnorm(n0, mean = mu0, sigma = Sigma0)
u1 <- rmvnorm(n1, mean = mu1, sigma = Sigma1)
QALY0 <- ((u0[,1]+u0[,2])/2)*(6/12) + ((u0[,2]+u0[,3])/2)*(6/12)
QALY1 <- ((u1[,1]+u1[,2])/2)*(6/12) + ((u1[,2]+u1[,3])/2)*(6/12)
#QALY_diff <- QALY1 - QALY0
#Delta_e <- round(mean(QALY_diff),digits=2)
#t.test(QALY_diff, conf.level = 0.95)
mean_u0 <- round(apply(u0,2,mean), digits=2)
mean_u1 <- round(apply(u1,2,mean), digits=2)
mean_QALY0 <- ((mean_u0[1]+mean_u0[2])/2)*(6/12) + ((mean_u0[2]+mean_u0[3])/2)*(6/12)
mean_QALY1 <- ((mean_u1[1]+mean_u1[2])/2)*(6/12) + ((mean_u1[2]+mean_u1[3])/2)*(6/12)
Delta_e <- mean_QALY1 - mean_QALY0

u_base <- c(u0[,1],u1[,1])
u_6m <- c(u0[,2],u1[,2])
u_12m <- c(u0[,3],u1[,3])
QALY <- c(QALY0, QALY1)
trt <- c(rep("old",n0),rep("new",n1))
dataset <- data.frame(u_base,u_6m,u_12m,QALY,trt)
dataset$trt <- factor(trt, levels = c("old", "new"))

library(emmeans)
#unadjusted analysis
lm1 <- lm(QALY ~ trt, data = dataset)
lm1.trt.ci <- confint(lm1, 'trtnew', level=0.95)
lm1.trt.sum <- c(coef(summary(lm1))["trtnew", c("Estimate", "Std. Error", "Pr(>|t|)")],lm1.trt.ci,lm1.trt.ci[2]-lm1.trt.ci[1])
names(lm1.trt.sum) <- c("Est","SE","p","CI(low)","CI(high)","CI(width)")
lm1.trt.sum <- round(lm1.trt.sum,digits=3)

lm1em <- emmeans(lm1, ~ trt)
contrast1_1vs0 <- list("New vs Old" = c(-1, 1))
lm1em_delta_e <- confint(contrast(lm1em, contrast1_1vs0))


#adjusted analysis
#dataset$u_base_star <- dataset$u_base - mean(dataset$u_base)
lm2 <- lm(QALY ~ trt + u_base, data = dataset)
lm2.trt.ci <- confint(lm2, 'trtnew', level=0.95)
lm2.trt.sum <- c(coef(summary(lm2))["trtnew", c("Estimate", "Std. Error", "Pr(>|t|)")],lm2.trt.ci,lm2.trt.ci[2]-lm2.trt.ci[1])
names(lm2.trt.sum) <- c("Est","SE","p","CI(low)","CI(high)","CI(width)")
lm2.trt.sum <- round(lm2.trt.sum,digits=3)

lm2em <- emmeans(lm2, ~ trt)
contrast2_1vs0 <- list("New vs Old" = c(-1, 1))
lm2em_delta_e <- confint(contrast(lm2em, contrast2_1vs0))


```

- **Unadjusted mean difference** can be obtained from the estimated *slope* ($\hat{\beta}_1$) of the linear regression

$$
\text{QALY}_i = \beta_0+\beta_1\times \text{arm}_i + \varepsilon_i
$$

- **Unadjusted means** in each arm can be obtained as *functions* of the estimated regression coefficients

$$
\begin{aligned}
\text{E}[\text{QALY}\mid \text{arm}=\text{old}] &= \hat{\beta}_0\\
\text{E}[\text{QALY}\mid \text{arm}=\text{new}] &= \hat{\beta}_0+\hat{\beta}_1\\
\end{aligned}
$$

## Baseline imbalances - adjusted estimates


- Recommended approach is to *include the imbalanced baseline variable into the regression*

$$
\text{QALY}_i = \beta_0+\beta_1\times \text{arm}_i + \beta_2\times \text{u}_{i0}+ \varepsilon_i
$$

- **Adjusted** estimates for $\Delta_e$ and mean QALYs in each arm can be obtained exactly as in the unadjusted case \red \textbf{BUT}\black with the *inclusion* of $\text{u}_0$ into the model

. . .

- In the presence of baseline imbalances, the \myblue \textbf{adjusted model} \black allows to:

  + Retrieve through $\hat{\beta}_1$ an **unbiased estimate** of $\Delta_e$ and $\text{E}[\text{QALY}\mid \text{arm}]$
  + Increase the **precision** of these estimates (ie *lower SEs \& narrower CIs*) 


```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| tidy: true

lm1_e0 <- round(summary(lm1em)$emmean[1],digits=5)
lm1_e0_lci <- round(summary(lm1em)$lower.CL[1],digits=5)
lm1_e0_uci <- round(summary(lm1em)$upper.CL[1],digits=5)
lm1_e1 <- round(summary(lm1em)$emmean[2],digits=5)
lm1_e1_lci <- round(summary(lm1em)$lower.CL[2],digits=5)
lm1_e1_uci <- round(summary(lm1em)$upper.CL[2],digits=5)
lm1_delta_e <- round(lm1em_delta_e$estimate,digits=5)
lm1_delta_e_lci <- round(lm1em_delta_e$lower.CL,digits=5)
lm1_delta_e_uci <- round(lm1em_delta_e$upper.CL,digits=5)

lm2_e0 <- round(summary(lm2em)$emmean[1],digits=5)
lm2_e0_lci <- round(summary(lm2em)$lower.CL[1],digits=5)
lm2_e0_uci <- round(summary(lm2em)$upper.CL[1],digits=5)
lm2_e1 <- round(summary(lm2em)$emmean[2],digits=5)
lm2_e1_lci <- round(summary(lm2em)$lower.CL[2],digits=5)
lm2_e1_uci <- round(summary(lm2em)$upper.CL[2],digits=5)
lm2_delta_e <- round(lm2em_delta_e$estimate,digits=5)
lm2_delta_e_lci <- round(lm2em_delta_e$lower.CL,digits=5)
lm2_delta_e_uci <- round(lm2em_delta_e$upper.CL,digits=5)

#create data frames for plotting

lm_mu_e <- c(lm1_e0,lm1_e1,lm2_e0,lm2_e1)
lm_mu_e_lci <- c(lm1_e0_lci,lm1_e1_lci,lm2_e0_lci,lm2_e1_lci)
lm_mu_e_uci <- c(lm1_e0_uci,lm1_e1_uci,lm2_e0_uci,lm2_e1_uci)
method <- c("unadjusted","unadjusted","adjusted","adjusted")
arm <- c("Old","New","Old","New")
mu_e_gg <- data.frame(cbind(lm_mu_e,lm_mu_e_lci,lm_mu_e_uci,method,arm))
mu_e_gg$arm <- factor(mu_e_gg$arm, levels = c("Old","New"))
mu_e_gg$method <- factor(mu_e_gg$method, levels = c("unadjusted","adjusted"))
names(mu_e_gg) <- c("Estimate","CI.low","CI.high","method","arm")

lm_delta_e <- c(lm1_delta_e,lm2_delta_e)
lm_delta_e_lci <- c(lm1_delta_e_lci,lm2_delta_e_lci)
lm_delta_e_uci <- c(lm1_delta_e_uci,lm2_delta_e_uci)
method <- c("unadjusted","adjusted")
delta_e_gg <- data.frame(cbind(lm_delta_e,lm_delta_e_lci,lm_delta_e_uci,method))
delta_e_gg$method <- factor(delta_e_gg$method, levels = c("unadjusted","adjusted"))
names(delta_e_gg) <- c("Estimate","CI.low","CI.high","method")
```

## Baseline imbalances - unadjusted vs adjusted estimates

:::: {layout="[0.5, 0.5]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 6
#| fig-height: 6 

#plot diff estimates
library(ggplot2)
delta_e_gg$Estimate <- as.numeric(delta_e_gg$Estimate)
delta_e_gg$CI.low <- as.numeric(delta_e_gg$CI.low)
delta_e_gg$CI.high <- as.numeric(delta_e_gg$CI.high)

ggplot(delta_e_gg, aes(x=method, y=Estimate, colour=method)) +
  geom_point(position=position_dodge(width=0.4), width=.1, size=2) +
  geom_errorbar(aes(ymin=CI.low, ymax=CI.high), width=.1, position = position_dodge(width = 0.4)) +
  scale_colour_manual(name="Method", labels=c("unadjusted","adjusted"), values=c("purple", "purple")) +
  ylab("Mean QALY Difference") + ylim(-0.03,0.055) +
  xlab("Method") +
  theme_classic() + 
  theme(legend.position = "none",
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \mypurple \textbf{Mean QALY difference} $\Delta_e$ \black

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

library(kableExtra)
kable(delta_e_gg, booktabs = TRUE, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:2, color = 'purple', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'purple', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8) 
```

:::

::::

## Baseline imbalances - unadjusted vs adjusted estimates

:::: {layout="[0.5, 0.5]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 6
#| fig-height: 6 

#plot QALY estimates
mu_e_gg$Estimate <- as.numeric(mu_e_gg$Estimate)
mu_e_gg$CI.low <- as.numeric(mu_e_gg$CI.low)
mu_e_gg$CI.high <- as.numeric(mu_e_gg$CI.high)
ggplot(mu_e_gg, aes(x=method, y=Estimate, colour=arm)) + 
  geom_point(position=position_dodge(width=0.4), width=.1, size=2) +
geom_errorbar(aes(ymin=CI.low, ymax=CI.high), width=.1, position = position_dodge(width = 0.4)) +
  scale_colour_manual(name="Arm", labels=c("Old","New"), values=c("red", "blue")) + 
  ylab("Mean QALY") + ylim(0.6,0.66) +
  xlab("Method") +
  theme_classic() + 
  theme(legend.position = "right",
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \red \textbf{Mean QALY} for arm = "Old" \black

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(mu_e_gg[c(1,3),1:4], booktabs = TRUE, row.names = F, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:2, color = 'red', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'red', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8)
```

\small 

- \blue \textbf{Mean QALY} for arm = "New" \black

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(mu_e_gg[c(2,4),1:4], booktabs = TRUE, row.names = F, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:2, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'blue', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8)
```
:::

::::


## Baseline imbalances - regression adjustment

- \myblue \textbf{Advantages}\black:

  + Easy to implement 
  + Allow to control for multiple variables 
  + Assess impact of specific variables on marginal CE outcomes (eg via interaction terms)

. . .

- \myred \textbf{Drawbacks}\black:

  + Assume variables' distribution is the same across arms
  + Adjusting for many variables may result in "overfitting"

. . .

- \olive \textbf{Other approaches}\black:

  + *Propensity score adjustment* (Indurkhya et al. 2006)
  + *Propensity score matching* (Sekhon et al. 2012)
  + *Genetic matching* (Sekhon et al. 2012)


## Correlation between CE outcomes

- Possible types of associations:

  + Treatments come from intensive research and are \red $\textbf{(+)}$ \black associated with higher unit costs
  + Treatments \blue $\textbf{(-)}$ \black reduce care pathway costs (eg fewer hospitalisations, side effects, etc.)

- If the outcomes are **sufficiently correlated**:

  + \olive \textbf{Joint modelling} \black of costs \& effects is needed to properly characterise uncertainty around parameter estimates and CE results
  + There is additional benefit from *borrowing information* across outcomes to estimate variance components and standard errors *more efficiently* than in separate univariate analyses

## Correlation between CE outcomes - an example

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| cache: true

options(scipen=999)
##| label: tbl-ex1
#generate data
library(mvtnorm)
n0 <- n1 <- 150
mu0 <- c(0.58,3)
Sigma0 <- diag(2) 
diag(Sigma0) <- c(0.1^2,1^2)
rho0 <- 0.75
Sigma0[1,2] <- Sigma0[2,1] <- rho0*0.1*1
mu1 <- c(0.65,3)
Sigma1 <- diag(2) 
diag(Sigma1) <- c(0.1^2,1^2) 
rho1 <- 0.75
Sigma1[1,2] <- Sigma1[2,1] <- rho1*0.1*1
set.seed(2345)
ec0 <- rmvnorm(n0, mean = mu0, sigma = Sigma0)
ec1 <- rmvnorm(n1, mean = mu1, sigma = Sigma1)
QALY0 <- ec0[,1]
QALY1 <- ec1[,1]
TC0 <- ec0[,2]*100
TC1 <- ec1[,2]*100
#generate baseline values
set.seed(2345)
u0 <- 0.1 + 0.001*QALY0 + rnorm(n0,0,0.25)
u1 <- 0.1 + 0.001*QALY1 + rnorm(n1,0,0.25)
c0 <- 100 + 0.001*TC0 + rnorm(n0,0,85)
c1 <- 100 + 0.001*TC1 + rnorm(n1,0,85)
#compute statistics
mean_QALY0 <- round(mean(QALY0), digits=2)
mean_QALY1 <- round(mean(QALY1), digits=2)
mean_TC0 <- round(mean(TC0), digits=0)
mean_TC1 <- round(mean(TC1), digits=0)
Delta_c <- mean_TC1 - mean_TC0
corr0_QT <- round(cor(QALY0,TC0), digits = 3)
corr1_QT <- round(cor(QALY1,TC1), digits = 3)

QALY <- c(QALY0, QALY1)
TC <- c(TC0, TC1)
u <- c(u0,u1)
c <- c(c0,c1)
trt <- c(rep("old",n0),rep("new",n1))
dataset <- data.frame(QALY,TC,u,c,trt)
dataset$trt <- factor(trt, levels = c("old", "new"))

mu_e <- c(mean_QALY0,mean_QALY1)
mu_c <- c(mean_TC0,mean_TC1)
rho_ec <- c(corr0_QT,corr1_QT)
arm <- c("Old","New")
sum_ec_gg <- data.frame(cbind(mu_e,mu_c,rho_ec,arm))
sum_ec_gg$arm <- factor(sum_ec_gg$arm, levels = c("Old","New"))
names(sum_ec_gg) <- c("QALY","TC","corr","arm")


#independent analyses
#library(tidyverse)   # ggplot2, dplyr, tidyr
#library(tidymodels)  # for broom functions
library(emmeans)    # for emmeans()
lm_e <- lm(QALY ~ trt + u, data = dataset)
lm_c <- lm(TC ~ trt + c, data = dataset)
lm_e.trt.ci <- confint(lm_e, 'trtnew', level=0.95)
lm_c.trt.ci <- confint(lm_c, 'trtnew', level=0.95)
lm_e.trt.sum <- c(coef(summary(lm_e))["trtnew", c("Estimate", "Std. Error", "Pr(>|t|)")],lm_e.trt.ci,lm_e.trt.ci[2]-lm_e.trt.ci[1])
lm_c.trt.sum <- c(coef(summary(lm_c))["trtnew", c("Estimate", "Std. Error", "Pr(>|t|)")],lm_c.trt.ci,lm_c.trt.ci[2]-lm_c.trt.ci[1])
names(lm_e.trt.sum) <- c("Est","SE","p","CI(low)","CI(high)","CI(width)")
names(lm_c.trt.sum) <- c("Est","SE","p","CI(low)","CI(high)","CI(width)")
lm_e.trt.sum <- round(lm_e.trt.sum,digits=4)
lm_c.trt.sum <- round(lm_c.trt.sum,digits=4)
lm_e.em <- emmeans(lm_e, ~ trt)
lm_c.em <- emmeans(lm_c, ~ trt)
lm_e.mu0.sum <- c(summary(lm_e.em)$emmean[1],summary(lm_e.em)$SE[1],summary(lm_e.em)$lower.CL[1],summary(lm_e.em)$upper.CL[1],summary(lm_e.em)$upper.CL[1]-summary(lm_e.em)$lower.CL[1])
lm_e.mu1.sum <- c(summary(lm_e.em)$emmean[2],summary(lm_e.em)$SE[2],summary(lm_e.em)$lower.CL[2],summary(lm_e.em)$upper.CL[2],summary(lm_e.em)$upper.CL[2]-summary(lm_e.em)$lower.CL[2])
lm_c.mu0.sum <- c(summary(lm_c.em)$emmean[1],summary(lm_c.em)$SE[1],summary(lm_c.em)$lower.CL[1],summary(lm_c.em)$upper.CL[1],summary(lm_c.em)$upper.CL[1]-summary(lm_c.em)$lower.CL[1])
lm_c.mu1.sum <- c(summary(lm_c.em)$emmean[2],summary(lm_c.em)$SE[2],summary(lm_c.em)$lower.CL[2],summary(lm_c.em)$upper.CL[2],summary(lm_c.em)$upper.CL[2]-summary(lm_c.em)$lower.CL[2])
names(lm_e.mu0.sum) <- names(lm_e.mu1.sum) <- names(lm_c.mu0.sum) <- names(lm_c.mu1.sum) <- c("Est","SE","CI(low)","CI(high)","CI(width)")
#contrast_e_1vs0 <- list("New vs Old" = c(-1, 1))
#contrast_c_1vs0 <- list("New vs Old" = c(-1, 1))
#lm_e.em_delta_e <- confint(contrast(lm_e.em, contrast_e_1vs0))
#lm_c.em_delta_c <- confint(contrast(lm_c.em, contrast_c_1vs0))

#SUR analysis
library(systemfit)
eq.e <- QALY~trt + u
eq.c <- TC~trt + c
#restrict = matrix(c(0,1,0,1), ncol = 4)
#rhs= c(0)
#                 control = systemfit.control(residCovWeighted = FALSE), 
#                 restrict.matrix = restrict, restrict.rhs = rhs
sur <- systemfit(list(QALYreg = eq.e, TCreg = eq.c), method="SUR", data=dataset)
sur_e.trt.ci <- confint(sur, level=0.95)["QALYreg_trtnew",]
sur_c.trt.ci <- confint(sur, level=0.95)["TCreg_trtnew",]
sur_e.trt.sum <- c(coef(summary(sur))["QALYreg_trtnew", c("Estimate", "Std. Error", "Pr(>|t|)")],sur_e.trt.ci,sur_e.trt.ci[2]-sur_e.trt.ci[1])
sur_c.trt.sum <- c(coef(summary(sur))["TCreg_trtnew", c("Estimate", "Std. Error", "Pr(>|t|)")],sur_c.trt.ci,sur_c.trt.ci[2]-sur_c.trt.ci[1])
names(sur_e.trt.sum) <- c("Est","SE","p","CI(low)","CI(high)","CI(width)")
names(sur_c.trt.sum) <- c("Est","SE","p","CI(low)","CI(high)","CI(width)")
sur_e.trt.sum <- round(sur_e.trt.sum,digits=4)
sur_c.trt.sum <- round(sur_c.trt.sum,digits=4)
#manually derive marginal means and SEs/CIs
X_sur_e <- model.matrix(sur$eq[[1]])
sigma_sur_e.hat <- summary(sur$eq[[1]])$sigma
beta_sur_e.hat <- coef(sur$eq[[1]])
XtX_sur_e.inv <- solve(t(X_sur_e) %*% X_sur_e ) 
contr_sur_e_mu0 <- c(1,0,1*mean(dataset$u)) 
contr_sur_e_mu1 <- c(1,1,1*mean(dataset$u)) 
ctb_sur_e_mu0 <- t(contr_sur_e_mu0) %*% beta_sur_e.hat 
ctb_sur_e_mu1 <- t(contr_sur_e_mu1) %*% beta_sur_e.hat 
std.err_sur_e_mu0 <- sigma_sur_e.hat * sqrt(t(contr_sur_e_mu0) %*% XtX_sur_e.inv %*% contr_sur_e_mu0 )
std.err_sur_e_mu1 <- sigma_sur_e.hat * sqrt(t(contr_sur_e_mu1) %*% XtX_sur_e.inv %*% contr_sur_e_mu1 )
X_sur_c <- model.matrix(sur$eq[[2]])
sigma_sur_c.hat <- summary(sur$eq[[2]])$sigma
beta_sur_c.hat <- coef(sur$eq[[2]])
XtX_sur_c.inv <- solve(t(X_sur_c) %*% X_sur_c) 
contr_sur_c_mu0 <- c(1,0,1*mean(dataset$c)) 
contr_sur_c_mu1 <- c(1,1,1*mean(dataset$c)) 
ctb_sur_c_mu0 <- t(contr_sur_c_mu0) %*% beta_sur_c.hat 
ctb_sur_c_mu1 <- t(contr_sur_c_mu1) %*% beta_sur_c.hat 
std.err_sur_c_mu0 <- sigma_sur_c.hat * sqrt(t(contr_sur_c_mu0) %*% XtX_sur_c.inv %*% contr_sur_c_mu0 )
std.err_sur_c_mu1 <- sigma_sur_c.hat * sqrt(t(contr_sur_c_mu1) %*% XtX_sur_c.inv %*% contr_sur_c_mu1 )
alpha<-0.05
n <- n0+n1
sur_e_mu0_l_cl <- ctb_sur_e_mu0 - qt(1-alpha/2,df=n-c(length(beta_sur_e.hat)-1))*std.err_sur_e_mu0
sur_e_mu0_u_cl <- ctb_sur_e_mu0 + qt(1-alpha/2,df=n-c(length(beta_sur_e.hat)-1))*std.err_sur_e_mu0
sur_e_mu1_l_cl <- ctb_sur_e_mu1 - qt(1-alpha/2,df=n-c(length(beta_sur_e.hat)-1))*std.err_sur_e_mu1
sur_e_mu1_u_cl <- ctb_sur_e_mu1 + qt(1-alpha/2,df=n-c(length(beta_sur_e.hat)-1))*std.err_sur_e_mu1
sur_c_mu0_l_cl <- ctb_sur_c_mu0 - qt(1-alpha/2,df=n-c(length(beta_sur_c.hat)-1))*std.err_sur_c_mu0
sur_c_mu0_u_cl <- ctb_sur_c_mu0 + qt(1-alpha/2,df=n-c(length(beta_sur_c.hat)-1))*std.err_sur_c_mu0
sur_c_mu1_l_cl <- ctb_sur_c_mu1 - qt(1-alpha/2,df=n-c(length(beta_sur_c.hat)-1))*std.err_sur_c_mu1
sur_c_mu1_u_cl <- ctb_sur_c_mu1 + qt(1-alpha/2,df=n-c(length(beta_sur_c.hat)-1))*std.err_sur_c_mu1
sur_e.mu0.sum <- cbind.data.frame(ctb_sur_e_mu0,std.err_sur_e_mu0,sur_e_mu0_l_cl,sur_e_mu0_u_cl,sur_e_mu0_u_cl-sur_e_mu0_l_cl)
sur_e.mu1.sum <- cbind.data.frame(ctb_sur_e_mu1,std.err_sur_e_mu1,sur_e_mu1_l_cl,sur_e_mu1_u_cl,sur_e_mu1_u_cl-sur_e_mu1_l_cl)
sur_c.mu0.sum <- cbind.data.frame(ctb_sur_c_mu0,std.err_sur_c_mu0,sur_c_mu0_l_cl,sur_c_mu0_u_cl,sur_c_mu0_u_cl-sur_c_mu0_l_cl)
sur_c.mu1.sum <- cbind.data.frame(ctb_sur_c_mu1,std.err_sur_c_mu1,sur_c_mu1_l_cl,sur_c_mu1_u_cl,sur_c_mu1_u_cl-sur_c_mu1_l_cl)
names(sur_e.mu0.sum) <- names(sur_e.mu1.sum) <- names(sur_c.mu0.sum) <- names(sur_c.mu1.sum) <- c("Est","SE","CI(low)","CI(high)","CI(width)") 

#bootstrap analysis
library(data.table)
library(bootstrap)
dataset.dt <- data.table(dataset)
n <- dim(dataset.dt)[1]
B <- 5000
data_ec_b_list <- list()
data_delta_c_b <- data_delta_e_b <- c()
data_mu0_c_b <- data_mu0_e_b <- c()
data_mu1_c_b <- data_mu1_e_b <- c()
for(i in 1:B){
  data_ec_b_list[[i]] <- dataset.dt[sample(.N, n, replace = T)]
  data_lm_c_coef_b <- coef(lm(TC ~ trt + c, data = data_ec_b_list[[i]]))
  data_lm_e_coef_b <- coef(lm(QALY ~ trt + u, data = data_ec_b_list[[i]]))
  data_mu0_c_b[i] <- data_lm_c_coef_b["(Intercept)"]+data_lm_c_coef_b["trtnew"]*0+data_lm_c_coef_b["c"]*mean(data_ec_b_list[[i]]$c)
  data_mu1_c_b[i] <- data_lm_c_coef_b["(Intercept)"]+data_lm_c_coef_b["trtnew"]*1+data_lm_c_coef_b["c"]*mean(data_ec_b_list[[i]]$c)
  data_mu0_e_b[i] <- data_lm_e_coef_b["(Intercept)"]+data_lm_e_coef_b["trtnew"]*0+data_lm_e_coef_b["u"]*mean(data_ec_b_list[[i]]$u)
  data_mu1_e_b[i] <- data_lm_e_coef_b["(Intercept)"]+data_lm_e_coef_b["trtnew"]*1+data_lm_e_coef_b["u"]*mean(data_ec_b_list[[i]]$u)  
  data_delta_c_b[i] <- data_lm_c_coef_b["trtnew"]
  data_delta_e_b[i] <- data_lm_e_coef_b["trtnew"]
}
mu0_c_b <- mean(data_mu0_c_b)
mu1_c_b <- mean(data_mu1_c_b)
mu0_e_b <- mean(data_mu0_e_b)
mu1_e_b <- mean(data_mu1_e_b)
delta_c_b <- mean(data_delta_c_b)
delta_e_b <- mean(data_delta_e_b)
sd_mu0_c_b <- sqrt((1/(B-1))*sum((mu0_c_b-data_mu0_c_b)^2))
sd_mu1_c_b <- sqrt((1/(B-1))*sum((mu1_c_b-data_mu1_c_b)^2))
sd_mu0_e_b <- sqrt((1/(B-1))*sum((mu0_e_b-data_mu0_e_b)^2))
sd_mu1_e_b <- sqrt((1/(B-1))*sum((mu1_e_b-data_mu1_e_b)^2))
sd_delta_c_b <- sqrt((1/(B-1))*sum((delta_c_b-data_delta_c_b)^2))
sd_delta_e_b <- sqrt((1/(B-1))*sum((delta_e_b-data_delta_e_b)^2))
alpha <- 0.05
mu0_c_l_perc <- quantile(data_mu0_c_b, probs = alpha/2)
mu0_c_u_perc <- quantile(data_mu0_c_b, probs = (1-alpha/2))
mu1_c_l_perc <- quantile(data_mu1_c_b, probs = alpha/2)
mu1_c_u_perc <- quantile(data_mu1_c_b, probs = (1-alpha/2))
mu0_e_l_perc <- quantile(data_mu0_e_b, probs = alpha/2)
mu0_e_u_perc <- quantile(data_mu0_e_b, probs = (1-alpha/2))
mu1_e_l_perc <- quantile(data_mu1_e_b, probs = alpha/2)
mu1_e_u_perc <- quantile(data_mu1_e_b, probs = (1-alpha/2))
delta_c_l_perc <- quantile(data_delta_c_b, probs = alpha/2)
delta_c_u_perc <- quantile(data_delta_c_b, probs = (1-alpha/2))
delta_e_l_perc <- quantile(data_delta_e_b, probs = alpha/2)
delta_e_u_perc <- quantile(data_delta_e_b, probs = (1-alpha/2))
boot_mu0_c.trt.sum.perc <- round(c(mu0_c_b,sd_mu0_c_b,mu0_c_l_perc,mu0_c_u_perc,mu0_c_u_perc-mu0_c_l_perc),digits=3)
boot_mu1_c.trt.sum.perc <- round(c(mu1_c_b,sd_mu1_c_b,mu1_c_l_perc,mu1_c_u_perc,mu1_c_u_perc-mu1_c_l_perc),digits=3)
boot_mu0_e.trt.sum.perc <- round(c(mu0_e_b,sd_mu0_e_b,mu0_e_l_perc,mu0_e_u_perc,mu0_e_u_perc-mu0_e_l_perc),digits=3)
boot_mu1_e.trt.sum.perc <- round(c(mu1_e_b,sd_mu1_e_b,mu1_e_l_perc,mu1_e_u_perc,mu1_e_u_perc-mu1_e_l_perc),digits=3)
boot_delta_c.trt.sum.perc <- round(c(delta_c_b,sd_delta_c_b,delta_c_l_perc,delta_c_u_perc,delta_c_u_perc-delta_c_l_perc),digits=3)
boot_delta_e.trt.sum.perc <- round(c(delta_e_b,sd_delta_e_b,delta_e_l_perc,delta_e_u_perc,delta_e_u_perc-delta_e_l_perc),digits=3)
names(boot_mu0_c.trt.sum.perc) <- names(boot_mu1_c.trt.sum.perc) <- names(boot_mu0_e.trt.sum.perc) <- names(boot_mu1_e.trt.sum.perc) <- names(boot_delta_c.trt.sum.perc) <- names(boot_delta_e.trt.sum.perc) <- c("Est","SE","CI(low)","CI(high)","CI(width)")
#use BCa correction
bar_mu0_c <- summary(emmeans(lm(TC~trt+ c,data=dataset),~trt))$emmean[1]
bar_mu1_c <- summary(emmeans(lm(TC~trt+ c,data=dataset),~trt))$emmean[2]
bar_mu0_e <- summary(emmeans(lm(QALY~trt+ u,data=dataset),~trt))$emmean[1]
bar_mu1_e <- summary(emmeans(lm(QALY~trt+ u,data=dataset),~trt))$emmean[2]
prop_mu0_c_lower <- length(data_mu0_c_b[data_mu0_c_b<bar_mu0_c])/B
prop_mu1_c_lower <- length(data_mu1_c_b[data_mu1_c_b<bar_mu1_c])/B
prop_mu0_e_lower <- length(data_mu0_e_b[data_mu0_e_b<bar_mu0_e])/B
prop_mu1_e_lower <- length(data_mu1_e_b[data_mu1_e_b<bar_mu1_e])/B
z0_mu0_c <- qnorm(prop_mu0_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_mu1_c <- qnorm(prop_mu1_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_mu0_e <- qnorm(prop_mu0_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_mu1_e <- qnorm(prop_mu1_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
bar_delta_c <- coef(lm(TC~trt+ c,data=dataset))["trtnew"]
bar_delta_e <- coef(lm(QALY~trt+ u,data=dataset))["trtnew"]
prop_delta_c_lower <- length(data_delta_c_b[data_delta_c_b<bar_delta_c])/B
prop_delta_e_lower <- length(data_delta_e_b[data_delta_e_b<bar_delta_e])/B
z0_delta_c <- qnorm(prop_delta_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_delta_e <- qnorm(prop_delta_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
jk_fun <- function(data, incremental = TRUE){
  n <- dim(data)[1]
  if(incremental == TRUE){
    jk_delta_c_i <- jk_delta_e_i <- c()
      for(i in 1:n){
    data_i <- data[-i,]
    jk_delta_c_i[i] <- coef(lm(TC ~ trt + c, data = data_i))["trtnew"]
    jk_delta_e_i[i] <- coef(lm(QALY ~ trt + u, data = data_i))["trtnew"]
      }
    jk_est_i <- cbind.data.frame(jk_delta_c_i,jk_delta_e_i)
    names(jk_est_i) <- c("delta_c","delta_e")
  }
  if(incremental == FALSE){
    jk_mu0_c_i <- jk_mu0_e_i <- c()
    jk_mu1_c_i <- jk_mu1_e_i <- c()
      for(i in 1:n){
    data_i <- data[-i,]
    jk_coef_c_i <- coef(lm(TC ~ trt + c, data = data_i))
    jk_coef_e_i <- coef(lm(QALY ~ trt + u, data = data_i))
    jk_mu0_c_i[i] <- jk_coef_c_i["(Intercept)"]+jk_coef_c_i["trtnew"]*0+jk_coef_c_i["c"]*mean(data_i$c)
    jk_mu1_c_i[i] <- jk_coef_c_i["(Intercept)"]+jk_coef_c_i["trtnew"]*1+jk_coef_c_i["c"]*mean(data_i$c)
    jk_mu0_e_i[i] <- jk_coef_e_i["(Intercept)"]+jk_coef_e_i["trtnew"]*0+jk_coef_e_i["u"]*mean(data_i$u)
    jk_mu1_e_i[i] <- jk_coef_e_i["(Intercept)"]+jk_coef_e_i["trtnew"]*1+jk_coef_e_i["u"]*mean(data_i$u)
      }
    jk_est_i <- cbind.data.frame(jk_mu0_c_i,jk_mu1_c_i,jk_mu0_e_i,jk_mu1_e_i)
    names(jk_est_i) <- c("mu0_c","mu1_c","mu0_e","mu1_e")
  }
  return(jk_est_i)
}
delta_jk <- jk_fun(dataset.dt, incremental = TRUE)
mu_jk <- jk_fun(dataset.dt, incremental = FALSE)
delta_jk_avg <- apply(delta_jk, 2, mean)
mu_jk_avg <- apply(mu_jk, 2, mean)
a_mu0_c <- sum((mu_jk_avg["mu0_c"] - mu_jk[,"mu0_c"])^3) / (6*(sum((mu_jk_avg["mu0_c"] - mu_jk[,"mu0_c"])^2))^(3/2))
a_mu1_c <- sum((mu_jk_avg["mu1_c"] - mu_jk[,"mu1_c"])^3) / (6*(sum((mu_jk_avg["mu1_c"] - mu_jk[,"mu1_c"])^2))^(3/2))
a_mu0_e <- sum((mu_jk_avg["mu0_e"] - mu_jk[,"mu0_e"])^3) / (6*(sum((mu_jk_avg["mu0_e"] - mu_jk[,"mu0_e"])^2))^(3/2))
a_mu1_e <- sum((mu_jk_avg["mu1_e"] - mu_jk[,"mu1_e"])^3) / (6*(sum((mu_jk_avg["mu1_e"] - mu_jk[,"mu1_e"])^2))^(3/2))
a_delta_c <- sum((delta_jk_avg["delta_c"] - delta_jk[,"delta_c"])^3) / (6*(sum((delta_jk_avg["delta_c"] - delta_jk[,"delta_c"])^2))^(3/2))
a_delta_e <- sum((delta_jk_avg["delta_e"] - delta_jk[,"delta_e"])^3) / (6*(sum((delta_jk_avg["delta_e"] - delta_jk[,"delta_e"])^2))^(3/2))
z_alpha1 <- qnorm(alpha/2, mean = 0, sd = 1, lower.tail = TRUE)
z_alpha2 <- qnorm(1-alpha/2, mean = 0, sd = 1, lower.tail = TRUE)
pl_mu0_c_bca <- pnorm(z0_mu0_c + ((z0_mu0_c+z_alpha1)/(1-a_mu0_c*(z0_mu0_c+z_alpha1))), mean = 0, sd = 1)
pu_mu0_c_bca <- pnorm(z0_mu0_c + ((z0_mu0_c+z_alpha2)/(1-a_mu0_c*(z0_mu0_c+z_alpha2))), mean = 0, sd = 1)
pl_mu1_c_bca <- pnorm(z0_mu1_c + ((z0_mu1_c+z_alpha1)/(1-a_mu1_c*(z0_mu1_c+z_alpha1))), mean = 0, sd = 1)
pu_mu1_c_bca <- pnorm(z0_mu1_c + ((z0_mu1_c+z_alpha2)/(1-a_mu1_c*(z0_mu1_c+z_alpha2))), mean = 0, sd = 1)
pl_mu0_e_bca <- pnorm(z0_mu0_e + ((z0_mu0_e+z_alpha1)/(1-a_mu0_e*(z0_mu0_e+z_alpha1))), mean = 0, sd = 1)
pu_mu0_e_bca <- pnorm(z0_mu0_e + ((z0_mu0_e+z_alpha2)/(1-a_mu0_e*(z0_mu0_e+z_alpha2))), mean = 0, sd = 1)
pl_mu1_e_bca <- pnorm(z0_mu1_e + ((z0_mu1_e+z_alpha1)/(1-a_mu1_e*(z0_mu1_e+z_alpha1))), mean = 0, sd = 1)
pu_mu1_e_bca <- pnorm(z0_mu1_e + ((z0_mu1_e+z_alpha2)/(1-a_mu1_e*(z0_mu1_e+z_alpha2))), mean = 0, sd = 1)
pl_delta_c_bca <- pnorm(z0_delta_c + ((z0_delta_c+z_alpha1)/(1-a_delta_c*(z0_delta_c+z_alpha1))), mean = 0, sd = 1)
pu_delta_c_bca <- pnorm(z0_delta_c + ((z0_delta_c+z_alpha2)/(1-a_delta_c*(z0_delta_c+z_alpha2))), mean = 0, sd = 1)
pl_delta_e_bca <- pnorm(z0_delta_e + ((z0_delta_e+z_alpha1)/(1-a_delta_e*(z0_delta_e+z_alpha1))), mean = 0, sd = 1)
pu_delta_e_bca <- pnorm(z0_delta_e + ((z0_delta_e+z_alpha2)/(1-a_delta_e*(z0_delta_e+z_alpha2))), mean = 0, sd = 1)
mu0_c_l_bca <- quantile(data_mu0_c_b, probs = pl_mu0_c_bca)
mu0_c_u_bca <- quantile(data_mu0_c_b, probs = pu_mu0_c_bca)
mu1_c_l_bca <- quantile(data_mu1_c_b, probs = pl_mu1_c_bca)
mu1_c_u_bca <- quantile(data_mu1_c_b, probs = pu_mu1_c_bca)
mu0_e_l_bca <- quantile(data_mu0_e_b, probs = pl_mu0_e_bca)
mu0_e_u_bca <- quantile(data_mu0_e_b, probs = pu_mu0_e_bca)
mu1_e_l_bca <- quantile(data_mu1_e_b, probs = pl_mu1_e_bca)
mu1_e_u_bca <- quantile(data_mu1_e_b, probs = pu_mu1_e_bca)
delta_c_l_bca <- quantile(data_delta_c_b, probs = pl_delta_c_bca)
delta_c_u_bca <- quantile(data_delta_c_b, probs = pu_delta_c_bca)
delta_e_l_bca <- quantile(data_delta_e_b, probs = pl_delta_e_bca)
delta_e_u_bca <- quantile(data_delta_e_b, probs = pu_delta_e_bca)
boot_mu0_c.trt.sum.bca <- round(c(mu0_c_b,sd_mu0_c_b,mu0_c_l_bca,mu0_c_u_bca,mu0_c_u_bca-mu0_c_l_bca),digits=3)
boot_mu1_c.trt.sum.bca <- round(c(mu1_c_b,sd_mu1_c_b,mu1_c_l_bca,mu1_c_u_bca,mu1_c_u_bca-mu1_c_l_bca),digits=3)
boot_mu0_e.trt.sum.bca <- round(c(mu0_e_b,sd_mu0_e_b,mu0_e_l_bca,mu0_e_u_bca,mu0_e_u_bca-mu0_e_l_bca),digits=3)
boot_mu1_e.trt.sum.bca <- round(c(mu1_e_b,sd_mu1_e_b,mu1_e_l_bca,mu1_e_u_bca,mu1_e_u_bca-mu1_e_l_bca),digits=3)
boot_delta_c.trt.sum.bca <- round(c(delta_c_b,sd_delta_c_b,delta_c_l_bca,delta_c_u_bca,delta_c_u_bca-delta_c_l_bca),digits=3)
boot_delta_e.trt.sum.bca <- round(c(delta_e_b,sd_delta_e_b,delta_e_l_bca,delta_e_u_bca,delta_e_u_bca-delta_e_l_bca),digits=3)
names(boot_mu0_c.trt.sum.bca) <- names(boot_mu1_c.trt.sum.bca) <- names(boot_mu0_e.trt.sum.bca) <- names(boot_mu1_e.trt.sum.bca) <- names(boot_delta_c.trt.sum.bca) <- names(boot_delta_e.trt.sum.bca) <- c("Est","SE","CI(low)","CI(high)","CI(width)")


```

:::: {layout="[0.5, 0.5]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 6
#| fig-height: 6 

#plot diff estimates
library(ggplot2)

ggplot(dataset, aes(x=QALY, y=TC, colour=trt)) +
  geom_point(width=.1, size=2, alpha=.5) +
  scale_colour_manual(name="Arm", labels=c("Old","New"), values=c("red", "blue")) +
  ylab("Total Costs") +
  xlab("QALYs") +
  theme_classic() + 
  theme(legend.position = "right",
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))
```

:::

:::{#secondcol}

\small

- Means and (Pearson's) \olive \textbf{correlations} \black between costs \& effects

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

library(kableExtra)
kable(sum_ec_gg, booktabs = TRUE, digits = 3, row.names = FALSE) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'red', bold = FALSE, italic = TRUE) %>% 
  row_spec(2, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(3, bold = TRUE, italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8) 
```

:::

::::

## CE correlation - independent analsyes

- We could run **separate analyses** for each outcome using the models

$$
\begin{aligned}
\text{QALY}_i &= \beta_0 + \beta_1\times \text{arm}_i + \beta_2\times u_{i0} + \varepsilon_{ie} \\
\text{TC}_i &= \alpha_0 + \alpha_1\times \text{arm}_i + \alpha_2\times c_{i0} + \varepsilon_{ic} \\
\end{aligned}
$$

- Get the estimates $\hat{\beta}=(\hat{\beta}_0,\hat{\beta}_1)$ and $\hat{\alpha}=(\hat{\alpha}_0,\hat{\alpha}_1)$, then derive:

  + \olive \textbf{Incremental}\black ($\Delta_e,\Delta_c$) and \olive \textbf{marginal}\black ($\text{E}[\text{QALY}\mid \text{arm}],\text{E}[\text{TC}\mid \text{arm}]$) quantities of interest
  + Associated *measures of uncertainty* (eg SEs or CIs)

. . .

- \textbf{Important}: by doing so, we are assuming \red \textbf{independence} \black between the outcomes!


## CE correlation - "joint" analsyes

- \olive \textbf{Seemingly Unrelated Regression} \black (SUR) equations

  + Same models but with **error terms linked** through the parameter $\rho$:

$$
\begin{aligned}
\begin{pmatrix}
\varepsilon_{ie}\\
\varepsilon_{ic}\\
\end{pmatrix} &\sim  \text{Normal}
\begin{bmatrix}
\begin{pmatrix}
0\\
0
\end{pmatrix}\!\!,&
\begin{pmatrix}
\sigma^2_e & \rho\sigma_e\sigma_c\\
\rho\sigma_c\sigma_e & \sigma^2_c
\end{pmatrix}
\end{bmatrix}
\end{aligned}
$$

. . .

- \olive \textbf{Bootstrapping} \black costs \& effects "in pairs" \small

  + Generate a "bootstrap" sample by **sampling with replacement** CE values for each individual from the observed data
  + Analyse CE outcomes and derive $(\hat{\beta},\hat{\alpha})^b$ --> $(\Delta_e,\Delta_c)^b$
  + Iterate the process a *sufficiently large number of times* (B) 
  + Use $(\Delta_e,\Delta_c)^b$ to approximate the sampling distribution of $(\Delta_e,\Delta_c)$
  + Use this distribution to quantify uncertainty (eg obtain CIs)


## What is bootstrapping?

```{=latex}
\begin{tikzpicture}
%Entire population
\only<1>{
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](3) at (-0.5,1.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](4) at (-0.8,1.9) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](6) at (-2.8,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](7) at (-1.7,2.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](8) at (-1.5,1.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](10) at (-2.7,1.2) {};
\draw[rounded corners=15pt,red,thick] (-3.5,0.5) rectangle (0.9,2.8) node[xshift=-2.2cm, yshift=0.2cm]{Original sample};

%Samples
\only<1>{\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont}](13) at (5.3,1.4) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_1$}](14) at (4.8,1.8) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_1$}](15) at (3.7,1.3) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_2$}](16) at (3.2,1.8) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_2$}](17) at (3.7,2.1) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_3$}](17a) at (4.2,1.5) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_3$}](17b) at (4.2,2.1) {};
\draw (3.9,1.9) [color=white] ellipse (1.2cm and .8cm);

\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_1$}](18) at (4.0,.4) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_1$}](19) at (4.5,.3) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_2$}](20) at (3.4,.1) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_2$}](21) at (2.8,.2) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_3$}](22) at (3.4,-.4) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_3$}](22b) at (3.9,-.2) {};
\draw (3.6,0.2) [color=white] ellipse (1.4cm and .8cm);

\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_1$}](23) at (7.1,1.2) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_1$}](24) at (7.5,1.2) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_2$}](25) at (6.4,1.1) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_2$}](26) at (5.9,1.1) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_3$}](27) at (6.8,.7) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_3$}](27b) at (7.2,.7) {};
\draw (6.8,1.2) [color=white] ellipse (1.4cm and .8cm);

\node[draw=none,font=\fontsize{7}{7}\selectfont](29) at (7.0,-.3) {\color{white}\textbf{\ldots}};
\draw[rounded corners=15pt,white,thick] (2.0,-.8) rectangle (8.3,2.8) node[xshift=-3.1cm, yshift=0.2cm]{Bootstrapped samples};
}

\node[draw=none](28) at (1.5,1.5) {$\Rightarrow$};
}

%Text
\draw(-1.3,-1.75) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\fontsize{8}{9}\selectfont,text width=4.6cm](7){
\begin{itemize}
\item Original sample $\approx$ population 
\item Original sample size $n=6$
\item Mean $\bar{e}=0.5$ \& $\bar{c}=150$
\item Sd $s_e=0.25$ \& $s_c=50$ 
\item Coeff $\hat{\beta}_1=0.15$ \& $\hat{\alpha}_1=35$
\end{itemize}
};

%Entire population
\only<2>{
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](3) at (-0.5,1.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](4) at (-0.8,1.9) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](6) at (-2.8,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](7) at (-1.7,2.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](8) at (-1.5,1.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](10) at (-2.7,1.2) {};
\draw[rounded corners=15pt,red,thick] (-3.5,0.5) rectangle (0.9,2.8) node[xshift=-2.2cm, yshift=0.2cm]{Original sample};

%Samples
\only<2>{\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont}](13) at (5.3,1.4) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](14) at (4.8,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](15) at (3.7,1.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](16) at (3.2,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](17) at (3.7,2.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](17a) at (4.2,1.5) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](17b) at (4.2,2.1) {};
\draw (3.9,1.9) [color=red] ellipse (1.2cm and .8cm);

\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_2$}](18) at (4.0,.4) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_2$}](19) at (4.5,.3) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_2$}](20) at (3.4,.1) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_2$}](21) at (2.8,.2) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_3$}](22) at (3.4,-.4) {};
\node[circle,fill=white,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_3$}](22b) at (3.9,-.2) {};
\draw (3.6,0.2) [color=white] ellipse (1.4cm and .8cm);

\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_3$}](23) at (7.1,1.2) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_3$}](24) at (7.5,1.2) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_3$}](25) at (6.4,1.1) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_3$}](26) at (5.9,1.1) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_2$}](27) at (6.8,.7) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_2$}](27b) at (7.2,.7) {};
\draw (6.8,1.2) [color=white] ellipse (1.4cm and .8cm);

\node[draw=none,font=\fontsize{7}{7}\selectfont](29) at (7.0,-.3) {\color{white}\textbf{\ldots}};
\draw[rounded corners=15pt,blue,thick] (2.0,-.8) rectangle (8.3,2.8) node[xshift=-3.1cm, yshift=0.2cm]{Bootstrapped samples};
}

\node[draw=none](28) at (1.5,1.5) {$\Rightarrow$};
}

\only<2>{
\draw(5.5,-1.7) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\fontsize{8}{9}\selectfont,text width=6.9cm](7){
\begin{itemize}
\item Bootstrap sample number $b=\color{red}1$
\item Bootstrapped sample size $n^b=\color{red} 6$
\item Bootstrapped Mean $\bar{e}^{b}=\color{red}0.4$ \& $\bar{c}^{b}=\color{red}160$
\item Bootstrapped Sd $s_e^{b}=\color{red}0.2$ \& $s_c^{b}=\color{red}50$
\item Bootstrapped Coeff $\hat{\beta}^{b}_1=\color{red}0.2$ \& $\hat{\alpha}^{b}_1=\color{red}40$
\end{itemize}
}

};


%Entire population
\only<3>{
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](3) at (-0.5,1.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](4) at (-0.8,1.9) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](6) at (-2.8,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](7) at (-1.7,2.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](8) at (-1.5,1.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](10) at (-2.7,1.2) {};
\draw[rounded corners=15pt,red,thick] (-3.5,0.5) rectangle (0.9,2.8) node[xshift=-2.2cm, yshift=0.2cm]{Original sample};

%Samples
\only<3>{\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont}](13) at (5.3,1.4) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](14) at (4.8,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](15) at (3.7,1.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](16) at (3.2,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](17) at (3.7,2.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](17a) at (4.2,1.5) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](17b) at (4.2,2.1) {};
\draw (3.9,1.9) ellipse (1.2cm and .8cm);

\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](18) at (4.0,.4) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](19) at (4.5,.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](20) at (3.4,.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](21) at (2.8,.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](22) at (3.4,-.4) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](22b) at (3.9,-.2) {};
\draw (3.6,0.2) [color=red] ellipse (1.4cm and .8cm);

\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_3$}](23) at (7.1,1.2) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_3$}](24) at (7.5,1.2) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_3$}](25) at (6.4,1.1) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_3$}](26) at (5.9,1.1) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$e_2$}](27) at (6.8,.7) {};
\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont \color{white}$c_2$}](27b) at (7.2,.7) {};
\draw (6.8,1.2) [color=white] ellipse (1.4cm and .8cm);

\node[draw=none,font=\fontsize{7}{7}\selectfont](29) at (7.0,-.3) {\color{white}\textbf{\ldots}};
\draw[rounded corners=15pt,blue,thick] (2.0,-.8) rectangle (8.3,2.8) node[xshift=-3.1cm, yshift=0.2cm]{Bootstrapped samples};
}

\node[draw=none](28) at (1.5,1.5) {$\Rightarrow$};
}

\only<3>{
\draw(5.5,-1.7) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\fontsize{8}{9}\selectfont,text width=6.9cm](7){
\begin{itemize}
\item Bootstrap sample number $b=\color{red}2$
\item Bootstrapped sample size $n^b=\color{red} 6$
\item Bootstrapped Mean $\bar{e}^{b}=\color{red}0.37$ \& $\bar{c}^{b}=\color{red}130$
\item Bootstrapped Sd $s_e^{b}=\color{red}0.13$ \& $s_c^{b}=\color{red}42$
\item Bootstrapped Coeff $\hat{\beta}^{b}_1=\color{red}0.18$ \& $\hat{\alpha}^{b}_1=\color{red}25$
\end{itemize}
}

};



%Entire population
\only<4>{
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](3) at (-0.5,1.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](4) at (-0.8,1.9) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](6) at (-2.8,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](7) at (-1.7,2.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](8) at (-1.5,1.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](10) at (-2.7,1.2) {};
\draw[rounded corners=15pt,red,thick] (-3.5,0.5) rectangle (0.9,2.8) node[xshift=-2.2cm, yshift=0.2cm]{Original sample};

%Samples
\only<4>{\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont}](13) at (5.3,1.4) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](14) at (4.8,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](15) at (3.7,1.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](16) at (3.2,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](17) at (3.7,2.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](17a) at (4.2,1.5) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](17b) at (4.2,2.1) {};
\draw (3.9,1.9) ellipse (1.2cm and .8cm);

\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](18) at (4.0,.4) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](19) at (4.5,.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](20) at (3.4,.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](21) at (2.8,.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](22) at (3.4,-.4) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](22b) at (3.9,-.2) {};
\draw (3.6,0.2) ellipse (1.4cm and .8cm);

\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](23) at (7.1,1.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](24) at (7.5,1.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](25) at (6.4,1.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](26) at (5.9,1.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](27) at (6.8,.7) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](27b) at (7.2,.7) {};
\draw (6.8,1.2) [color=red] ellipse (1.4cm and .8cm);

\node[draw=none,font=\fontsize{7}{7}\selectfont](29) at (7.0,-.3) {\color{white}\textbf{\ldots}};
\draw[rounded corners=15pt,blue,thick] (2.0,-.8) rectangle (8.3,2.8) node[xshift=-3.1cm, yshift=0.2cm]{Bootstrapped samples};
}

\node[draw=none](28) at (1.5,1.5) {$\Rightarrow$};
}

\only<4>{
\draw(5.5,-1.7) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\fontsize{8}{9}\selectfont,text width=6.9cm](7){
\begin{itemize}
\item Bootstrap sample number $b=\color{red}3$
\item Bootstrapped sample size $n^b=\color{red} 6$
\item Bootstrapped Mean $\bar{e}^{b}=\color{red}0.5$ \& $\bar{c}^{b}=\color{red}155$
\item Bootstrapped Sd $s_e^{b}=\color{red}0.14$ \& $s_c^{b}=\color{red}32$
\item Bootstrapped Coeff $\hat{\beta}^{b}_1=\color{red}0.15$ \& $\hat{\alpha}^{b}_1=\color{red}33$
\end{itemize}
}

};


%Entire population
\only<5>{
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](3) at (-0.5,1.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](4) at (-0.8,1.9) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](6) at (-2.8,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](7) at (-1.7,2.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](8) at (-1.5,1.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](10) at (-2.7,1.2) {};
\draw[rounded corners=15pt,red,thick] (-3.5,0.5) rectangle (0.9,2.8) node[xshift=-2.2cm, yshift=0.2cm]{Original sample};

%Samples
\only<5>{\node[circle,fill=white!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont}](13) at (5.3,1.4) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](14) at (4.8,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](15) at (3.7,1.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_1$}](16) at (3.2,1.8) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_1$}](17) at (3.7,2.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](17a) at (4.2,1.5) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](17b) at (4.2,2.1) {};
\draw (3.9,1.9) ellipse (1.2cm and .8cm);

\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](18) at (4.0,.4) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](19) at (4.5,.3) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](20) at (3.4,.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](21) at (2.8,.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](22) at (3.4,-.4) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](22b) at (3.9,-.2) {};
\draw (3.6,0.2) ellipse (1.4cm and .8cm);

\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](23) at (7.1,1.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](24) at (7.5,1.2) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_3$}](25) at (6.4,1.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_3$}](26) at (5.9,1.1) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $e_2$}](27) at (6.8,.7) {};
\node[circle,fill=blue!20,inner sep=0pt,minimum size=2pt,label=above:{\fontsize{7}{7}\selectfont $c_2$}](27b) at (7.2,.7) {};
\draw (6.8,1.2) ellipse (1.4cm and .8cm);

\node[draw=none,font=\fontsize{7}{7}\selectfont](29) at (7.0,-.3) {\color{red}\textbf{\ldots}};
\draw[rounded corners=15pt,blue,thick] (2.0,-.8) rectangle (8.3,2.8) node[xshift=-3.1cm, yshift=0.2cm]{Bootstrapped samples};
}

\node[draw=none](28) at (1.5,1.5) {$\Rightarrow$};
}

\only<5>{
\draw(5,-1.7) node[align=center,rectangle,rounded corners,draw=none,font=\sffamily\fontsize{8}{9}\selectfont,text width=6cm](7){
\begin{itemize}
\item Iterate the process $b=4,\ldots,B$ times 
\item Quantify uncertainty of the estimators (eg CIs) using all bootstrapped samples
\end{itemize}
}

};

\end{tikzpicture}
```

## Correlation - comparison of approaches

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

#combine results in data frame
df.delta.estimate <- c(lm_e.trt.sum["Est"],sur_e.trt.sum["Est"],boot_delta_e.trt.sum.perc["Est"],boot_delta_e.trt.sum.bca["Est"],lm_c.trt.sum["Est"],sur_c.trt.sum["Est"],boot_delta_c.trt.sum.perc["Est"],boot_delta_c.trt.sum.bca["Est"])
df.delta.CI.low <- c(lm_e.trt.sum["CI(low)"],sur_e.trt.sum["CI(low)"],boot_delta_e.trt.sum.perc["CI(low)"],boot_delta_e.trt.sum.bca["CI(low)"],lm_c.trt.sum["CI(low)"],sur_c.trt.sum["CI(low)"],boot_delta_c.trt.sum.perc["CI(low)"],boot_delta_c.trt.sum.bca["CI(low)"])
df.delta.CI.high <- c(lm_e.trt.sum["CI(high)"],sur_e.trt.sum["CI(high)"],boot_delta_e.trt.sum.perc["CI(high)"],boot_delta_e.trt.sum.bca["CI(high)"],lm_c.trt.sum["CI(high)"],sur_c.trt.sum["CI(high)"],boot_delta_c.trt.sum.perc["CI(high)"],boot_delta_c.trt.sum.bca["CI(high)"])
df.delta.method <- c("OLS","SUR","boot(p)","boot(b)","OLS","SUR","boot(p)","boot(b)")
df.delta.outcome <- c("QALY","QALY","QALY","QALY","TC","TC","TC","TC")
df.delta.corr <- cbind.data.frame(df.delta.estimate,df.delta.CI.low,df.delta.CI.high,df.delta.method,df.delta.outcome)
names(df.delta.corr) <- c("Estimate","CI.low","CI.high","method","outcome")

#plot diff estimates
library(ggplot2)
df.delta.corr$Estimate <- as.numeric(df.delta.corr$Estimate)
df.delta.corr$CI.low <- as.numeric(df.delta.corr$CI.low)
df.delta.corr$CI.high <- as.numeric(df.delta.corr$CI.high)
df.delta.corr$method <- factor(df.delta.corr$method, levels = c("OLS","SUR","boot(p)","boot(b)"))
df.delta.corr$outcome <- factor(df.delta.corr$outcome, levels = c("QALY","TC"))
df.delta.corr.QALY <- df.delta.corr[df.delta.corr$outcome=="QALY",-5]
df.delta.corr.TC <- df.delta.corr[df.delta.corr$outcome=="TC", -5]

ggplot(df.delta.corr, aes(x=factor(method, levels = c("OLS","SUR","boot(p)","boot(b)")), y=Estimate, colour=factor(outcome, levels = c("QALY","TC")))) +
  geom_point(position=position_dodge(width=0.4), width=.1, size=2) +
  geom_errorbar(aes(ymin=CI.low, ymax=CI.high), width=.1, position = position_dodge(width = 0.4)) + facet_wrap(~factor(outcome, levels = c("QALY","TC")), scales = "free") +
  ylab("Mean Difference") + scale_colour_manual(name="outcome", labels=c("QALY","TC"), values=c("purple", "purple")) +
  xlab("") +
  theme_classic() + 
  theme(legend.position = "none",
        text = element_text(size = 10),
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \myblue \textbf{Mean QALY difference} $\Delta_e$ \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(df.delta.corr.QALY, booktabs = TRUE, row.names = FALSE ,digits = 4) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:4, color = 'purple', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'purple', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

\small

- \myred \textbf{Mean TC difference} $\Delta_c$ \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(df.delta.corr.TC, booktabs = TRUE, row.names = FALSE, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:4, color = 'purple', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'purple', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::

## Correlation - comparison of approaches

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

#combine results in data frame
df.mu.estimate <- as.numeric(c(lm_e.mu0.sum["Est"],sur_e.mu0.sum["Est"],boot_mu0_e.trt.sum.perc["Est"],boot_mu0_e.trt.sum.bca["Est"],lm_c.mu0.sum["Est"],sur_c.mu0.sum["Est"],boot_mu0_c.trt.sum.perc["Est"],boot_mu0_c.trt.sum.bca["Est"],lm_e.mu1.sum["Est"],sur_e.mu1.sum["Est"],boot_mu1_e.trt.sum.perc["Est"],boot_mu1_e.trt.sum.bca["Est"],lm_c.mu1.sum["Est"],sur_c.mu1.sum["Est"],boot_mu1_c.trt.sum.perc["Est"],boot_mu1_c.trt.sum.bca["Est"]))
df.mu.CI.low <- as.numeric(c(lm_e.mu0.sum["CI(low)"],sur_e.mu0.sum["CI(low)"],boot_mu0_e.trt.sum.perc["CI(low)"],boot_mu0_e.trt.sum.bca["CI(low)"],lm_c.mu0.sum["CI(low)"],sur_c.mu0.sum["CI(low)"],boot_mu0_c.trt.sum.perc["CI(low)"],boot_mu0_c.trt.sum.bca["CI(low)"],lm_e.mu1.sum["CI(low)"],sur_e.mu1.sum["CI(low)"],boot_mu1_e.trt.sum.perc["CI(low)"],boot_mu1_e.trt.sum.bca["CI(low)"],lm_c.mu1.sum["CI(low)"],sur_c.mu1.sum["CI(low)"],boot_mu1_c.trt.sum.perc["CI(low)"],boot_mu1_c.trt.sum.bca["CI(low)"]))
df.mu.CI.high <- as.numeric(c(lm_e.mu0.sum["CI(high)"],sur_e.mu0.sum["CI(high)"],boot_mu0_e.trt.sum.perc["CI(high)"],boot_mu0_e.trt.sum.bca["CI(high)"],lm_c.mu0.sum["CI(high)"],sur_c.mu0.sum["CI(high)"],boot_mu0_c.trt.sum.perc["CI(high)"],boot_mu0_c.trt.sum.bca["CI(high)"],lm_e.mu1.sum["CI(high)"],sur_e.mu1.sum["CI(high)"],boot_mu1_e.trt.sum.perc["CI(high)"],boot_mu1_e.trt.sum.bca["CI(high)"],lm_c.mu1.sum["CI(high)"],sur_c.mu1.sum["CI(high)"],boot_mu1_c.trt.sum.perc["CI(high)"],boot_mu1_c.trt.sum.bca["CI(high)"]))
df.mu.method <- c("OLS","SUR","boot(p)","boot(b)","OLS","SUR","boot(p)","boot(b)",
                  "OLS","SUR","boot(p)","boot(b)","OLS","SUR","boot(p)","boot(b)")
df.mu.outcome <- c("QALY","QALY","QALY","QALY","TC","TC","TC","TC",
                   "QALY","QALY","QALY","QALY","TC","TC","TC","TC")
df.mu.arm <- c(rep("Old",8),rep("New",8))
df.mu.corr <- cbind.data.frame(df.mu.estimate,df.mu.CI.low,df.mu.CI.high,df.mu.method,df.mu.outcome,df.mu.arm)
names(df.mu.corr) <- c("Estimate","CI.low","CI.high","method","outcome","arm")

#plot diff estimates
df.mu.corr$method <- factor(df.mu.corr$method, levels = c("OLS","SUR","boot(p)","boot(b)"))
df.mu.corr$outcome <- factor(df.mu.corr$outcome, levels = c("QALY","TC"))
df.mu.corr$arm <- factor(df.mu.corr$arm, levels = c("Old","New"))
df.mu.corr.QALY <- df.mu.corr[df.mu.corr$outcome=="QALY",-5]
df.mu.corr.TC <- df.mu.corr[df.mu.corr$outcome=="TC", -5]

ggplot(df.mu.corr.QALY, aes(x=factor(method, levels = c("OLS","SUR","boot(p)","boot(b)")), y=Estimate, colour=arm)) +
  geom_point(position=position_dodge(width=0.4), width=.1, size=2) +
  geom_errorbar(aes(ymin=CI.low, ymax=CI.high), width=.1, position = position_dodge(width = 0.4)) + facet_wrap(~arm, scales = "free") +
  ylab("Mean QALY Difference") + scale_colour_manual(name="arm", labels=c("Old","New"), values=c("red", "blue")) +
  xlab("") +
  theme_classic() + 
  theme(legend.position = "none",
        text = element_text(size = 10),
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \myred \textbf{Mean QALY} for arm = "Old" \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

df.mu.corr.QALY.old <- df.mu.corr.QALY[df.mu.corr.QALY$arm=="Old",-5]
kable(df.mu.corr.QALY.old, booktabs = TRUE, row.names = FALSE ,digits = 4) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:4, color = 'red', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'red', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

\small

- \myblue \textbf{Mean QALY} for arm = "New" \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

df.mu.corr.QALY.new <- df.mu.corr.QALY[df.mu.corr.QALY$arm=="New",-5]
kable(df.mu.corr.QALY.new, booktabs = TRUE, row.names = FALSE, digits = 4) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:4, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'blue', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::


## Correlation - comparison of approaches

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

ggplot(df.mu.corr.TC, aes(x=factor(method, levels = c("OLS","SUR","boot(p)","boot(b)")), y=Estimate, colour=arm)) +
  geom_point(position=position_dodge(width=0.4), width=.1, size=2) +
  geom_errorbar(aes(ymin=CI.low, ymax=CI.high), width=.1, position = position_dodge(width = 0.4)) + facet_wrap(~arm, scales = "free") +
  ylab("Mean TC Difference") + scale_colour_manual(name="arm", labels=c("Old","New"), values=c("red", "blue")) +
  xlab("") +
  theme_classic() + 
  theme(legend.position = "none",
        text = element_text(size = 10),
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \myred \textbf{Mean TC} for arm = "Old" \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

df.mu.corr.TC.old <- df.mu.corr.TC[df.mu.corr.TC$arm=="Old",-5]
kable(df.mu.corr.TC.old, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:4, color = 'red', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'red', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

\small

- \myblue \textbf{Mean TC} for arm = "New" \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

df.mu.corr.TC.new <- df.mu.corr.TC[df.mu.corr.TC$arm=="New",-5]
kable(df.mu.corr.TC.new, booktabs = TRUE, row.names = FALSE, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:4, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'blue', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::

## Correlation - SUR/bootstrapping

- \olive \textbf{SUR}\black:

  + Can be more \myblue \textbf{efficient} \black than separate OLS analyses
  + Allow inclusion of outcome-specific variables into the regressions
  + Similar \myred \textbf{limitations} \black of standard regression

. . .

- \olive (non-parametric) \textbf{Bootstrapping}\black:

  + Paired re-sampling can \myblue \textbf{maintain} \black CE correlation
  + Performance wrt joint models has **not** been fully assessed
  + \myred \textbf{Different ways} \black to compute CIs (percentile, bias-corrected and accelerated, ...)

. . .

- \olive \textbf{Other approaches}\black:

  + *Bayesian joint models* (Gabrio et al. 2019)


## Skewness in CE outcomes

- Costs are typically \olive \textbf{right-skewed} \black while utilities tend to be \olive \textbf{left-skewed}\black:

  + Costs are bound at $0$ with few participants with very high costs
  + Utilities are bound at $1$ with few participants with very low (also negative) values

. . .

- Many methods rely on \olive \textbf{Normality} \black assumptions that may be violated and lead to misleading inferences:

  + In "large" samples, **CLT** ensures that estimates are unbiased but *efficiency* may not be achieved 
  + In "small" samples, *unbiasdness* is no longer guaranteed 

. . .

- **No general consensus** at which point:
  + The degree of skewness is "too high"
  + The size of the sample is "too small"

. . .

- Data *transformations* (eg log) are **not appropriate** as they do not provide inferences about population means of interest  

## Skewness in CE outcomes - an example

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| cache: false

#simulate typical distribution of u and c in pop and sample
n_pop <- 5000
mu_u <- 0.86
sigma_u <- 0.2
tau_u <- (mu_u*(1-mu_u)/sigma_u^2-1)
shape1_u <- mu_u*tau_u
shape2_u <- (1-mu_u)*tau_u
set.seed(2345)
pop_u <- rbeta(n_pop,shape1 = shape1_u, shape2 = shape2_u)
mu_c <- 100 
sigma_c <- 97
shape_c <- mu_c^2/sigma_c^2
scale_c <- sigma_c^2/mu_c
set.seed(2345)
pop_c <- rgamma(n_pop, shape = shape_c, scale = scale_c)
n_sam <- 25
dataset_pop_skew.df <- data.frame(pop_u,pop_c)
names(dataset_pop_skew.df) <- c("QALY","TC")
set.seed(2345)
dataset_sam_skew.df <- dataset_pop_skew.df[sample(nrow(dataset_pop_skew.df), n_sam), ]
names(dataset_sam_skew.df) <- c("QALY","TC")
bar_u <- mean(dataset_sam_skew.df$QALY)
sd_u <- sd(dataset_sam_skew.df$QALY)
bar_c <- mean(dataset_sam_skew.df$TC)
sd_c <- sd(dataset_sam_skew.df$TC)
sample_tau_u <- (bar_u*(1-bar_u)/sd_u^2-1)
sample_shape1_u <- bar_u*sample_tau_u
sample_shape2_u <- (1-bar_u)*sample_tau_u
sample_shape_c <- bar_c^2/sd_c^2
sample_scale_c <- sd_c^2/bar_c


#generate histograms for pop
gghist1_pop_e <- ggplot(dataset_pop_skew.df, aes(x=QALY)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=0.1) +
  xlab("QALY") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,9)) +
  scale_x_continuous(limits = c(0,1.25)) +
  geom_vline(xintercept = mu_u, colour="blue", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")

gghist2_pop_e <- ggplot(dataset_pop_skew.df, aes(x=QALY)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=0.1) +
  xlab("QALY") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,9)) +
  scale_x_continuous(limits = c(0,1.25)) +
  stat_function(fun = dnorm, args = list(mean = mu_u, sd = sigma_u), color="black", linewidth=1) +
  geom_vline(xintercept = mu_u, colour="blue", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")

gghist3_pop_e <- ggplot(dataset_pop_skew.df, aes(x=QALY)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=0.1) +
  xlab("QALY") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,9)) +
  scale_x_continuous(limits = c(0,1.25)) +
  stat_function(fun = dnorm, args = list(mean = mu_u, sd = sigma_u), color="black", linewidth=1) +
  geom_function(fun = dbeta, args = list(shape1 = shape1_u, shape2 = shape2_u), color="darkgreen", linewidth = 1) + 
  geom_vline(xintercept = mu_u, colour="blue", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")

gghist1_pop_c <- ggplot(dataset_pop_skew.df, aes(x=TC)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=30) +
  xlab("TC") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,0.011)) +
  scale_x_continuous(limits = c(-200,600)) +
  geom_vline(xintercept = mu_c, colour="blue", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")

gghist2_pop_c <- ggplot(dataset_pop_skew.df, aes(x=TC)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=30) +
  xlab("TC") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,0.011)) +
  scale_x_continuous(limits = c(-200,600)) +
  stat_function(fun = dnorm, args = list(mean = mu_c, sd = sigma_c), linewidth=1) +
  geom_vline(xintercept = mu_c, colour="blue", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")


gghist3_pop_c <- ggplot(dataset_pop_skew.df, aes(x=TC)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=30) +
  xlab("TC") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,0.011)) +
  scale_x_continuous(limits = c(-200,600)) +
  stat_function(fun = dnorm, args = list(mean = mu_c, sd = sigma_c), linewidth=1) +
  geom_function(fun = dgamma, args = list(shape = shape_c, scale = scale_c), color="darkgreen", linewidth=1) + 
  geom_vline(xintercept = mu_c, colour="blue", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")



#generate histograms for sample
gghist1_sam_e <- ggplot(dataset_sam_skew.df, aes(x=QALY)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=0.1) +
  xlab("QALY") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,9)) +
  scale_x_continuous(limits = c(0,1.25)) +
  geom_vline(xintercept = mu_u, colour="blue", linewidth=1) +
  geom_vline(xintercept = bar_u, colour="red", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")

gghist2_sam_e <- ggplot(dataset_sam_skew.df, aes(x=QALY)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=0.1) +
  xlab("QALY") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,9)) +
  scale_x_continuous(limits = c(0,1.25)) +
  stat_function(fun = dnorm, args = list(mean = bar_u, sd = sd_u), color="black", linewidth=1) +
  geom_vline(xintercept = mu_u, colour="blue", linewidth=1) +
  geom_vline(xintercept = bar_u, colour="red", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")

gghist3_sam_e <- ggplot(dataset_sam_skew.df, aes(x=QALY)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=0.1) +
  xlab("QALY") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,9)) +
  scale_x_continuous(limits = c(0,1.25)) +
  stat_function(fun = dnorm, args = list(mean = bar_u, sd = sd_u), color="black", linewidth=1) +
  geom_function(fun = dbeta, args = list(shape1 = sample_shape1_u, shape2 = sample_shape2_u), color="darkgreen", linewidth = 1) + 
  geom_vline(xintercept = mu_u, colour="blue", linewidth=1) +
  geom_vline(xintercept = bar_u, colour="red", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")

gghist1_sam_c <- ggplot(dataset_sam_skew.df, aes(x=TC)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=30) +
  xlab("TC") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,0.011)) +
  scale_x_continuous(limits = c(-200,600)) +
  geom_vline(xintercept = 100, colour="blue", linewidth=1) +
  geom_vline(xintercept = bar_c, colour="red", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")

gghist2_sam_c <- ggplot(dataset_sam_skew.df, aes(x=TC)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=30) +
  xlab("TC") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,0.011)) +
  scale_x_continuous(limits = c(-200,600)) +
  stat_function(fun = dnorm, args = list(mean = bar_c, sd = sd_c), linewidth=1) +
  geom_vline(xintercept = 100, colour="blue", linewidth=1) +
  geom_vline(xintercept = bar_c, colour="red", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")

gghist3_sam_c <- ggplot(dataset_sam_skew.df, aes(x=TC)) + 
  geom_histogram(aes(y =..density..), color="black",fill="white", binwidth=30) +
  xlab("TC") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,0.011)) +
  scale_x_continuous(limits = c(-200,600)) +
  stat_function(fun = dnorm, args = list(mean = bar_c, sd = sd_c), linewidth=1) +
  geom_function(fun = dgamma, args = list(shape = sample_shape_c, scale = sample_scale_c), color="darkgreen", linewidth=1) + 
  geom_vline(xintercept = 100, colour="blue", linewidth=1) +
  geom_vline(xintercept = bar_c, colour="red", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")

#see accuracy of predictions
mu_u_pop_ci <- quantile(dataset_pop_skew.df$QALY, probs = c(0.025,0.975))
mu_c_pop_ci <- quantile(dataset_pop_skew.df$TC, probs = c(0.025,0.975))
mu_u_sam_ci <- quantile(dataset_sam_skew.df$QALY, probs = c(0.025,0.975))
mu_c_sam_ci <- quantile(dataset_sam_skew.df$TC, probs = c(0.025,0.975))

u_pred_norm_pop <- u_pred_norm_sam <- c()
c_pred_norm_pop <- c_pred_norm_sam <- c()
set.seed(2345)
for(i in 1:1000){
u_pred_norm_pop[i] <- mean(rnorm(n_pop, mean = mu_u, sd = sigma_u/sqrt(n_pop)))
u_pred_norm_sam[i] <- mean(rnorm(n_pop,mean = bar_u, sd = sd_u/sqrt(n_pop)))
c_pred_norm_pop[i] <- mean(rnorm(n_pop, mean = mu_c, sd = sigma_c/sqrt(n_pop)))
c_pred_norm_sam[i] <- mean(rnorm(n_pop,mean = bar_c, sd = sd_c/sqrt(n_pop)))
}
u_pred_norm_mean_pop <- mean(u_pred_norm_pop)
u_pred_norm_ci_pop <- quantile(u_pred_norm_pop, probs = c(0.025,0.975))
u_pred_norm_mean_sam <- mean(u_pred_norm_sam)
u_pred_norm_ci_sam <- quantile(u_pred_norm_sam, probs = c(0.025,0.975))
c_pred_norm_mean_pop <- mean(c_pred_norm_pop)
c_pred_norm_ci_pop <- quantile(c_pred_norm_pop, probs = c(0.025,0.975))
c_pred_norm_mean_sam <- mean(c_pred_norm_sam)
c_pred_norm_ci_sam <- quantile(c_pred_norm_sam, probs = c(0.025,0.975))

set.seed(2345)
u_pred_norm <- rnorm(1000, mean = bar_u, sd = sd_u)
u_pred_norm_mean <- mean(u_pred_norm)
u_pred_norm_sd <- sd(u_pred_norm)
u_pred_norm_ci <- quantile(u_pred_norm, probs = c(0.025,0.975))

u_pred_beta <- rbeta(1000, shape1 = sample_shape1_u, shape2 = sample_shape2_u)
u_pred_beta_mean <- mean(u_pred_beta)
u_pred_beta_sd <- sd(u_pred_beta)
u_pred_beta_ci <- quantile(u_pred_beta, probs = c(0.025,0.975))

c_pred_norm <- rnorm(1000,mean = bar_c, sd = sd_c)
c_pred_norm_mean <- mean(c_pred_norm)
c_pred_norm_sd <- sd(c_pred_norm)
c_pred_norm_ci <- quantile(c_pred_norm, probs = c(0.025,0.975))

c_pred_gamma <- rgamma(1000, shape = sample_shape_c, scale = sample_scale_c)
c_pred_gamma_mean <- mean(c_pred_gamma)
c_pred_gamma_sd <- sd(c_pred_gamma)
c_pred_gamma_ci <- quantile(c_pred_gamma, probs = c(0.025,0.975))

```


:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

library(ggpubr)
ggarrange(gghist1_pop_e,gghist1_pop_c,nrow = 2, ncol = 1)
```

:::

:::{#secondcol}

\small

- QALYs in \myblue \textbf{large} \black samples

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

tbl_pop_u <- cbind.data.frame(mu_u,sigma_u,mu_u_pop_ci[1],mu_u_pop_ci[2],n_pop)
names(tbl_pop_u) <- c("Mean","Sd","CI(low)","CI(high)","size")
kable(tbl_pop_u, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'blue', italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down")

```

\small

- TC in \myblue \textbf{large} \black samples

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

tbl_pop_c <- cbind.data.frame(mu_c,sigma_c,mu_c_pop_ci[1],mu_c_pop_ci[2],n_pop)
names(tbl_pop_c) <- c("Mean","Sd","CI(low)","CI(high)","size")
kable(tbl_pop_c, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'blue', italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::

## Skewness in CE outcomes - an example

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

ggarrange(gghist2_pop_e,gghist2_pop_c,nrow = 2, ncol = 1)
```

:::

:::{#secondcol}

\small

-  \textbf{CLT} in \myblue \textbf{large} \black samples

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

clt_pop_u <- cbind.data.frame(u_pred_norm_mean_pop,sigma_u/sqrt(n_pop),u_pred_norm_ci_pop[1],u_pred_norm_ci_pop[2],n_pop)
names(clt_pop_u) <- c("Mean","Sd","CI(low)","CI(high)","size")
tbl2_pop_u <- rbind.data.frame(tbl_pop_u,clt_pop_u)
kable(tbl2_pop_u, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down")

```

\small

-  \textbf{CLT} \myblue \textbf{large} \black samples

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

clt_pop_c <- cbind.data.frame(c_pred_norm_mean_pop,sigma_c/sqrt(n_pop),c_pred_norm_ci_pop[1],c_pred_norm_ci_pop[2],n_pop)
names(clt_pop_c) <- c("Mean","Sd","CI(low)","CI(high)","size")
tbl2_pop_c <- rbind.data.frame(tbl_pop_c,clt_pop_c)
kable(tbl2_pop_c, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::


## Skewness in CE outcomes - an example

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

ggarrange(gghist2_sam_e,gghist2_sam_c,nrow = 2, ncol = 1)
```

:::

:::{#secondcol}

\small

-  \textbf{CLT} in \myred \textbf{small} \black samples

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

tbl_sam_u <- cbind.data.frame(bar_u,sd_u,mu_u_pop_ci[1],mu_u_pop_ci[2],n_sam)
names(tbl_sam_u) <- c("Mean","Sd","CI(low)","CI(high)","size")
clt_sam_u <- cbind.data.frame(u_pred_norm_mean_sam,sigma_u/sqrt(n_sam),u_pred_norm_ci_sam[1],u_pred_norm_ci_sam[2],n_sam)
names(clt_sam_u) <- c("Mean","Sd","CI(low)","CI(high)","size")
tbl2_sam_u <- rbind.data.frame(tbl_pop_u,tbl_sam_u,clt_sam_u)
kable(tbl2_sam_u, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  row_spec(2, color = 'red', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down")

```

\small

-  \textbf{CLT} in \myred \textbf{small} \black samples

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

tbl_sam_c <- cbind.data.frame(bar_c,sd_c,mu_c_sam_ci[1],mu_c_sam_ci[2],n_sam)
names(tbl_sam_c) <- c("Mean","Sd","CI(low)","CI(high)","size")
clt_sam_c <- cbind.data.frame(c_pred_norm_mean_sam,sigma_c/sqrt(n_sam),c_pred_norm_ci_sam[1],c_pred_norm_ci_sam[2],n_sam)
names(clt_sam_c) <- c("Mean","Sd","CI(low)","CI(high)","size")
tbl2_sam_c <- rbind.data.frame(tbl_pop_c,tbl_sam_c,clt_sam_c)
kable(tbl2_sam_c, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  row_spec(2, color = 'red', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::



## Skewness in CE outcomes - an example

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

ggarrange(gghist3_sam_e,gghist3_sam_c,nrow = 2, ncol = 1)
```

:::

:::{#secondcol}

\small

-  Other distribution (\olive\textbf{Beta}\black) in \myred \textbf{small} \black samples

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

tbl_sam_u_norm <- cbind.data.frame(u_pred_norm_mean,u_pred_norm_sd,u_pred_norm_ci[1],u_pred_norm_ci[2],n_sam)
tbl_sam_u_beta <- cbind.data.frame(u_pred_beta_mean,u_pred_beta_sd,u_pred_beta_ci[1],u_pred_beta_ci[2],n_sam)
names(tbl_sam_u_norm) <- names(tbl_sam_u_beta) <- c("Mean","Sd","CI(low)","CI(high)","size")
tbl3_sam_u <- rbind.data.frame(tbl_pop_u,tbl_sam_u,tbl_sam_u_norm,tbl_sam_u_beta)
kable(tbl3_sam_u, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  row_spec(2, color = 'red', bold = FALSE, italic = TRUE) %>% 
  row_spec(4, color = 'darkgreen', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down")

```

\small

-  Other distribution (\olive\textbf{Gamma}\black) in \myred \textbf{small} \black samples

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

tbl_sam_c_norm <- cbind.data.frame(c_pred_norm_mean,c_pred_norm_sd,c_pred_norm_ci[1],c_pred_norm_ci[2],n_sam)
tbl_sam_c_gamma <- cbind.data.frame(c_pred_gamma_mean,c_pred_gamma_sd,c_pred_gamma_ci[1],c_pred_gamma_ci[2],n_sam)
names(tbl_sam_c_norm) <- names(tbl_sam_c_gamma) <- c("Mean","Sd","CI(low)","CI(high)","size")
tbl3_sam_c <- rbind.data.frame(tbl_pop_c,tbl_sam_c,tbl_sam_c_norm,tbl_sam_c_gamma)
kable(tbl3_sam_c, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  row_spec(2, color = 'red', bold = FALSE, italic = TRUE) %>%
  row_spec(4, color = 'darkgreen', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::

## Skewness - alternative methods

- OLS/SUR *ignoring skewness* and rely on \textbf{CLT/bootstrapping}:

. . .

- \olive\textbf{Generalised Linear Model} \black (GLM):

$$
\begin{aligned}
\text{E}[\text{QALY}_i] &= g_e(\beta_0 + \beta_1\times \text{arm}_i + \beta_2\times u_{i0})^{-1} \\
\text{E}[\text{TC}_i] &= g_c(\alpha_0 + \alpha_1\times \text{arm}_i + \alpha_2\times c_{i0})^{-1} \\
\end{aligned}
$$

. . .


- Choose \myblue \textbf{link functions} \black to model the *expected values*:

  + $g_e(\cdot)^{-1}=\text{logit}()$ \&  $g_c(\cdot)^{-1}=\text{log}()$

. . .


- Choose \myred \textbf{alternative distributions} \black for the *error terms*:

  + $\varepsilon_{ie}\sim \text{Beta}()$ \& $\varepsilon_{ic}\sim \text{Gamma}()$



```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| cache: true

#create dataset by arm
n_sam <- 20
mu_u <- c(0.86,0.9)
sigma_u <- c(0.2,0.2)
tau_u <- (mu_u*(1-mu_u)/sigma_u^2-1)
shape1_u <- mu_u*tau_u
shape2_u <- (1-mu_u)*tau_u
Delta_e <- mu_u[2]-mu_u[1]
mu_c <- c(100,125) 
sigma_c <- c(17,17)
shape_c <- mu_c^2/sigma_c^2
scale_c <- sigma_c^2/mu_c
Delta_c <- mu_c[2]-mu_c[1]
set.seed(2345)
sam0_u <- rbeta(n_sam/2,shape1 = shape1_u[1], shape2 = shape2_u[1])
sam1_u <- rbeta(n_sam/2,shape1 = shape1_u[2], shape2 = shape2_u[2])
sam_u <- c(sam0_u,sam1_u)
base_u <- 0.75 + 0.5*sam_u + rnorm(n_sam, 0, 0.05) 
set.seed(2345)
sam0_c <- rgamma(n_sam/2, shape = shape_c[1], scale = scale_c[1])
sam1_c <- rgamma(n_sam/2, shape = shape_c[2], scale = scale_c[2])
sam_c <- c(sam0_c,sam1_c)
base_c <- 50 + 0.01*sam_c + rnorm(n_sam, 0, 0.5) 
trt <- c(rep("old",n_sam/2),rep("new",n_sam/2))
dataset_sam_skew.df <- data.frame(sam_u,sam_c,base_u,base_c,trt)
names(dataset_sam_skew.df) <- c("QALY","TC","u","c","trt")
dataset_sam_skew.df <- dataset_sam_skew.df[sample(1:nrow(dataset_sam_skew.df)), ]
dataset_sam_skew.df$trt <- factor(dataset_sam_skew.df$trt, levels = c("old","new"))

#analysis ignoring skewness: OLS+boot
library(systemfit)
eq.e <- QALY~trt 
eq.c <- TC~trt
sur <- systemfit(list(QALYreg = eq.e, TCreg = eq.c), method="OLS", data=dataset_sam_skew.df)
#manually derive marginal means and SEs/CIs
X_sur_e <- model.matrix(sur$eq[[1]])
sigma_sur_e.hat <- summary(sur$eq[[1]])$sigma
beta_sur_e.hat <- coef(sur$eq[[1]])
XtX_sur_e.inv <- solve(t(X_sur_e) %*% X_sur_e ) 
contr_sur_e_mu0 <- c(1,0) 
contr_sur_e_mu1 <- c(1,1) 
ctb_sur_e_mu0 <- t(contr_sur_e_mu0) %*% beta_sur_e.hat 
ctb_sur_e_mu1 <- t(contr_sur_e_mu1) %*% beta_sur_e.hat 
std.err_sur_e_mu0 <- sigma_sur_e.hat * sqrt(t(contr_sur_e_mu0) %*% XtX_sur_e.inv %*% contr_sur_e_mu0 )
std.err_sur_e_mu1 <- sigma_sur_e.hat * sqrt(t(contr_sur_e_mu1) %*% XtX_sur_e.inv %*% contr_sur_e_mu1 )
X_sur_c <- model.matrix(sur$eq[[2]])
sigma_sur_c.hat <- summary(sur$eq[[2]])$sigma
beta_sur_c.hat <- coef(sur$eq[[2]])
XtX_sur_c.inv <- solve(t(X_sur_c) %*% X_sur_c) 
contr_sur_c_mu0 <- c(1,0) 
contr_sur_c_mu1 <- c(1,1) 
ctb_sur_c_mu0 <- t(contr_sur_c_mu0) %*% beta_sur_c.hat 
ctb_sur_c_mu1 <- t(contr_sur_c_mu1) %*% beta_sur_c.hat 
std.err_sur_c_mu0 <- sigma_sur_c.hat * sqrt(t(contr_sur_c_mu0) %*% XtX_sur_c.inv %*% contr_sur_c_mu0 )
std.err_sur_c_mu1 <- sigma_sur_c.hat * sqrt(t(contr_sur_c_mu1) %*% XtX_sur_c.inv %*% contr_sur_c_mu1 )
alpha<-0.05
n <- n_sam
sur_e_mu0_l_cl <- ctb_sur_e_mu0 - qt(1-alpha/2,df=n-c(length(beta_sur_e.hat)-1))*std.err_sur_e_mu0
sur_e_mu0_u_cl <- ctb_sur_e_mu0 + qt(1-alpha/2,df=n-c(length(beta_sur_e.hat)-1))*std.err_sur_e_mu0
sur_e_mu1_l_cl <- ctb_sur_e_mu1 - qt(1-alpha/2,df=n-c(length(beta_sur_e.hat)-1))*std.err_sur_e_mu1
sur_e_mu1_u_cl <- ctb_sur_e_mu1 + qt(1-alpha/2,df=n-c(length(beta_sur_e.hat)-1))*std.err_sur_e_mu1
sur_c_mu0_l_cl <- ctb_sur_c_mu0 - qt(1-alpha/2,df=n-c(length(beta_sur_c.hat)-1))*std.err_sur_c_mu0
sur_c_mu0_u_cl <- ctb_sur_c_mu0 + qt(1-alpha/2,df=n-c(length(beta_sur_c.hat)-1))*std.err_sur_c_mu0
sur_c_mu1_l_cl <- ctb_sur_c_mu1 - qt(1-alpha/2,df=n-c(length(beta_sur_c.hat)-1))*std.err_sur_c_mu1
sur_c_mu1_u_cl <- ctb_sur_c_mu1 + qt(1-alpha/2,df=n-c(length(beta_sur_c.hat)-1))*std.err_sur_c_mu1
sur_e.mu0.sum <- cbind.data.frame(ctb_sur_e_mu0,std.err_sur_e_mu0,sur_e_mu0_l_cl,sur_e_mu0_u_cl,sur_e_mu0_u_cl-sur_e_mu0_l_cl)
sur_e.mu1.sum <- cbind.data.frame(ctb_sur_e_mu1,std.err_sur_e_mu1,sur_e_mu1_l_cl,sur_e_mu1_u_cl,sur_e_mu1_u_cl-sur_e_mu1_l_cl)
sur_c.mu0.sum <- cbind.data.frame(ctb_sur_c_mu0,std.err_sur_c_mu0,sur_c_mu0_l_cl,sur_c_mu0_u_cl,sur_c_mu0_u_cl-sur_c_mu0_l_cl)
sur_c.mu1.sum <- cbind.data.frame(ctb_sur_c_mu1,std.err_sur_c_mu1,sur_c_mu1_l_cl,sur_c_mu1_u_cl,sur_c_mu1_u_cl-sur_c_mu1_l_cl)
names(sur_e.mu0.sum) <- names(sur_e.mu1.sum) <- names(sur_c.mu0.sum) <- names(sur_c.mu1.sum) <- c("Est","SE","CI(low)","CI(high)","CI(width)") 

#bootstrap analysis
library(data.table)
library(bootstrap)
dataset.dt <- data.table(dataset_sam_skew.df)
n <- dim(dataset.dt)[1]
B <- 5000
data_ec_b_list <- list()
data_delta_c_b <- data_delta_e_b <- c()
data_mu0_c_b <- data_mu0_e_b <- c()
data_mu1_c_b <- data_mu1_e_b <- c()
for(i in 1:B){
  data_ec_b_list[[i]] <- dataset.dt[sample(.N, n, replace = T)]
  data_lm_c_coef_b <- coef(lm(TC ~ trt, data = data_ec_b_list[[i]]))
  data_lm_e_coef_b <- coef(lm(QALY ~ trt, data = data_ec_b_list[[i]]))
  data_mu0_c_b[i] <- data_lm_c_coef_b["(Intercept)"]+data_lm_c_coef_b["trtnew"]*0
  data_mu1_c_b[i] <- data_lm_c_coef_b["(Intercept)"]+data_lm_c_coef_b["trtnew"]*1
  data_mu0_e_b[i] <- data_lm_e_coef_b["(Intercept)"]+data_lm_e_coef_b["trtnew"]*0
  data_mu1_e_b[i] <- data_lm_e_coef_b["(Intercept)"]+data_lm_e_coef_b["trtnew"]*1  
  data_delta_c_b[i] <- data_lm_c_coef_b["trtnew"]
  data_delta_e_b[i] <- data_lm_e_coef_b["trtnew"]
}
mu0_c_b <- mean(data_mu0_c_b)
mu1_c_b <- mean(data_mu1_c_b)
mu0_e_b <- mean(data_mu0_e_b)
mu1_e_b <- mean(data_mu1_e_b)
delta_c_b <- mean(data_delta_c_b)
delta_e_b <- mean(data_delta_e_b)
sd_mu0_c_b <- sqrt((1/(B-1))*sum((mu0_c_b-data_mu0_c_b)^2))
sd_mu1_c_b <- sqrt((1/(B-1))*sum((mu1_c_b-data_mu1_c_b)^2))
sd_mu0_e_b <- sqrt((1/(B-1))*sum((mu0_e_b-data_mu0_e_b)^2))
sd_mu1_e_b <- sqrt((1/(B-1))*sum((mu1_e_b-data_mu1_e_b)^2))
sd_delta_c_b <- sqrt((1/(B-1))*sum((delta_c_b-data_delta_c_b)^2))
sd_delta_e_b <- sqrt((1/(B-1))*sum((delta_e_b-data_delta_e_b)^2))
alpha <- 0.05
mu0_c_l_perc <- quantile(data_mu0_c_b, probs = alpha/2)
mu0_c_u_perc <- quantile(data_mu0_c_b, probs = (1-alpha/2))
mu1_c_l_perc <- quantile(data_mu1_c_b, probs = alpha/2)
mu1_c_u_perc <- quantile(data_mu1_c_b, probs = (1-alpha/2))
mu0_e_l_perc <- quantile(data_mu0_e_b, probs = alpha/2)
mu0_e_u_perc <- quantile(data_mu0_e_b, probs = (1-alpha/2))
mu1_e_l_perc <- quantile(data_mu1_e_b, probs = alpha/2)
mu1_e_u_perc <- quantile(data_mu1_e_b, probs = (1-alpha/2))
delta_c_l_perc <- quantile(data_delta_c_b, probs = alpha/2)
delta_c_u_perc <- quantile(data_delta_c_b, probs = (1-alpha/2))
delta_e_l_perc <- quantile(data_delta_e_b, probs = alpha/2)
delta_e_u_perc <- quantile(data_delta_e_b, probs = (1-alpha/2))
boot_mu0_c.trt.sum.perc <- round(c(mu0_c_b,sd_mu0_c_b,mu0_c_l_perc,mu0_c_u_perc,mu0_c_u_perc-mu0_c_l_perc),digits=3)
boot_mu1_c.trt.sum.perc <- round(c(mu1_c_b,sd_mu1_c_b,mu1_c_l_perc,mu1_c_u_perc,mu1_c_u_perc-mu1_c_l_perc),digits=3)
boot_mu0_e.trt.sum.perc <- round(c(mu0_e_b,sd_mu0_e_b,mu0_e_l_perc,mu0_e_u_perc,mu0_e_u_perc-mu0_e_l_perc),digits=3)
boot_mu1_e.trt.sum.perc <- round(c(mu1_e_b,sd_mu1_e_b,mu1_e_l_perc,mu1_e_u_perc,mu1_e_u_perc-mu1_e_l_perc),digits=3)
boot_delta_c.trt.sum.perc <- round(c(delta_c_b,sd_delta_c_b,delta_c_l_perc,delta_c_u_perc,delta_c_u_perc-delta_c_l_perc),digits=3)
boot_delta_e.trt.sum.perc <- round(c(delta_e_b,sd_delta_e_b,delta_e_l_perc,delta_e_u_perc,delta_e_u_perc-delta_e_l_perc),digits=3)
names(boot_mu0_c.trt.sum.perc) <- names(boot_mu1_c.trt.sum.perc) <- names(boot_mu0_e.trt.sum.perc) <- names(boot_mu1_e.trt.sum.perc) <- names(boot_delta_c.trt.sum.perc) <- names(boot_delta_e.trt.sum.perc) <- c("Est","SE","CI(low)","CI(high)","CI(width)")
#use BCa correction
bar_mu0_c <- summary(emmeans(lm(TC~trt,data=dataset_sam_skew.df),~trt))$emmean[1]
bar_mu1_c <- summary(emmeans(lm(TC~trt,data=dataset_sam_skew.df),~trt))$emmean[2]
bar_mu0_e <- summary(emmeans(lm(QALY~trt,data=dataset_sam_skew.df),~trt))$emmean[1]
bar_mu1_e <- summary(emmeans(lm(QALY~trt,data=dataset_sam_skew.df),~trt))$emmean[2]
prop_mu0_c_lower <- length(data_mu0_c_b[data_mu0_c_b<bar_mu0_c])/B
prop_mu1_c_lower <- length(data_mu1_c_b[data_mu1_c_b<bar_mu1_c])/B
prop_mu0_e_lower <- length(data_mu0_e_b[data_mu0_e_b<bar_mu0_e])/B
prop_mu1_e_lower <- length(data_mu1_e_b[data_mu1_e_b<bar_mu1_e])/B
z0_mu0_c <- qnorm(prop_mu0_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_mu1_c <- qnorm(prop_mu1_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_mu0_e <- qnorm(prop_mu0_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_mu1_e <- qnorm(prop_mu1_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
bar_delta_c <- coef(lm(TC~trt,data=dataset_sam_skew.df))["trtnew"]
bar_delta_e <- coef(lm(QALY~trt,data=dataset_sam_skew.df))["trtnew"]
prop_delta_c_lower <- length(data_delta_c_b[data_delta_c_b<bar_delta_c])/B
prop_delta_e_lower <- length(data_delta_e_b[data_delta_e_b<bar_delta_e])/B
z0_delta_c <- qnorm(prop_delta_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_delta_e <- qnorm(prop_delta_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
jk_fun <- function(data, incremental = TRUE){
  n <- dim(data)[1]
  if(incremental == TRUE){
    jk_delta_c_i <- jk_delta_e_i <- c()
      for(i in 1:n){
    data_i <- data[-i,]
    jk_delta_c_i[i] <- coef(lm(TC ~ trt, data = data_i))["trtnew"]
    jk_delta_e_i[i] <- coef(lm(QALY ~ trt, data = data_i))["trtnew"]
      }
    jk_est_i <- cbind.data.frame(jk_delta_c_i,jk_delta_e_i)
    names(jk_est_i) <- c("delta_c","delta_e")
  }
  if(incremental == FALSE){
    jk_mu0_c_i <- jk_mu0_e_i <- c()
    jk_mu1_c_i <- jk_mu1_e_i <- c()
      for(i in 1:n){
    data_i <- data[-i,]
    jk_coef_c_i <- coef(lm(TC ~ trt, data = data_i))
    jk_coef_e_i <- coef(lm(QALY ~ trt, data = data_i))
    jk_mu0_c_i[i] <- jk_coef_c_i["(Intercept)"]+jk_coef_c_i["trtnew"]*0
    jk_mu1_c_i[i] <- jk_coef_c_i["(Intercept)"]+jk_coef_c_i["trtnew"]*1
    jk_mu0_e_i[i] <- jk_coef_e_i["(Intercept)"]+jk_coef_e_i["trtnew"]*0
    jk_mu1_e_i[i] <- jk_coef_e_i["(Intercept)"]+jk_coef_e_i["trtnew"]*1
      }
    jk_est_i <- cbind.data.frame(jk_mu0_c_i,jk_mu1_c_i,jk_mu0_e_i,jk_mu1_e_i)
    names(jk_est_i) <- c("mu0_c","mu1_c","mu0_e","mu1_e")
  }
  return(jk_est_i)
}
delta_jk <- jk_fun(dataset.dt, incremental = TRUE)
mu_jk <- jk_fun(dataset.dt, incremental = FALSE)
delta_jk_avg <- apply(delta_jk, 2, mean)
mu_jk_avg <- apply(mu_jk, 2, mean)
a_mu0_c <- sum((mu_jk_avg["mu0_c"] - mu_jk[,"mu0_c"])^3) / (6*(sum((mu_jk_avg["mu0_c"] - mu_jk[,"mu0_c"])^2))^(3/2))
a_mu1_c <- sum((mu_jk_avg["mu1_c"] - mu_jk[,"mu1_c"])^3) / (6*(sum((mu_jk_avg["mu1_c"] - mu_jk[,"mu1_c"])^2))^(3/2))
a_mu0_e <- sum((mu_jk_avg["mu0_e"] - mu_jk[,"mu0_e"])^3) / (6*(sum((mu_jk_avg["mu0_e"] - mu_jk[,"mu0_e"])^2))^(3/2))
a_mu1_e <- sum((mu_jk_avg["mu1_e"] - mu_jk[,"mu1_e"])^3) / (6*(sum((mu_jk_avg["mu1_e"] - mu_jk[,"mu1_e"])^2))^(3/2))
a_delta_c <- sum((delta_jk_avg["delta_c"] - delta_jk[,"delta_c"])^3) / (6*(sum((delta_jk_avg["delta_c"] - delta_jk[,"delta_c"])^2))^(3/2))
a_delta_e <- sum((delta_jk_avg["delta_e"] - delta_jk[,"delta_e"])^3) / (6*(sum((delta_jk_avg["delta_e"] - delta_jk[,"delta_e"])^2))^(3/2))
z_alpha1 <- qnorm(alpha/2, mean = 0, sd = 1, lower.tail = TRUE)
z_alpha2 <- qnorm(1-alpha/2, mean = 0, sd = 1, lower.tail = TRUE)
pl_mu0_c_bca <- pnorm(z0_mu0_c + ((z0_mu0_c+z_alpha1)/(1-a_mu0_c*(z0_mu0_c+z_alpha1))), mean = 0, sd = 1)
pu_mu0_c_bca <- pnorm(z0_mu0_c + ((z0_mu0_c+z_alpha2)/(1-a_mu0_c*(z0_mu0_c+z_alpha2))), mean = 0, sd = 1)
pl_mu1_c_bca <- pnorm(z0_mu1_c + ((z0_mu1_c+z_alpha1)/(1-a_mu1_c*(z0_mu1_c+z_alpha1))), mean = 0, sd = 1)
pu_mu1_c_bca <- pnorm(z0_mu1_c + ((z0_mu1_c+z_alpha2)/(1-a_mu1_c*(z0_mu1_c+z_alpha2))), mean = 0, sd = 1)
pl_mu0_e_bca <- pnorm(z0_mu0_e + ((z0_mu0_e+z_alpha1)/(1-a_mu0_e*(z0_mu0_e+z_alpha1))), mean = 0, sd = 1)
pu_mu0_e_bca <- pnorm(z0_mu0_e + ((z0_mu0_e+z_alpha2)/(1-a_mu0_e*(z0_mu0_e+z_alpha2))), mean = 0, sd = 1)
pl_mu1_e_bca <- pnorm(z0_mu1_e + ((z0_mu1_e+z_alpha1)/(1-a_mu1_e*(z0_mu1_e+z_alpha1))), mean = 0, sd = 1)
pu_mu1_e_bca <- pnorm(z0_mu1_e + ((z0_mu1_e+z_alpha2)/(1-a_mu1_e*(z0_mu1_e+z_alpha2))), mean = 0, sd = 1)
pl_delta_c_bca <- pnorm(z0_delta_c + ((z0_delta_c+z_alpha1)/(1-a_delta_c*(z0_delta_c+z_alpha1))), mean = 0, sd = 1)
pu_delta_c_bca <- pnorm(z0_delta_c + ((z0_delta_c+z_alpha2)/(1-a_delta_c*(z0_delta_c+z_alpha2))), mean = 0, sd = 1)
pl_delta_e_bca <- pnorm(z0_delta_e + ((z0_delta_e+z_alpha1)/(1-a_delta_e*(z0_delta_e+z_alpha1))), mean = 0, sd = 1)
pu_delta_e_bca <- pnorm(z0_delta_e + ((z0_delta_e+z_alpha2)/(1-a_delta_e*(z0_delta_e+z_alpha2))), mean = 0, sd = 1)
mu0_c_l_bca <- quantile(data_mu0_c_b, probs = pl_mu0_c_bca)
mu0_c_u_bca <- quantile(data_mu0_c_b, probs = pu_mu0_c_bca)
mu1_c_l_bca <- quantile(data_mu1_c_b, probs = pl_mu1_c_bca)
mu1_c_u_bca <- quantile(data_mu1_c_b, probs = pu_mu1_c_bca)
mu0_e_l_bca <- quantile(data_mu0_e_b, probs = pl_mu0_e_bca)
mu0_e_u_bca <- quantile(data_mu0_e_b, probs = pu_mu0_e_bca)
mu1_e_l_bca <- quantile(data_mu1_e_b, probs = pl_mu1_e_bca)
mu1_e_u_bca <- quantile(data_mu1_e_b, probs = pu_mu1_e_bca)
delta_c_l_bca <- quantile(data_delta_c_b, probs = pl_delta_c_bca)
delta_c_u_bca <- quantile(data_delta_c_b, probs = pu_delta_c_bca)
delta_e_l_bca <- quantile(data_delta_e_b, probs = pl_delta_e_bca)
delta_e_u_bca <- quantile(data_delta_e_b, probs = pu_delta_e_bca)
boot_mu0_c.trt.sum.bca <- round(c(mu0_c_b,sd_mu0_c_b,mu0_c_l_bca,mu0_c_u_bca,mu0_c_u_bca-mu0_c_l_bca),digits=3)
boot_mu1_c.trt.sum.bca <- round(c(mu1_c_b,sd_mu1_c_b,mu1_c_l_bca,mu1_c_u_bca,mu1_c_u_bca-mu1_c_l_bca),digits=3)
boot_mu0_e.trt.sum.bca <- round(c(mu0_e_b,sd_mu0_e_b,mu0_e_l_bca,mu0_e_u_bca,mu0_e_u_bca-mu0_e_l_bca),digits=3)
boot_mu1_e.trt.sum.bca <- round(c(mu1_e_b,sd_mu1_e_b,mu1_e_l_bca,mu1_e_u_bca,mu1_e_u_bca-mu1_e_l_bca),digits=3)
boot_delta_c.trt.sum.bca <- round(c(delta_c_b,sd_delta_c_b,delta_c_l_bca,delta_c_u_bca,delta_c_u_bca-delta_c_l_bca),digits=3)
boot_delta_e.trt.sum.bca <- round(c(delta_e_b,sd_delta_e_b,delta_e_l_bca,delta_e_u_bca,delta_e_u_bca-delta_e_l_bca),digits=3)
names(boot_mu0_c.trt.sum.bca) <- names(boot_mu1_c.trt.sum.bca) <- names(boot_mu0_e.trt.sum.bca) <- names(boot_mu1_e.trt.sum.bca) <- names(boot_delta_c.trt.sum.bca) <- names(boot_delta_e.trt.sum.bca) <- c("Est","SE","CI(low)","CI(high)","CI(width)")


#analysis taking into account skewness: GLM
library(mfx)
eq.e <- QALY~trt
eq.c <- TC~trt
glm_e <- betareg(eq.e, data = dataset_sam_skew.df,  link = "logit", link.phi = "log", type = "ML")
glm_c <- glm(eq.c, data = dataset_sam_skew.df, family = Gamma(link = "identity"))
glm_e.em <- emmeans(glm_e, ~ trt)
glm_c.em <- emmeans(glm_c, ~ trt)
contrast1_1vs0 <- list("New vs Old" = c(-1, 1))
glm_em_delta_e <- confint(contrast(glm_e.em, contrast1_1vs0))
contrast1_1vs0 <- list("New vs Old" = c(-1, 1))
glm_em_delta_c <- confint(contrast(glm_c.em, contrast1_1vs0))
glm_e.trt.sum <- c(glm_em_delta_e$estimate,glm_em_delta_e$SE,glm_em_delta_e$asymp.LCL,glm_em_delta_e$asymp.UCL,glm_em_delta_e$asymp.UCL-glm_em_delta_e$asymp.LCL)
glm_c.trt.sum <- c(glm_em_delta_c$estimate,glm_em_delta_c$SE,glm_em_delta_c$lower.CL,glm_em_delta_c$upper.CL,glm_em_delta_c$upper.CL-glm_em_delta_c$lower.CL)
names(glm_e.trt.sum) <- c("Est","SE","CI(low)","CI(high)","CI(width)")
glm_e.trt.sum <- round(glm_e.trt.sum,digits=3)
names(glm_c.trt.sum) <- c("Est","SE","CI(low)","CI(high)","CI(width)")
glm_c.trt.sum <- round(glm_c.trt.sum,digits=3)
glm_e.mu0.sum <- c(summary(glm_e.em)$emmean[1],summary(glm_e.em)$SE[1],summary(glm_e.em)$asymp.LCL[1],summary(glm_e.em)$asymp.UCL[1],summary(glm_e.em)$asymp.UCL[1]-summary(glm_e.em)$asymp.LCL[1])
glm_e.mu1.sum <- c(summary(glm_e.em)$emmean[2],summary(glm_e.em)$SE[2],summary(glm_e.em)$asymp.LCL[2],summary(glm_e.em)$asymp.UCL[2],summary(glm_e.em)$asymp.UCL[2]-summary(glm_e.em)$asymp.LCL[2])
glm_c.mu0.sum <- c(summary(glm_c.em)$emmean[1],summary(glm_c.em)$SE[1],summary(glm_c.em)$lower.CL[1],summary(glm_c.em)$upper.CL[1],summary(glm_c.em)$upper.CL[1]-summary(glm_c.em)$lower.CL[1])
glm_c.mu1.sum <- c(summary(glm_c.em)$emmean[2],summary(lm_c.em)$SE[2],summary(glm_c.em)$lower.CL[2],summary(glm_c.em)$upper.CL[2],summary(glm_c.em)$upper.CL[2]-summary(glm_c.em)$lower.CL[2])
names(glm_e.mu0.sum) <- names(glm_e.mu1.sum) <- names(glm_c.mu0.sum) <- names(glm_c.mu1.sum) <- c("Est","SE","CI(low)","CI(high)","CI(width)")

```


## Skewness - alternative methods

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

#combine results in data frame
df.delta.estimate <- c(boot_delta_e.trt.sum.perc["Est"],boot_delta_e.trt.sum.bca["Est"],glm_e.trt.sum["Est"],boot_delta_c.trt.sum.perc["Est"],boot_delta_c.trt.sum.bca["Est"],glm_c.trt.sum["Est"])
df.delta.CI.low <- c(boot_delta_e.trt.sum.perc["CI(low)"],boot_delta_e.trt.sum.bca["CI(low)"],glm_e.trt.sum["CI(low)"],boot_delta_c.trt.sum.perc["CI(low)"],boot_delta_c.trt.sum.bca["CI(low)"],glm_c.trt.sum["CI(low)"])
df.delta.CI.high <- c(boot_delta_e.trt.sum.perc["CI(high)"],boot_delta_e.trt.sum.bca["CI(high)"],glm_e.trt.sum["CI(high)"],boot_delta_c.trt.sum.perc["CI(high)"],boot_delta_c.trt.sum.bca["CI(high)"],glm_c.trt.sum["CI(high)"])
df.delta.method <- c("boot(p)","boot(b)","GLM","boot(p)","boot(b)","GLM")
df.delta.outcome <- c("QALY","QALY","QALY","TC","TC","TC")
df.delta.skew <- cbind.data.frame(df.delta.estimate,df.delta.CI.low,df.delta.CI.high,df.delta.method,df.delta.outcome)
names(df.delta.skew) <- c("Estimate","CI.low","CI.high","method","outcome")

glm_mu_e <- c(boot_mu0_e.trt.sum.perc["Est"], boot_mu0_e.trt.sum.bca["Est"], glm_e.mu0.sum["Est"],boot_mu1_e.trt.sum.perc["Est"], boot_mu1_e.trt.sum.bca["Est"], glm_e.mu1.sum["Est"])
glm_mu_e_lci <- c(boot_mu0_e.trt.sum.perc["CI(low)"], boot_mu0_e.trt.sum.bca["CI(low)"], glm_e.mu0.sum["CI(low)"],boot_mu1_e.trt.sum.perc["CI(low)"], boot_mu1_e.trt.sum.bca["CI(low)"], glm_e.mu1.sum["CI(low)"])
glm_mu_e_uci <- c(boot_mu0_e.trt.sum.perc["CI(high)"], boot_mu0_e.trt.sum.bca["CI(high)"], glm_e.mu0.sum["CI(high)"],boot_mu1_e.trt.sum.perc["CI(high)"], boot_mu1_e.trt.sum.bca["CI(high)"], glm_e.mu1.sum["CI(high)"])
glm.method <- c("boot(p)","boot(b)","GLM","boot(p)","boot(b)","GLM")
glm.arm <- c("Old","Old","Old","New","New","New")
mu_glm.e_gg <- data.frame(cbind(glm_mu_e,glm_mu_e_lci,glm_mu_e_uci,glm.method,glm.arm))
mu_glm.e_gg$glm.arm <- factor(mu_glm.e_gg$glm.arm, levels = c("Old","New"))
mu_glm.e_gg$glm.method <- factor(mu_glm.e_gg$glm.method, levels = c("boot(p)","boot(b)","GLM"))
names(mu_glm.e_gg) <- c("Estimate","CI.low","CI.high","method","arm")


glm_mu_c <- c(boot_mu0_c.trt.sum.perc["Est"], boot_mu0_c.trt.sum.bca["Est"], glm_c.mu0.sum["Est"],boot_mu1_c.trt.sum.perc["Est"], boot_mu1_c.trt.sum.bca["Est"], glm_c.mu1.sum["Est"])
glm_mu_c_lci <- c(boot_mu0_c.trt.sum.perc["CI(low)"], boot_mu0_c.trt.sum.bca["CI(low)"], glm_c.mu0.sum["CI(low)"],boot_mu1_c.trt.sum.perc["CI(low)"], boot_mu1_c.trt.sum.bca["CI(low)"], glm_c.mu1.sum["CI(low)"])
glm_mu_c_uci <- c(boot_mu0_c.trt.sum.perc["CI(high)"], boot_mu0_c.trt.sum.bca["CI(high)"], glm_c.mu0.sum["CI(high)"],boot_mu1_c.trt.sum.perc["CI(high)"], boot_mu1_c.trt.sum.bca["CI(high)"], glm_c.mu1.sum["CI(high)"])
glm.method <- c("boot(p)","boot(b)","GLM","boot(p)","boot(b)","GLM")
glm.arm <- c("Old","Old","Old","New","New","New")
mu_glm.c_gg <- data.frame(cbind(glm_mu_c,glm_mu_c_lci,glm_mu_c_uci,glm.method,glm.arm))
mu_glm.c_gg$glm.arm <- factor(mu_glm.c_gg$glm.arm, levels = c("Old","New"))
mu_glm.c_gg$glm.method <- factor(mu_glm.c_gg$glm.method, levels = c("boot(p)","boot(b)","GLM"))
names(mu_glm.c_gg) <- c("Estimate","CI.low","CI.high","method","arm")


#plot diff estimates
library(ggplot2)
df.delta.skew$Estimate <- as.numeric(df.delta.skew$Estimate)
df.delta.skew$CI.low <- as.numeric(df.delta.skew$CI.low)
df.delta.skew$CI.high <- as.numeric(df.delta.skew$CI.high)
df.delta.skew$method <- factor(df.delta.skew$method, levels = c("boot(p)","boot(b)","GLM"))
df.delta.skew$outcome <- factor(df.delta.skew$outcome, levels = c("QALY","TC"))
df.delta.skew.QALY <- df.delta.skew[df.delta.skew$outcome=="QALY",-5]
df.delta.skew.TC <- df.delta.skew[df.delta.skew$outcome=="TC", -5]
dummy <- data.frame(outcome = c("QALY", "TC"), Z = c(Delta_e, Delta_c))
dummy$outcome <- factor(dummy$outcome, levels = c("QALY","TC"))

ggplot(df.delta.skew, aes(x=factor(method, levels = c("boot(p)","boot(b)","GLM")), y=Estimate, colour=factor(outcome, levels = c("QALY","TC")))) +
  geom_point(position=position_dodge(width=0.4), width=.1, size=2) +
  geom_hline(data = dummy, aes(yintercept = Z)) + 
  geom_errorbar(aes(ymin=CI.low, ymax=CI.high), width=.1, position = position_dodge(width = 0.4)) + facet_wrap(~factor(outcome, levels = c("QALY","TC")), scales = "free") +
  ylab("Mean Difference") + scale_colour_manual(name="outcome", labels=c("QALY","TC"), values=c("purple", "purple")) +
  xlab("") +
  theme_classic() + 
  theme(legend.position = "none",
        text = element_text(size = 10),
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \myblue \textbf{Mean QALY difference} $\Delta_e$ \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(df.delta.skew.QALY, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'purple', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'purple', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

\small

- \myred \textbf{Mean TC difference} $\Delta_c$ \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(df.delta.skew.TC, booktabs = TRUE, row.names = FALSE, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'purple', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'purple', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::


## Skewness - alternative methods

:::: {layout="[0.5, 0.5]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 6
#| fig-height: 6 

#plot QALY estimates
mu_glm.e_gg$Estimate <- round(as.numeric(mu_glm.e_gg$Estimate), digits = 3)
mu_glm.e_gg$CI.low <- round(as.numeric(mu_glm.e_gg$CI.low), digits = 3)
mu_glm.e_gg$CI.high <- round(as.numeric(mu_glm.e_gg$CI.high), digits = 3)

ggplot(mu_glm.e_gg, aes(x=method, y=as.numeric(Estimate), colour=arm)) + 
  geom_point(position=position_dodge(width=0.4), width=.1, size=2) +
geom_errorbar(aes(ymin=as.numeric(CI.low), ymax=as.numeric(CI.high)), width=.1, position = position_dodge(width = 0.4)) +
  scale_colour_manual(name="Arm", labels=c("Old","New"), values=c("red", "blue")) + 
  ylab("Mean QALY") + ylim(0.65,1) +
  geom_hline(yintercept = mu_u[1], col = "red4") +
  geom_hline(yintercept = mu_u[2], col = "blue4") +
  xlab("Method") +
  theme_classic() + 
  theme(legend.position = "right",
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \red \textbf{Mean QALY} for arm = "Old" \black

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(mu_glm.e_gg[c(1:3),1:4], booktabs = TRUE, row.names = F, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'red', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'red', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8)
```

\small 

- \blue \textbf{Mean QALY} for arm = "New" \black

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(mu_glm.e_gg[c(4:6),1:4], booktabs = TRUE, row.names = F, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'blue', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8)
```
:::

::::


## Skewness - alternative methods

:::: {layout="[0.5, 0.5]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 6
#| fig-height: 6 

#plot TC estimates
mu_glm.c_gg$Estimate <- round(as.numeric(mu_glm.c_gg$Estimate), digits = 3)
mu_glm.c_gg$CI.low <- round(as.numeric(mu_glm.c_gg$CI.low), digits = 3)
mu_glm.c_gg$CI.high <- round(as.numeric(mu_glm.c_gg$CI.high), digits = 3)

ggplot(mu_glm.c_gg, aes(x=method, y=as.numeric(Estimate), colour=arm)) + 
  geom_point(position=position_dodge(width=0.4), width=.1, size=2) +
geom_errorbar(aes(ymin=as.numeric(CI.low), ymax=as.numeric(CI.high)), width=.1, position = position_dodge(width = 0.4)) +
  scale_colour_manual(name="Arm", labels=c("Old","New"), values=c("red", "blue")) + 
  ylab("Mean TC") + ylim(80,155) +
  geom_hline(yintercept = mu_c[1], col = "red4") +
  geom_hline(yintercept = mu_c[2], col = "blue4") +
  xlab("Method") +
  theme_classic() + 
  theme(legend.position = "right",
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \red \textbf{Mean TC} for arm = "Old" \black

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(mu_glm.c_gg[c(1:3),1:4], booktabs = TRUE, row.names = F, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'red', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'red', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8)
```

\small 

- \blue \textbf{Mean TC} for arm = "New" \black

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(mu_glm.c_gg[c(4:6),1:4], booktabs = TRUE, row.names = F, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'blue', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8)
```
:::

::::

## Skewness - GLM/bootstrapping

- \olive \textbf{GLM}\black:

  + Allow comparison of means on \myblue \textbf{natural scale} \black 
  + Can handle \myblue \textbf{skewness} \black also in "small" samples
  + The choice of \myred \textbf{distribution} \black and \myred \textbf{link function} \black crucial (not always easy)

. . .

- \olive (non-parametric) \textbf{Bootstrapping}\black:

  + Allow comparison of means on \myblue \textbf{natural scale} \black
  + Does not assume specific \myblue \textbf{distributions} \black
  + Good performance in \myblue \textbf{"large"} \black samples but **poor** in  \myred \textbf{"small"} \black samples
  + \myred \textbf{Different ways} \black to compute CIs (percentile, bias-corrected and accelerated, ...)

. . .

- \olive \textbf{Other approaches}\black:

  + *Bayesian joint models* (Gabrio et al. 2019, )
  + *Hurdle models* (Gabrio et al. 2019, Lambert et al. 2008)


## Clustering of data

- Trial participants may be \olive \textbf{clustered} \black (eg practices/hospitals) and *clusters may be randomised instead of individuals*

  + Typical of **cluster RCTs** where patients in a cluster are randomised to different treatments
  + Individual effects \& costs in the same cluster tend to be more *homogeneous* than those in different clusters

. . .

- Standard methods (eg OLS, SUR \& GLM) assume \olive \textbf{independence} \black of observations but participants in same cluster are likely to be *associated with each other*

  + Ignoring clustering \myred \textbf{underestimates} \black statistical uncertainty (eg variance)
  + may lead to \myred \textbf{incorrect} \black inferences and \myred \textbf{bias} \black the results

. . .

- In CE studies, \olive \textbf{additional challenges} \black need to be addressed:

  + Account for \myred \textbf{correlation} \black between outcomes
  + Deal with \myred \textbf{skewness} \black in both outcomes

## Clustering of data - an example

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| cache: true

#simulate clustered data
#simulate cluster-level means
n <- 100
J <- 26
beta0_c <- 100
beta1_c <- 20
tau_c <- 10*2
trt_j <- c(rep(0,J/2),rep(1,J/2))
set.seed(2345)
phi_cj <- rnorm(J,beta0_c+beta1_c*trt_j, tau_c) 
c_ij <- matrix(NA, nrow = n, ncol = J)
sigma_c <- 15*2
set.seed(2345)
for(j in 1:J){
  c_ij[,j] <- rnorm(n,phi_cj[j],sigma_c)
}
beta0_e <- 0.5
beta1_e <- 0.1
tau_e <- 0.1*2
gamma <- 0 #tau_e/tau_c  gamma*(phi_cj - (beta0_c+beta1_c*trt_j)
set.seed(2345)
phi_ej <- rnorm(J,beta0_e+beta1_e*trt_j, tau_e) 
e_ij <- matrix(NA, nrow = n, ncol = J)
sigma_e <- 0.15*2
rho_ec <- 0.5
theta <- rho_ec*(sigma_e/sigma_c)
set.seed(2345)
for(j in 1:J){
  e_ij[,j] <- rnorm(n,phi_ej[j]+theta*(c_ij[,j]-phi_cj[j]),sigma_e)+rnorm(n,0,0.15)
}
icc_c <- tau_c^2/(tau_c^2+sigma_c^2)
icc_e <- tau_e^2/(tau_e^2+sigma_e^2)
mu0_c <- beta0_c
mu1_c <- beta0_c + beta1_c
mu0_e <- beta0_e
mu1_e <- beta0_e + beta1_e
Delta_c <- beta1_c
Delta_e <- beta1_e
#create dataset
cluster <- rep(1:J, each=n)
TC <- c(c_ij)
QALY <- c(e_ij)
trt <- ifelse(cluster<=13,"old","new")
id <- rep(1:n*J)
data.clus.df <- data.frame(id, QALY,TC,trt,cluster)
data.clus.df$trt <- factor(data.clus.df$trt, levels = c("old","new"))

#fit different methods
# OLS + boot and ignore uncertainty
library(data.table)
library(bootstrap)
set.seed(2345)
dataset.dt <- data.table(data.clus.df)
n <- dim(dataset.dt)[1]
B <- 5000
data_ec_b_list <- list()
data_delta_c_b <- data_delta_e_b <- c()
data_mu0_c_b <- data_mu0_e_b <- c()
data_mu1_c_b <- data_mu1_e_b <- c()
for(i in 1:B){
  data_ec_b_list[[i]] <- dataset.dt[sample(.N, n, replace = T)]
  data_lm_c_coef_b <- coef(lm(TC ~ trt, data = data_ec_b_list[[i]]))
  data_lm_e_coef_b <- coef(lm(QALY ~ trt, data = data_ec_b_list[[i]]))
  data_mu0_c_b[i] <- data_lm_c_coef_b["(Intercept)"]+data_lm_c_coef_b["trtnew"]*0
  data_mu1_c_b[i] <- data_lm_c_coef_b["(Intercept)"]+data_lm_c_coef_b["trtnew"]*1
  data_mu0_e_b[i] <- data_lm_e_coef_b["(Intercept)"]+data_lm_e_coef_b["trtnew"]*0
  data_mu1_e_b[i] <- data_lm_e_coef_b["(Intercept)"]+data_lm_e_coef_b["trtnew"]*1
  data_delta_c_b[i] <- data_lm_c_coef_b["trtnew"]
  data_delta_e_b[i] <- data_lm_e_coef_b["trtnew"]
}
mu0_c_b <- mean(data_mu0_c_b)
mu1_c_b <- mean(data_mu1_c_b)
mu0_e_b <- mean(data_mu0_e_b)
mu1_e_b <- mean(data_mu1_e_b)
delta_c_b <- mean(data_delta_c_b)
delta_e_b <- mean(data_delta_e_b)
sd_mu0_c_b <- sqrt((1/(B-1))*sum((mu0_c_b-data_mu0_c_b)^2))
sd_mu1_c_b <- sqrt((1/(B-1))*sum((mu1_c_b-data_mu1_c_b)^2))
sd_mu0_e_b <- sqrt((1/(B-1))*sum((mu0_e_b-data_mu0_e_b)^2))
sd_mu1_e_b <- sqrt((1/(B-1))*sum((mu1_e_b-data_mu1_e_b)^2))
sd_delta_c_b <- sqrt((1/(B-1))*sum((delta_c_b-data_delta_c_b)^2))
sd_delta_e_b <- sqrt((1/(B-1))*sum((delta_e_b-data_delta_e_b)^2))
alpha <- 0.05
mu0_c_l_perc <- quantile(data_mu0_c_b, probs = alpha/2)
mu0_c_u_perc <- quantile(data_mu0_c_b, probs = (1-alpha/2))
mu1_c_l_perc <- quantile(data_mu1_c_b, probs = alpha/2)
mu1_c_u_perc <- quantile(data_mu1_c_b, probs = (1-alpha/2))
mu0_e_l_perc <- quantile(data_mu0_e_b, probs = alpha/2)
mu0_e_u_perc <- quantile(data_mu0_e_b, probs = (1-alpha/2))
mu1_e_l_perc <- quantile(data_mu1_e_b, probs = alpha/2)
mu1_e_u_perc <- quantile(data_mu1_e_b, probs = (1-alpha/2))
delta_c_l_perc <- quantile(data_delta_c_b, probs = alpha/2)
delta_c_u_perc <- quantile(data_delta_c_b, probs = (1-alpha/2))
delta_e_l_perc <- quantile(data_delta_e_b, probs = alpha/2)
delta_e_u_perc <- quantile(data_delta_e_b, probs = (1-alpha/2))
boot_mu0_c.trt.sum.perc <- round(c(mu0_c_b,sd_mu0_c_b,mu0_c_l_perc,mu0_c_u_perc,mu0_c_u_perc-mu0_c_l_perc),digits=3)
boot_mu1_c.trt.sum.perc <- round(c(mu1_c_b,sd_mu1_c_b,mu1_c_l_perc,mu1_c_u_perc,mu1_c_u_perc-mu1_c_l_perc),digits=3)
boot_mu0_e.trt.sum.perc <- round(c(mu0_e_b,sd_mu0_e_b,mu0_e_l_perc,mu0_e_u_perc,mu0_e_u_perc-mu0_e_l_perc),digits=3)
boot_mu1_e.trt.sum.perc <- round(c(mu1_e_b,sd_mu1_e_b,mu1_e_l_perc,mu1_e_u_perc,mu1_e_u_perc-mu1_e_l_perc),digits=3)
boot_delta_c.trt.sum.perc <- round(c(delta_c_b,sd_delta_c_b,delta_c_l_perc,delta_c_u_perc,delta_c_u_perc-delta_c_l_perc),digits=3)
boot_delta_e.trt.sum.perc <- round(c(delta_e_b,sd_delta_e_b,delta_e_l_perc,delta_e_u_perc,delta_e_u_perc-delta_e_l_perc),digits=3)
names(boot_mu0_c.trt.sum.perc) <- names(boot_mu1_c.trt.sum.perc) <- names(boot_mu0_e.trt.sum.perc) <- names(boot_mu1_e.trt.sum.perc) <- names(boot_delta_c.trt.sum.perc) <- names(boot_delta_e.trt.sum.perc) <- c("Est","SE","CI(low)","CI(high)","CI(width)")
#use BCa correction
bar_mu0_c <- summary(emmeans(lm(TC~trt,data=data.clus.df),~trt))$emmean[1]
bar_mu1_c <- summary(emmeans(lm(TC~trt,data=data.clus.df),~trt))$emmean[2]
bar_mu0_e <- summary(emmeans(lm(QALY~trt,data=data.clus.df),~trt))$emmean[1]
bar_mu1_e <- summary(emmeans(lm(QALY~trt,data=data.clus.df),~trt))$emmean[2]
prop_mu0_c_lower <- length(data_mu0_c_b[data_mu0_c_b<bar_mu0_c])/B
prop_mu1_c_lower <- length(data_mu1_c_b[data_mu1_c_b<bar_mu1_c])/B
prop_mu0_e_lower <- length(data_mu0_e_b[data_mu0_e_b<bar_mu0_e])/B
prop_mu1_e_lower <- length(data_mu1_e_b[data_mu1_e_b<bar_mu1_e])/B
z0_mu0_c <- qnorm(prop_mu0_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_mu1_c <- qnorm(prop_mu1_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_mu0_e <- qnorm(prop_mu0_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_mu1_e <- qnorm(prop_mu1_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
bar_delta_c <- coef(lm(TC~trt,data=data.clus.df))["trtnew"]
bar_delta_e <- coef(lm(QALY~trt,data=data.clus.df))["trtnew"]
prop_delta_c_lower <- length(data_delta_c_b[data_delta_c_b<bar_delta_c])/B
prop_delta_e_lower <- length(data_delta_e_b[data_delta_e_b<bar_delta_e])/B
z0_delta_c <- qnorm(prop_delta_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_delta_e <- qnorm(prop_delta_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
jk_fun <- function(data, incremental = TRUE){
  n <- dim(data)[1]
  if(incremental == TRUE){
    jk_delta_c_i <- jk_delta_e_i <- c()
      for(i in 1:n){
    data_i <- data[-i,]
    jk_delta_c_i[i] <- coef(lm(TC ~ trt, data = data_i))["trtnew"]
    jk_delta_e_i[i] <- coef(lm(QALY ~ trt, data = data_i))["trtnew"]
      }
    jk_est_i <- cbind.data.frame(jk_delta_c_i,jk_delta_e_i)
    names(jk_est_i) <- c("delta_c","delta_e")
  }
  if(incremental == FALSE){
    jk_mu0_c_i <- jk_mu0_e_i <- c()
    jk_mu1_c_i <- jk_mu1_e_i <- c()
      for(i in 1:n){
    data_i <- data[-i,]
    jk_coef_c_i <- coef(lm(TC ~ trt, data = data_i))
    jk_coef_e_i <- coef(lm(QALY ~ trt, data = data_i))
    jk_mu0_c_i[i] <- jk_coef_c_i["(Intercept)"]+jk_coef_c_i["trtnew"]*0
    jk_mu1_c_i[i] <- jk_coef_c_i["(Intercept)"]+jk_coef_c_i["trtnew"]*1
    jk_mu0_e_i[i] <- jk_coef_e_i["(Intercept)"]+jk_coef_e_i["trtnew"]*0
    jk_mu1_e_i[i] <- jk_coef_e_i["(Intercept)"]+jk_coef_e_i["trtnew"]*1
      }
    jk_est_i <- cbind.data.frame(jk_mu0_c_i,jk_mu1_c_i,jk_mu0_e_i,jk_mu1_e_i)
    names(jk_est_i) <- c("mu0_c","mu1_c","mu0_e","mu1_e")
  }
  return(jk_est_i)
}
delta_jk <- jk_fun(dataset.dt, incremental = TRUE)
mu_jk <- jk_fun(dataset.dt, incremental = FALSE)
delta_jk_avg <- apply(delta_jk, 2, mean)
mu_jk_avg <- apply(mu_jk, 2, mean)
a_mu0_c <- sum((mu_jk_avg["mu0_c"] - mu_jk[,"mu0_c"])^3) / (6*(sum((mu_jk_avg["mu0_c"] - mu_jk[,"mu0_c"])^2))^(3/2))
a_mu1_c <- sum((mu_jk_avg["mu1_c"] - mu_jk[,"mu1_c"])^3) / (6*(sum((mu_jk_avg["mu1_c"] - mu_jk[,"mu1_c"])^2))^(3/2))
a_mu0_e <- sum((mu_jk_avg["mu0_e"] - mu_jk[,"mu0_e"])^3) / (6*(sum((mu_jk_avg["mu0_e"] - mu_jk[,"mu0_e"])^2))^(3/2))
a_mu1_e <- sum((mu_jk_avg["mu1_e"] - mu_jk[,"mu1_e"])^3) / (6*(sum((mu_jk_avg["mu1_e"] - mu_jk[,"mu1_e"])^2))^(3/2))
a_delta_c <- sum((delta_jk_avg["delta_c"] - delta_jk[,"delta_c"])^3) / (6*(sum((delta_jk_avg["delta_c"] - delta_jk[,"delta_c"])^2))^(3/2))
a_delta_e <- sum((delta_jk_avg["delta_e"] - delta_jk[,"delta_e"])^3) / (6*(sum((delta_jk_avg["delta_e"] - delta_jk[,"delta_e"])^2))^(3/2))
z_alpha1 <- qnorm(alpha/2, mean = 0, sd = 1, lower.tail = TRUE)
z_alpha2 <- qnorm(1-alpha/2, mean = 0, sd = 1, lower.tail = TRUE)
pl_mu0_c_bca <- pnorm(z0_mu0_c + ((z0_mu0_c+z_alpha1)/(1-a_mu0_c*(z0_mu0_c+z_alpha1))), mean = 0, sd = 1)
pu_mu0_c_bca <- pnorm(z0_mu0_c + ((z0_mu0_c+z_alpha2)/(1-a_mu0_c*(z0_mu0_c+z_alpha2))), mean = 0, sd = 1)
pl_mu1_c_bca <- pnorm(z0_mu1_c + ((z0_mu1_c+z_alpha1)/(1-a_mu1_c*(z0_mu1_c+z_alpha1))), mean = 0, sd = 1)
pu_mu1_c_bca <- pnorm(z0_mu1_c + ((z0_mu1_c+z_alpha2)/(1-a_mu1_c*(z0_mu1_c+z_alpha2))), mean = 0, sd = 1)
pl_mu0_e_bca <- pnorm(z0_mu0_e + ((z0_mu0_e+z_alpha1)/(1-a_mu0_e*(z0_mu0_e+z_alpha1))), mean = 0, sd = 1)
pu_mu0_e_bca <- pnorm(z0_mu0_e + ((z0_mu0_e+z_alpha2)/(1-a_mu0_e*(z0_mu0_e+z_alpha2))), mean = 0, sd = 1)
pl_mu1_e_bca <- pnorm(z0_mu1_e + ((z0_mu1_e+z_alpha1)/(1-a_mu1_e*(z0_mu1_e+z_alpha1))), mean = 0, sd = 1)
pu_mu1_e_bca <- pnorm(z0_mu1_e + ((z0_mu1_e+z_alpha2)/(1-a_mu1_e*(z0_mu1_e+z_alpha2))), mean = 0, sd = 1)
pl_delta_c_bca <- pnorm(z0_delta_c + ((z0_delta_c+z_alpha1)/(1-a_delta_c*(z0_delta_c+z_alpha1))), mean = 0, sd = 1)
pu_delta_c_bca <- pnorm(z0_delta_c + ((z0_delta_c+z_alpha2)/(1-a_delta_c*(z0_delta_c+z_alpha2))), mean = 0, sd = 1)
pl_delta_e_bca <- pnorm(z0_delta_e + ((z0_delta_e+z_alpha1)/(1-a_delta_e*(z0_delta_e+z_alpha1))), mean = 0, sd = 1)
pu_delta_e_bca <- pnorm(z0_delta_e + ((z0_delta_e+z_alpha2)/(1-a_delta_e*(z0_delta_e+z_alpha2))), mean = 0, sd = 1)
mu0_c_l_bca <- quantile(data_mu0_c_b, probs = pl_mu0_c_bca)
mu0_c_u_bca <- quantile(data_mu0_c_b, probs = pu_mu0_c_bca)
mu1_c_l_bca <- quantile(data_mu1_c_b, probs = pl_mu1_c_bca)
mu1_c_u_bca <- quantile(data_mu1_c_b, probs = pu_mu1_c_bca)
mu0_e_l_bca <- quantile(data_mu0_e_b, probs = pl_mu0_e_bca)
mu0_e_u_bca <- quantile(data_mu0_e_b, probs = pu_mu0_e_bca)
mu1_e_l_bca <- quantile(data_mu1_e_b, probs = pl_mu1_e_bca)
mu1_e_u_bca <- quantile(data_mu1_e_b, probs = pu_mu1_e_bca)
delta_c_l_bca <- quantile(data_delta_c_b, probs = pl_delta_c_bca)
delta_c_u_bca <- quantile(data_delta_c_b, probs = pu_delta_c_bca)
delta_e_l_bca <- quantile(data_delta_e_b, probs = pl_delta_e_bca)
delta_e_u_bca <- quantile(data_delta_e_b, probs = pu_delta_e_bca)
boot_mu0_c.trt.sum.bca <- round(c(mu0_c_b,sd_mu0_c_b,mu0_c_l_bca,mu0_c_u_bca,mu0_c_u_bca-mu0_c_l_bca),digits=3)
boot_mu1_c.trt.sum.bca <- round(c(mu1_c_b,sd_mu1_c_b,mu1_c_l_bca,mu1_c_u_bca,mu1_c_u_bca-mu1_c_l_bca),digits=3)
boot_mu0_e.trt.sum.bca <- round(c(mu0_e_b,sd_mu0_e_b,mu0_e_l_bca,mu0_e_u_bca,mu0_e_u_bca-mu0_e_l_bca),digits=3)
boot_mu1_e.trt.sum.bca <- round(c(mu1_e_b,sd_mu1_e_b,mu1_e_l_bca,mu1_e_u_bca,mu1_e_u_bca-mu1_e_l_bca),digits=3)
boot_delta_c.trt.sum.bca <- round(c(delta_c_b,sd_delta_c_b,delta_c_l_bca,delta_c_u_bca,delta_c_u_bca-delta_c_l_bca),digits=3)
boot_delta_e.trt.sum.bca <- round(c(delta_e_b,sd_delta_e_b,delta_e_l_bca,delta_e_u_bca,delta_e_u_bca-delta_e_l_bca),digits=3)
names(boot_mu0_c.trt.sum.bca) <- names(boot_mu1_c.trt.sum.bca) <- names(boot_mu0_e.trt.sum.bca) <- names(boot_mu1_e.trt.sum.bca) <- names(boot_delta_c.trt.sum.bca) <- names(boot_delta_e.trt.sum.bca) <- c("Est","SE","CI(low)","CI(high)","CI(width)")

# MLMs
library(lme4)
library(nlme)
mlm_e <- lme(QALY ~ trt, random = ~1|cluster, data = data.clus.df, method = "REML")
beta_e <- mlm_e$coeff$fixed["trtnew"]            
se_beta_e <- sqrt(diag(mlm_e$varFix))["trtnew"]
beta_e.ci <- intervals(mlm_e)$fixed["trtnew",c("lower","upper")]
alpha<-0.05
beta_e_lci <- beta_e - qt(1-alpha/2,df=J-c(length(mlm_e$coeff$fixed)-1))*se_beta_e
beta_e_uci <- beta_e + qt(1-alpha/2,df=J-c(length(mlm_e$coeff$fixed)-1))*se_beta_e
mlm1em_e <- emmeans(mlm_e, ~ trt)
contrast1_1vs0 <- list("New vs Old" = c(-1, 1))
mlm1em_delta_e <- confint(contrast(mlm1em_e, contrast1_1vs0))
mlm_c <- lme(TC ~ trt, random = ~1|cluster, data = data.clus.df, method = "REML")
beta_c <- mlm_c$coeff$fixed["trtnew"]            
se_beta_c <- sqrt(diag(mlm_c$varFix))["trtnew"]
beta_c.ci <- intervals(mlm_c)$fixed["trtnew",c("lower","upper")]
beta_c_lci <- beta_c - qt(1-alpha/2,df=J-c(length(mlm_c$coeff$fixed)-1))*se_beta_c
beta_c_uci <- beta_c + qt(1-alpha/2,df=J-c(length(mlm_c$coeff$fixed)-1))*se_beta_c
mlm1em_c <- emmeans(mlm_c, ~ trt)
contrast1_1vs0 <- list("New vs Old" = c(-1, 1))
mlm1em_delta_c <- confint(contrast(mlm1em_c, contrast1_1vs0))

#Two-stage bootstrap (TSB) with shrinkage correction
n_tsb <- dim(dataset.dt)[1]
B <- 5000
data_tsb_delta_c_b <- data_tsb_delta_e_b <- c()
data_tsb_mu0_c_b <- data_tsb_mu0_e_b <- c()
data_tsb_mu1_c_b <- data_tsb_mu1_e_b <- c()
for(i in 1:B){
count <- 0 
n.strata <- length(unique(data.clus.df$trt))
shrunk.data <- c()
#set.seed(2345)
while (count<n.strata){
count <- count+1
data1 <- data.frame(data.clus.df[data.clus.df$trt==unique(data.clus.df$trt)[count],])
clus.size <- table(data1$cluster)
cost.x <- tapply(data1$TC,data1$cluster,mean) # calc cluster means
qaly.x <- tapply(data1$QALY,data1$cluster,mean) # calc cluster means
# STANDARDIZE Z: calc b for standardizing z
a <- length(unique(data1$cluster))
if (var(clus.size)==0){
b <- unique(clus.size)
} else {
if (unbalclus=="donner"){
ifelse(warning,print("'average' clus size = Donner"),NA)
n <- sum(clus.size)
b <- (n-(sum(clus.size^2)/n))/(a-1)
} else if (unbalclus=="median"){
ifelse(warning,print("'average' clus size = median"),NA)
b <- median(clus.size)
} else if (unbalclus=="mean"){
ifelse(warning,print("'average' clus size = mean"),NA)
b <- mean(clus.size)
} else {}
} # End of 'else'
# standardize z using cluser means (dfm = deviation from cluster mean)
cost.dfm <- data1$TC-rep(cost.x,times=clus.size)
qaly.dfm <- data1$QALY-rep(qaly.x,times=clus.size)
cost.z <- (cost.dfm)/sqrt(1-1/b)
qaly.z <- (qaly.dfm)/sqrt(1-1/b)
# SHRINKAGE: calc c for shrinking x
cost.ssw <- sum(cost.dfm^2)
qaly.ssw <- sum(qaly.dfm^2)
cost.ssb <- sum((cost.x-mean(cost.x))^2)
qaly.ssb <- sum((qaly.x-mean(qaly.x))^2)
cost.rhs <- a/(a-1) - cost.ssw/(b*(b-1)*cost.ssb)
qaly.rhs <- a/(a-1) - qaly.ssw/(b*(b-1)*qaly.ssb)
ifelse(cost.rhs<0, cost.c<-1, cost.c<-1-sqrt(cost.rhs))
ifelse(qaly.rhs<0, qaly.c<-1, qaly.c<-1-sqrt(qaly.rhs))
## re-calc x
cost.x <- cost.c*mean(data1$TC) + (1-cost.c)*cost.x
qaly.x <- qaly.c*mean(data1$QALY) + (1-qaly.c)*qaly.x
# TWO-STAGE SAMPLING & RE-CONSTRUCT OBS WITH SHRUNKEN MEANS AND STANDARDIZED RESIDUALS
# gen random clus (order) id with replacement
sampled.x.cid <- sample(1:length(unique(data1$cluster)),replace=T)
sampled.z.iid <- sample(1:length(cost.z),sum(clus.size[sampled.x.cid]),replace=T) # chosen ind ids for varying stratum sizes
sampled.cost <- rep(cost.x[sampled.x.cid],times=clus.size[sampled.x.cid])+cost.z[sampled.z.iid]
sampled.qaly <- rep(qaly.x[sampled.x.cid],times=clus.size[sampled.x.cid])+qaly.z[sampled.z.iid]
# bind data from multiple strata together
shrunk.data <- as.data.frame(rbind(shrunk.data,cbind(sampled.cost,sampled.qaly,
rep(unique(data1$cluster)[sampled.x.cid],times=clus.size[sampled.x.cid]),
rep(unique(data.clus.df$trt)[count],times=sum(clus.size[sampled.x.cid])))))
} # end of while
colnames(shrunk.data) <- c("TC","QALY","cluster","trt")
shrunk.data$trt <- ifelse(shrunk.data$trt==1,"old","new")
shrunk.data$trt <- factor(shrunk.data$trt, levels = c("old","new"))
dataset_tsb.dt <- data.table(shrunk.data)
data_tsb_lm_c_coef_b <- coef(lm(TC ~ trt, data = dataset_tsb.dt))
data_tsb_lm_e_coef_b <- coef(lm(QALY ~ trt, data = dataset_tsb.dt))
data_tsb_mu0_c_b[i] <-data_tsb_lm_c_coef_b["(Intercept)"]+data_tsb_lm_c_coef_b["trtnew"]*0
data_tsb_mu1_c_b[i] <-data_tsb_lm_c_coef_b["(Intercept)"]+data_tsb_lm_c_coef_b["trtnew"]*1
data_tsb_mu0_e_b[i] <-data_tsb_lm_e_coef_b["(Intercept)"]+data_tsb_lm_e_coef_b["trtnew"]*0 
data_tsb_mu1_e_b[i] <-data_tsb_lm_e_coef_b["(Intercept)"]+data_tsb_lm_e_coef_b["trtnew"]*1  
data_tsb_delta_c_b[i] <- data_tsb_lm_c_coef_b["trtnew"] 
data_tsb_delta_e_b[i] <- data_tsb_lm_e_coef_b["trtnew"]
}
mu0_tsb_c_b <- mean(data_tsb_mu0_c_b)
mu1_tsb_c_b <- mean(data_tsb_mu1_c_b)
mu0_tsb_e_b <- mean(data_tsb_mu0_e_b)
mu1_tsb_e_b <- mean(data_tsb_mu1_e_b)
delta_tsb_c_b <- mean(data_tsb_delta_c_b)
delta_tsb_e_b <- mean(data_tsb_delta_e_b)
sd_tsb_mu0_c_b <- sqrt((1/(B-1))*sum((mu0_tsb_c_b-data_tsb_mu0_c_b)^2))
sd_tsb_mu1_c_b <- sqrt((1/(B-1))*sum((mu1_tsb_c_b-data_tsb_mu1_c_b)^2))
sd_tsb_mu0_e_b <- sqrt((1/(B-1))*sum((mu0_tsb_e_b-data_tsb_mu0_e_b)^2))
sd_tsb_mu1_e_b <- sqrt((1/(B-1))*sum((mu1_tsb_e_b-data_tsb_mu1_e_b)^2))
sd_tsb_delta_c_b <- sqrt((1/(B-1))*sum((delta_tsb_c_b-data_tsb_delta_c_b)^2))
sd_tsb_delta_e_b <- sqrt((1/(B-1))*sum((delta_tsb_e_b-data_tsb_delta_e_b)^2))
alpha <- 0.05
mu0_tsb_c_l_perc <- quantile(data_tsb_mu0_c_b, probs = alpha/2)
mu0_tsb_c_u_perc <- quantile(data_tsb_mu0_c_b, probs = (1-alpha/2))
mu1_tsb_c_l_perc <- quantile(data_tsb_mu1_c_b, probs = alpha/2)
mu1_tsb_c_u_perc <- quantile(data_tsb_mu1_c_b, probs = (1-alpha/2))
mu0_tsb_e_l_perc <- quantile(data_tsb_mu0_e_b, probs = alpha/2)
mu0_tsb_e_u_perc <- quantile(data_tsb_mu0_e_b, probs = (1-alpha/2))
mu1_tsb_e_l_perc <- quantile(data_tsb_mu1_e_b, probs = alpha/2)
mu1_tsb_e_u_perc <- quantile(data_tsb_mu1_e_b, probs = (1-alpha/2))
delta_tsb_c_l_perc <- quantile(data_tsb_delta_c_b, probs = alpha/2)
delta_tsb_c_u_perc <- quantile(data_tsb_delta_c_b, probs = (1-alpha/2))
delta_tsb_e_l_perc <- quantile(data_tsb_delta_e_b, probs = alpha/2)
delta_tsb_e_u_perc <- quantile(data_tsb_delta_e_b, probs = (1-alpha/2))
boot_tsb_mu0_c.trt.sum.perc <- round(c(mu0_tsb_c_b,sd_tsb_mu0_c_b,mu0_tsb_c_l_perc,mu0_tsb_c_u_perc,mu0_tsb_c_u_perc-mu0_tsb_c_l_perc),digits=3)
boot_tsb_mu1_c.trt.sum.perc <- round(c(mu1_tsb_c_b,sd_tsb_mu1_c_b,mu1_tsb_c_l_perc,mu1_tsb_c_u_perc,mu1_tsb_c_u_perc-mu1_tsb_c_l_perc),digits=3)
boot_tsb_mu0_e.trt.sum.perc <- round(c(mu0_tsb_e_b,sd_tsb_mu0_e_b,mu0_tsb_e_l_perc,mu0_tsb_e_u_perc,mu0_tsb_e_u_perc-mu0_tsb_e_l_perc),digits=3)
boot_tsb_mu1_e.trt.sum.perc <- round(c(mu1_tsb_e_b,sd_tsb_mu1_e_b,mu1_tsb_e_l_perc,mu1_tsb_e_u_perc,mu1_tsb_e_u_perc-mu1_tsb_e_l_perc),digits=3)
boot_tsb_delta_c.trt.sum.perc <- round(c(delta_tsb_c_b,sd_tsb_delta_c_b,delta_tsb_c_l_perc,delta_tsb_c_u_perc,delta_tsb_c_u_perc-delta_tsb_c_l_perc),digits=3)
boot_tsb_delta_e.trt.sum.perc <- round(c(delta_tsb_e_b,sd_tsb_delta_e_b,delta_tsb_e_l_perc,delta_tsb_e_u_perc,delta_tsb_e_u_perc-delta_tsb_e_l_perc),digits=3)
names(boot_tsb_mu0_c.trt.sum.perc) <- names(boot_tsb_mu1_c.trt.sum.perc) <- names(boot_tsb_mu0_e.trt.sum.perc) <- names(boot_tsb_mu1_e.trt.sum.perc) <- names(boot_tsb_delta_c.trt.sum.perc) <- names(boot_tsb_delta_e.trt.sum.perc) <- c("Est","SE","CI(low)","CI(high)","CI(width)")

#use BCa correction
bar_tsb_mu0_c <- summary(emmeans(lm(TC~trt,data=data.clus.df),~trt))$emmean[1]
bar_tsb_mu1_c <- summary(emmeans(lm(TC~trt,data=data.clus.df),~trt))$emmean[2]
bar_tsb_mu0_e <- summary(emmeans(lm(QALY~trt,data=data.clus.df),~trt))$emmean[1]
bar_tsb_mu1_e <- summary(emmeans(lm(QALY~trt,data=data.clus.df),~trt))$emmean[2]
prop_tsb_mu0_c_lower <- length(data_tsb_mu0_c_b[data_tsb_mu0_c_b<bar_tsb_mu0_c])/B
prop_tsb_mu1_c_lower <- length(data_tsb_mu1_c_b[data_tsb_mu1_c_b<bar_tsb_mu1_c])/B
prop_tsb_mu0_e_lower <- length(data_tsb_mu0_e_b[data_tsb_mu0_e_b<bar_tsb_mu0_e])/B
prop_tsb_mu1_e_lower <- length(data_tsb_mu1_e_b[data_tsb_mu1_e_b<bar_tsb_mu1_e])/B
z0_tsb_mu0_c <- qnorm(prop_tsb_mu0_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_tsb_mu1_c <- qnorm(prop_tsb_mu1_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_tsb_mu0_e <- qnorm(prop_tsb_mu0_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_tsb_mu1_e <- qnorm(prop_tsb_mu1_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
bar_tsb_delta_c <- coef(lm(TC~trt,data=data.clus.df))["trtnew"]
bar_tsb_delta_e <- coef(lm(QALY~trt,data=data.clus.df))["trtnew"]
prop_tsb_delta_c_lower <- length(data_delta_c_b[data_tsb_delta_c_b<bar_tsb_delta_c])/B
prop_tsb_delta_e_lower <- length(data_delta_e_b[data_tsb_delta_e_b<bar_tsb_delta_e])/B
z0_tsb_delta_c <- qnorm(prop_tsb_delta_c_lower, mean = 0, sd = 1,lower.tail = TRUE)
z0_tsb_delta_e <- qnorm(prop_tsb_delta_e_lower, mean = 0, sd = 1,lower.tail = TRUE)
jk_tsb_fun <- function(data, incremental = TRUE){
  n <- dim(data)[1]
  if(incremental == TRUE){
    jk_delta_c_i <- jk_delta_e_i <- c()
      for(i in 1:n){
    data_i <- data[-i,]
    jk_delta_c_i[i] <- coef(lm(TC ~ trt, data = data_i))["trtnew"]
    jk_delta_e_i[i] <- coef(lm(QALY ~ trt, data = data_i))["trtnew"]
      }
    jk_est_i <- cbind.data.frame(jk_delta_c_i,jk_delta_e_i)
    names(jk_est_i) <- c("delta_c","delta_e")
  }
  if(incremental == FALSE){
    jk_mu0_c_i <- jk_mu0_e_i <- c()
    jk_mu1_c_i <- jk_mu1_e_i <- c()
      for(i in 1:n){
    data_i <- data[-i,]
    jk_coef_c_i <- coef(lm(TC ~ trt, data = data_i))
    jk_coef_e_i <- coef(lm(QALY ~ trt, data = data_i))
    jk_mu0_c_i[i] <- jk_coef_c_i["(Intercept)"]+jk_coef_c_i["trtnew"]*0
    jk_mu1_c_i[i] <- jk_coef_c_i["(Intercept)"]+jk_coef_c_i["trtnew"]*1
    jk_mu0_e_i[i] <- jk_coef_e_i["(Intercept)"]+jk_coef_e_i["trtnew"]*0
    jk_mu1_e_i[i] <- jk_coef_e_i["(Intercept)"]+jk_coef_e_i["trtnew"]*1
      }
    jk_est_i <- cbind.data.frame(jk_mu0_c_i,jk_mu1_c_i,jk_mu0_e_i,jk_mu1_e_i)
    names(jk_est_i) <- c("mu0_c","mu1_c","mu0_e","mu1_e")
  }
  return(jk_est_i)
}
delta_tsb_jk <- jk_tsb_fun(dataset.dt, incremental = TRUE)
mu_tsb_jk <- jk_tsb_fun(dataset.dt, incremental = FALSE)
delta_tsb_jk_avg <- apply(delta_tsb_jk, 2, mean)
mu_tsb_jk_avg <- apply(mu_tsb_jk, 2, mean)
a_tsb_mu0_c <- sum((mu_tsb_jk_avg["mu0_c"] - mu_tsb_jk[,"mu0_c"])^3) / (6*(sum((mu_tsb_jk_avg["mu0_c"] - mu_tsb_jk[,"mu0_c"])^2))^(3/2))
a_tsb_mu1_c <- sum((mu_jk_avg["mu1_c"] - mu_tsb_jk[,"mu1_c"])^3) / (6*(sum((mu_tsb_jk_avg["mu1_c"] - mu_tsb_jk[,"mu1_c"])^2))^(3/2))
a_tsb_mu0_e <- sum((mu_tsb_jk_avg["mu0_e"] - mu_tsb_jk[,"mu0_e"])^3) / (6*(sum((mu_tsb_jk_avg["mu0_e"] - mu_tsb_jk[,"mu0_e"])^2))^(3/2))
a_tsb_mu1_e <- sum((mu_jk_avg["mu1_e"] - mu_tsb_jk[,"mu1_e"])^3) / (6*(sum((mu_tsb_jk_avg["mu1_e"] - mu_tsb_jk[,"mu1_e"])^2))^(3/2))
a_tsb_delta_c <- sum((delta_tsb_jk_avg["delta_c"] - delta_tsb_jk[,"delta_c"])^3) / (6*(sum((delta_tsb_jk_avg["delta_c"] - delta_tsb_jk[,"delta_c"])^2))^(3/2))
a_tsb_delta_e <- sum((delta_tsb_jk_avg["delta_e"] - delta_tsb_jk[,"delta_e"])^3) / (6*(sum((delta_tsb_jk_avg["delta_e"] - delta_tsb_jk[,"delta_e"])^2))^(3/2))
z_alpha1 <- qnorm(alpha/2, mean = 0, sd = 1, lower.tail = TRUE)
z_alpha2 <- qnorm(1-alpha/2, mean = 0, sd = 1, lower.tail = TRUE)
pl_tsb_mu0_c_bca <- pnorm(z0_tsb_mu0_c + ((z0_tsb_mu0_c+z_alpha1)/(1-a_tsb_mu0_c*(z0_tsb_mu0_c+z_alpha1))), mean = 0, sd = 1)
pu_tsb_mu0_c_bca <- pnorm(z0_tsb_mu0_c + ((z0_tsb_mu0_c+z_alpha2)/(1-a_tsb_mu0_c*(z0_tsb_mu0_c+z_alpha2))), mean = 0, sd = 1)
pl_tsb_mu1_c_bca <- pnorm(z0_tsb_mu1_c + ((z0_tsb_mu1_c+z_alpha1)/(1-a_tsb_mu1_c*(z0_tsb_mu1_c+z_alpha1))), mean = 0, sd = 1)
pu_tsb_mu1_c_bca <- pnorm(z0_tsb_mu1_c + ((z0_tsb_mu1_c+z_alpha2)/(1-a_tsb_mu1_c*(z0_tsb_mu1_c+z_alpha2))), mean = 0, sd = 1)
pl_tsb_mu0_e_bca <- pnorm(z0_tsb_mu0_e + ((z0_tsb_mu0_e+z_alpha1)/(1-a_tsb_mu0_e*(z0_tsb_mu0_e+z_alpha1))), mean = 0, sd = 1)
pu_tsb_mu0_e_bca <- pnorm(z0_tsb_mu0_e + ((z0_tsb_mu0_e+z_alpha2)/(1-a_tsb_mu0_e*(z0_tsb_mu0_e+z_alpha2))), mean = 0, sd = 1)
pl_tsb_mu1_e_bca <- pnorm(z0_tsb_mu1_e + ((z0_tsb_mu1_e+z_alpha1)/(1-a_tsb_mu1_e*(z0_tsb_mu1_e+z_alpha1))), mean = 0, sd = 1)
pu_tsb_mu1_e_bca <- pnorm(z0_tsb_mu1_e + ((z0_tsb_mu1_e+z_alpha2)/(1-a_tsb_mu1_e*(z0_tsb_mu1_e+z_alpha2))), mean = 0, sd = 1)
pl_tsb_delta_c_bca <- pnorm(z0_tsb_delta_c + ((z0_tsb_delta_c+z_alpha1)/(1-a_tsb_delta_c*(z0_tsb_delta_c+z_alpha1))), mean = 0, sd = 1)
pu_tsb_delta_c_bca <- pnorm(z0_tsb_delta_c + ((z0_tsb_delta_c+z_alpha2)/(1-a_tsb_delta_c*(z0_tsb_delta_c+z_alpha2))), mean = 0, sd = 1)
pl_tsb_delta_e_bca <- pnorm(z0_tsb_delta_e + ((z0_tsb_delta_e+z_alpha1)/(1-a_tsb_delta_e*(z0_tsb_delta_e+z_alpha1))), mean = 0, sd = 1)
pu_tsb_delta_e_bca <- pnorm(z0_tsb_delta_e + ((z0_tsb_delta_e+z_alpha2)/(1-a_tsb_delta_e*(z0_tsb_delta_e+z_alpha2))), mean = 0, sd = 1)
mu0_tsb_c_l_bca <- quantile(data_tsb_mu0_c_b, probs = pl_tsb_mu0_c_bca)
mu0_tsb_c_u_bca <- quantile(data_tsb_mu0_c_b, probs = pu_tsb_mu0_c_bca)
mu1_tsb_c_l_bca <- quantile(data_tsb_mu1_c_b, probs = pl_tsb_mu1_c_bca)
mu1_tsb_c_u_bca <- quantile(data_tsb_mu1_c_b, probs = pu_tsb_mu1_c_bca)
mu0_tsb_e_l_bca <- quantile(data_tsb_mu0_e_b, probs = pl_tsb_mu0_e_bca)
mu0_tsb_e_u_bca <- quantile(data_tsb_mu0_e_b, probs = pu_tsb_mu0_e_bca)
mu1_tsb_e_l_bca <- quantile(data_tsb_mu1_e_b, probs = pl_tsb_mu1_e_bca)
mu1_tsb_e_u_bca <- quantile(data_tsb_mu1_e_b, probs = pu_tsb_mu1_e_bca)
delta_tsb_c_l_bca <- quantile(data_tsb_delta_c_b, probs = pl_tsb_delta_c_bca)
delta_tsb_c_u_bca <- quantile(data_tsb_delta_c_b, probs = pu_tsb_delta_c_bca)
delta_tsb_e_l_bca <- quantile(data_tsb_delta_e_b, probs = pl_tsb_delta_e_bca)
delta_tsb_e_u_bca <- quantile(data_tsb_delta_e_b, probs = pu_tsb_delta_e_bca)
boot_tsb_mu0_c.trt.sum.bca <- round(c(mu0_tsb_c_b,sd_tsb_mu0_c_b,mu0_tsb_c_l_bca,mu0_tsb_c_u_bca,mu0_tsb_c_u_bca-mu0_tsb_c_l_bca),digits=3)
boot_tsb_mu1_c.trt.sum.bca <- round(c(mu1_tsb_c_b,sd_tsb_mu1_c_b,mu1_tsb_c_l_bca,mu1_tsb_c_u_bca,mu1_tsb_c_u_bca-mu1_tsb_c_l_bca),digits=3)
boot_tsb_mu0_e.trt.sum.bca <- round(c(mu0_tsb_e_b,sd_tsb_mu0_e_b,mu0_tsb_e_l_bca,mu0_tsb_e_u_bca,mu0_tsb_e_u_bca-mu0_tsb_e_l_bca),digits=3)
boot_tsb_mu1_e.trt.sum.bca <- round(c(mu1_tsb_e_b,sd_tsb_mu1_e_b,mu1_tsb_e_l_bca,mu1_tsb_e_u_bca,mu1_tsb_e_u_bca-mu1_tsb_e_l_bca),digits=3)
boot_tsb_delta_c.trt.sum.bca <- round(c(delta_tsb_c_b,sd_tsb_delta_c_b,delta_tsb_c_l_bca,delta_tsb_c_u_bca,delta_tsb_c_u_bca-delta_tsb_c_l_bca),digits=3)
boot_tsb_delta_e.trt.sum.bca <- round(c(delta_tsb_e_b,sd_tsb_delta_e_b,delta_tsb_e_l_bca,delta_tsb_e_u_bca,delta_tsb_e_u_bca-delta_tsb_e_l_bca),digits=3)
names(boot_tsb_mu0_c.trt.sum.bca) <- names(boot_tsb_mu1_c.trt.sum.bca) <- names(boot_tsb_mu0_e.trt.sum.bca) <- names(boot_tsb_mu1_e.trt.sum.bca) <- names(boot_tsb_delta_c.trt.sum.bca) <- names(boot_tsb_delta_e.trt.sum.bca) <- c("Est","SE","CI(low)","CI(high)","CI(width)")

```

:::: {layout="[0.5, 0.5]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4
#| fig-height: 4 

#plot data by cluster (a few clusters)
data.clus.df.gg <- data.clus.df[data.clus.df$cluster %in% c(1:3,24:26),]
data.clus.df.gg$cluster <- ifelse(data.clus.df.gg$cluster=="24","4",data.clus.df.gg$cluster)
data.clus.df.gg$cluster <- ifelse(data.clus.df.gg$cluster=="25","5",data.clus.df.gg$cluster)
data.clus.df.gg$cluster <- ifelse(data.clus.df.gg$cluster=="26","6",data.clus.df.gg$cluster)
data.clus.df.gg$cluster <- factor(data.clus.df.gg$cluster)

ggplot(data.clus.df.gg, aes(x=QALY, y=TC, colour=factor(cluster))) +
  geom_point(position=position_dodge(width=0.4), width=.1, size=1) +
  ylab("QALY") + scale_colour_manual(name="cluster", labels=c("1","2","3","4","5","6"), values=c("red", "red","red","blue","blue","blue")) + 
  facet_wrap(~factor(cluster, levels = c("1","2","3","4","5","6")), scales = "free") +
  xlab("TC") +
  theme_classic() + 
  theme(legend.position = "none",
        text = element_text(size = 10),
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))
```

:::

:::{#secondcol}

\small

- Costs \& effects across \olive \textbf{clusters} \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

#compute all and cluster specific stats
clus_all_e_bar <- tapply(data.clus.df.gg$QALY, data.clus.df.gg$trt, mean)
clus_all_e_sd <- tapply(data.clus.df.gg$QALY, data.clus.df.gg$trt, sd)
clus_all_c_bar <- tapply(data.clus.df.gg$TC, data.clus.df.gg$trt, mean)
clus_all_c_sd <- tapply(data.clus.df.gg$TC, data.clus.df.gg$trt, sd)
clus_e_bar <- tapply(data.clus.df.gg$QALY, data.clus.df.gg$cluster, mean)
clus_e_sd <- tapply(data.clus.df.gg$QALY, data.clus.df.gg$cluster, sd)
clus_c_bar <- tapply(data.clus.df.gg$TC, data.clus.df.gg$cluster, mean)
clus_c_sd <- tapply(data.clus.df.gg$TC, data.clus.df.gg$cluster, sd)
clus_cid <- rep(1:6)
clus_trt <- c(rep("Old",3),rep("New",3))
all_trt <- c("Old","New")
sum_ec_clus_gg <- data.frame(clus_e_bar,clus_e_sd,clus_c_bar,clus_c_sd,clus_trt)
sum_ec_all_gg <- data.frame(clus_all_e_bar,clus_all_e_sd,clus_all_c_bar,clus_all_c_sd,all_trt)
names(sum_ec_clus_gg) <- names(sum_ec_all_gg) <-  c("mean(e)","sd(e)","mean(c)","sd(c)","arm")

kable(sum_ec_all_gg, booktabs = TRUE, digits = 3, row.names = FALSE) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'red', bold = FALSE, italic = TRUE) %>% 
  row_spec(2, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1:4, bold = TRUE, italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6) 
```


\small

- Costs \& effects by \olive \textbf{cluster} \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(sum_ec_clus_gg, booktabs = TRUE, digits = 3, row.names = FALSE) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'red', bold = FALSE, italic = TRUE) %>% 
  row_spec(4:6, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1:4, bold = TRUE, italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6) 
```

:::

::::


## Clustering - alternative methods

- \olive\textbf{Multilevel Model} \black (MLM):

1. Add \textbf{"random" terms} $(u_{je},u_{jc})$ to OLS/SUR model to capture differences between $j$-th cluster QALY/TC means from overall means in each arm
  
$$
\begin{aligned}
\text{QALY}_{ij} &= \beta_0 + \beta_1\times \text{arm}_j + u_{je} + \varepsilon_{ije} \\
\text{TC}_{ij} &= \alpha_0 + \alpha_1\times \text{arm}_j + u_{jc} + \varepsilon_{ijc} \\
\end{aligned}
$$

. . .


2. Model cluster-specific error terms using some *distribution* (eg Normal) and **link them** through the parameter $\psi$ (often assumed $0$)

$$
\begin{aligned}
\begin{pmatrix}
u_{je}\\
u_{jc}\\
\end{pmatrix} &\sim  \text{Normal}
\begin{bmatrix}
\begin{pmatrix}
0\\
0
\end{pmatrix}\!\!,&
\begin{pmatrix}
\tau^2_e & \psi\tau_e\tau_c\\
\psi\tau_c\tau_e & \tau^2_c
\end{pmatrix}
\end{bmatrix}
\end{aligned}
$$

## Clustering - alternative methods

- \olive (non-parametric) \textbf{Two-Stage Bootstrap} \black (TSB):

```{=latex}
\begin{enumerate}
\item[1] \textbf{Two-stage routine} to account for data clustering:
\begin{itemize}\small
\item[-] First \olive \textbf{sample clusters} \black then \olive \textbf{individuals} \black within each resampled cluster
\item[-] Analyse CE outcomes and derive $(\hat{\beta},\hat{\alpha})^b$ --> $(\Delta_e,\Delta_c)^b$
\item[-] Iterate the process a \textit{sufficiently} large number of times (B) 
\item[-] Use the estimates $(\Delta_e,\Delta_c)^b$ to quantify uncertainty (eg obtain CIs)
\end{itemize}
\end{enumerate}
```

. . .


```{=latex}
\begin{enumerate}
\item[2] Apply \textbf{"shrinkage"} correction to avoid \myred \textbf{overestimation} \black of variance
\begin{itemize}\small
\item[-] Before any resampling, \textbf{cluster means} are \textit{shrunk} and \textbf{individual residuals} estimated from cluster means
\item[-] Sample \olive \textbf{shrunken cluster means} \black then \olive \textbf{individual residuals} \black
\item[-] Combine shrunken means and residuals to obtain bootstrap dataset
\end{itemize}
\end{enumerate}
```


## Clustering - alternative methods

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

#combine results in data frame
df.clus.delta.estimate <- c(boot_delta_e.trt.sum.bca["Est"],mlm1em_delta_e$estimate,boot_tsb_delta_e.trt.sum.bca["Est"],boot_delta_c.trt.sum.bca["Est"],mlm1em_delta_c$estimate,boot_tsb_delta_c.trt.sum.bca["Est"])
df.clus.delta.CI.low <- c(boot_delta_e.trt.sum.bca["CI(low)"],mlm1em_delta_e$lower.CL,boot_tsb_delta_e.trt.sum.bca["CI(low)"],boot_delta_c.trt.sum.bca["CI(low)"],mlm1em_delta_c$lower.CL,boot_tsb_delta_c.trt.sum.bca["CI(low)"])  
df.clus.delta.CI.high <- c(boot_delta_e.trt.sum.bca["CI(high)"],mlm1em_delta_e$upper.CL,boot_tsb_delta_e.trt.sum.bca["CI(high)"],boot_delta_c.trt.sum.bca["CI(high)"],mlm1em_delta_c$upper.CL,boot_tsb_delta_c.trt.sum.bca["CI(high)"])  
df.clus.delta.method <- c("boot(bca)","MLM","TSB(bca)","boot(bca)","MLM","TSB(bca)")
df.clus.delta.outcome <- c("QALY","QALY","QALY","TC","TC","TC")
df.delta.clus <- cbind.data.frame(df.clus.delta.estimate,df.clus.delta.CI.low,df.clus.delta.CI.high,df.clus.delta.method,df.clus.delta.outcome)
names(df.delta.clus) <- c("Estimate","CI.low","CI.high","method","outcome")

#plot diff estimates
df.delta.clus$Estimate <- as.numeric(df.delta.clus$Estimate)
df.delta.clus$CI.low <- as.numeric(df.delta.clus$CI.low)
df.delta.clus$CI.high <- as.numeric(df.delta.clus$CI.high)
df.delta.clus$method <- factor(df.delta.clus$method, levels = c("boot(bca)","MLM","TSB(bca)"))
df.delta.clus$outcome <- factor(df.delta.clus$outcome, levels = c("QALY","TC"))
df.delta.clus.QALY <- df.delta.clus[df.delta.clus$outcome=="QALY",-5]
df.delta.clus.TC <- df.delta.clus[df.delta.clus$outcome=="TC", -5]

ggplot(df.delta.clus, aes(x=factor(method, levels = c("boot(bca)","MLM","TSB(bca)")), y=Estimate, colour=factor(outcome, levels = c("QALY","TC")))) +
  geom_point(position=position_dodge(width=0.4), width=.1, size=2) +
  geom_errorbar(aes(ymin=CI.low, ymax=CI.high), width=.1, position = position_dodge(width = 0.4)) + facet_wrap(~factor(outcome, levels = c("QALY","TC")), scales = "free") +
  ylab("Mean Difference") + scale_colour_manual(name="outcome", labels=c("QALY","TC"), values=c("purple", "purple")) +
  xlab("") +
  theme_classic() + 
  theme(legend.position = "none",
        text = element_text(size = 10),
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \myblue \textbf{Mean QALY difference} $\Delta_e$ \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(df.delta.clus.QALY, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'purple', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'purple', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

\small

- \myred \textbf{Mean TC difference} $\Delta_c$ \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(df.delta.clus.TC, booktabs = TRUE, row.names = FALSE, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'purple', bold = FALSE, italic = TRUE) %>% 
  column_spec(2:3, bold = TRUE, color = 'purple', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::

## Clustering - alternative methods

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

#combine results in data frame
df.clus.mu.estimate <- c(boot_mu0_e.trt.sum.bca["Est"],summary(mlm1em_e)$emmean[1],boot_tsb_mu0_e.trt.sum.bca["Est"],boot_mu0_c.trt.sum.bca["Est"],summary(mlm1em_c)$emmean[1],boot_tsb_mu0_c.trt.sum.bca["Est"],boot_mu1_e.trt.sum.bca["Est"],summary(mlm1em_e)$emmean[2],boot_tsb_mu1_e.trt.sum.bca["Est"],boot_mu1_c.trt.sum.bca["Est"],summary(mlm1em_c)$emmean[2],boot_tsb_mu1_c.trt.sum.bca["Est"])
df.clus.mu.CI.low <- c(boot_mu0_e.trt.sum.bca["CI(low)"],summary(mlm1em_e)$lower.CL[1],boot_tsb_mu0_e.trt.sum.bca["CI(low)"],boot_mu0_c.trt.sum.bca["CI(low)"],summary(mlm1em_c)$lower.CL[1],boot_tsb_mu0_c.trt.sum.bca["CI(low)"],boot_mu1_e.trt.sum.bca["CI(low)"],summary(mlm1em_e)$lower.CL[2],boot_tsb_mu1_e.trt.sum.bca["CI(low)"],boot_mu1_c.trt.sum.bca["CI(low)"],summary(mlm1em_c)$lower.CL[2],boot_tsb_mu1_c.trt.sum.bca["CI(low)"])
df.clus.mu.CI.high <- c(boot_mu0_e.trt.sum.bca["CI(high)"],summary(mlm1em_e)$upper.CL[1],boot_tsb_mu0_e.trt.sum.bca["CI(high)"],boot_mu0_c.trt.sum.bca["CI(high)"],summary(mlm1em_c)$upper.CL[1],boot_tsb_mu0_c.trt.sum.bca["CI(high)"],boot_mu1_e.trt.sum.bca["CI(high)"],summary(mlm1em_e)$upper.CL[2],boot_tsb_mu1_e.trt.sum.bca["CI(high)"],boot_mu1_c.trt.sum.bca["CI(high)"],summary(mlm1em_c)$upper.CL[2],boot_tsb_mu1_c.trt.sum.bca["CI(high)"])  
df.clus.mu.method <- c("boot(bca)","MLM","TSB(bca)","boot(bca)","MLM","TSB(bca)",
                       "boot(bca)","MLM","TSB(bca)","boot(bca)","MLM","TSB(bca)")
df.clus.mu.outcome <- c("QALY","QALY","QALY","TC","TC","TC",
                        "QALY","QALY","QALY","TC","TC","TC")
df.clus.mu.arm <- c(rep("Old",6),rep("New",6))
df.mu.clus <- cbind.data.frame(df.clus.mu.estimate,df.clus.mu.CI.low,df.clus.mu.CI.high,df.clus.mu.method,df.clus.mu.outcome,df.clus.mu.arm)
names(df.mu.clus) <- c("Estimate","CI.low","CI.high","method","outcome","arm")

#plot diff estimates
df.mu.clus$Estimate <- as.numeric(df.mu.clus$Estimate)
df.mu.clus$CI.low <- as.numeric(df.mu.clus$CI.low)
df.mu.clus$CI.high <- as.numeric(df.mu.clus$CI.high)
df.mu.clus$method <- factor(df.mu.clus$method, levels = c("boot(bca)","MLM","TSB(bca)"))
df.mu.clus$outcome <- factor(df.mu.clus$outcome, levels = c("QALY","TC"))
df.mu.clus$arm <- factor(df.mu.clus$arm, levels = c("Old","New"))
df.mu.clus.QALY <- df.mu.clus[df.mu.clus$outcome=="QALY",-5]
df.mu.clus.TC <- df.mu.clus[df.mu.clus$outcome=="TC", -5]

ggplot(df.mu.clus.QALY, aes(x=factor(method, levels = c("boot(bca)","MLM","TSB(bca)")), y=Estimate, colour=arm)) +
  geom_point(position=position_dodge(width=0.4), width=.1, size=2) +
  geom_errorbar(aes(ymin=CI.low, ymax=CI.high), width=.1, position = position_dodge(width = 0.4)) +
  ylab("Mean QALY") + scale_colour_manual(name="Arm", labels=c("Old","New"), values=c("red", "blue")) +
  xlab("Method") +
  theme_classic() + 
  theme(legend.position = "right",
        text = element_text(size = 10),
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \myred \textbf{Mean QALY} for arm = "Old" \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

df.mu.clus.QALY.old <- df.mu.clus.QALY[df.mu.clus.QALY$arm=="Old",]
kable(df.mu.clus.QALY.old, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'red', bold = FALSE, italic = TRUE) %>% 
  column_spec(2:3, bold = TRUE, color = 'red', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

\small

- \myblue \textbf{Mean QALY} for arm = "New" \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

df.mu.clus.QALY.new <- df.mu.clus.QALY[df.mu.clus.QALY$arm=="New",]
kable(df.mu.clus.QALY.new, booktabs = TRUE, row.names = FALSE, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(2:3, bold = TRUE, color = 'blue', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::


## Clustering - alternative methods

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

ggplot(df.mu.clus.TC, aes(x=factor(method, levels = c("boot(bca)","MLM","TSB(bca)")), y=Estimate, colour=arm)) +
  geom_point(position=position_dodge(width=0.4), width=.1, size=2) +
  geom_errorbar(aes(ymin=CI.low, ymax=CI.high), width=.1, position = position_dodge(width = 0.4)) +
  ylab("Mean TC") + scale_colour_manual(name="Arm", labels=c("Old","New"), values=c("red", "blue")) +
  xlab("Method") +
  theme_classic() + 
  theme(legend.position = "right",
        text = element_text(size = 10),
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \myred \textbf{Mean TC} for arm = "Old" \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

df.mu.clus.TC.old <- df.mu.clus.TC[df.mu.clus.TC$arm=="Old",]
kable(df.mu.clus.TC.old, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'red', bold = FALSE, italic = TRUE) %>% 
  column_spec(2:3, bold = TRUE, color = 'red', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

\small

- \myblue \textbf{Mean TC} for arm = "New" \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

df.mu.clus.TC.new <- df.mu.clus.TC[df.mu.clus.TC$arm=="New",]
kable(df.mu.clus.TC.new, booktabs = TRUE, row.names = FALSE, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(2:3, bold = TRUE, color = 'blue', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::

## Clustering - MLM/TSB

- \olive \textbf{MLM}\black:

  + Extends standard OLS/SUR framework to deal with \myblue \textbf{clustering} \black
  + Good performance except with \myred \textbf{small samples} \black \& \myred \textbf{numbers of clusters} \black
  + Difficult to implement unless assuming \myred \textbf{independence} \black between outcomes and Normality

. . .

- \olive (non-parametric) \textbf{TSB}\black:

  + Standard bootstrap **ignores** clustering and \myred \textbf{underestimates} \black uncertainty
  + \myblue \textbf{Two-stage procedure} \black needed to account for clustering
  + Can be combined with SUR to deal with CE correlation
  + \myblue \textbf{Shrinkage correction} \black needed to avoid overestimation

. . .

- \olive \textbf{Other approaches}\black:

  + *Bayesian hierarchical models* (Grieve et al. 2010, Gomes et al. 2012)


## Missing data

\small
- Missing CE values almost \olive \textbf{inevitably} \black occur:

  + A single missing CE *component* leads to a missing *QALY/TC* value
  + Need to accept \myred \textbf{inherent uncertainty} \black in analysis
  + Any method is based on some \myred \textbf{untestable assumptions} \black

. . .

- Express assumptions as \myblue \textbf{missingness mechanism} \black (Little et al. 2019):

  + **Missing Completely At Random** (MCAR): occur *randomly*
  + **Missing At Random** (MAR): due to some *observed variables*
  + **Missing Not At Random** (MNAR): due to some *unobserved variables*

. . .

- Method should be *aligned* with the \olive \textbf{selected assumptions} \black:

  + Avoid methods with \myred \textbf{unrealistic} \black assumptions (eg mean imputation)
  + Define a *base-case* scenario (eg MAR)
  + Assess **sensitivity** of results to some *departures*


## Missing data - an example

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| cache: false

#simulate data and missing under different mechanisms

set.seed(2345)
n_full <- 250
mu_x <- 0.5
sd_x <- 0.15
x_data <- rnorm(n_full, mu_x, sd_x)
p_trt <- 0.5
trt_data <- rbinom(n_full, p_trt, size = 1)
beta0_data <- 0.2
beta1_data <- 0.15
beta2_data <- 1
y_data <- beta0_data + beta1_data*trt_data + beta2_data*x_data + rnorm(n_full, 0, 0.1)
full.df <- data.frame(y_data,trt_data,x_data)
names(full.df) <- c("QALY","trt","u")
full.df$trt <- ifelse(full.df$trt==0,"old","new")
full.df$trt <- factor(full.df$trt, levels = c("old","new"))
lm_full_data <- lm(QALY ~ trt + u, data = full.df)
lm_delta_data <- summary(lm_full_data)$coefficients["trtnew","Estimate"]
lm_se_delta_data <- summary(lm_full_data)$coefficients["trtnew","Std. Error"]
lm_ci_delta_data <- confint(lm_full_data)["trtnew",]
lm_delta_data.sum <- c(lm_delta_data,lm_se_delta_data,lm_ci_delta_data)
names(lm_delta_data.sum) <- c("Estimate","SE","lower.CL","upper.CL")
library(emmeans)
em_lm_mu_data <- emmeans(lm_full_data, ~ trt)

#introduce MCAR missingness
set.seed(2345)
eta0_mcar <- 0.25
eta_1_mcar <- 0
eta_2_mcar <- 0
eta_3_mcar <- 0
p_mcar <- eta0_mcar + eta_1_mcar*full.df$u + eta_2_mcar*full.df$QALY + eta_3_mcar*as.numeric(full.df$trt)
m_mcar <- rbinom(n_full, p_mcar, size = 1)
full.mcar <- full.df
full.mcar$m <- m_mcar
full.mcar$QALY_obs <- ifelse(full.mcar$m==0,full.mcar$QALY,NA)
full.mcar$QALY_mis <- ifelse(full.mcar$m==1,full.mcar$QALY,NA)
lm_mcar_data <- lm(QALY_obs ~ trt + u, data = full.mcar, na.action = na.omit)
lm_delta_data.mcar <- summary(lm_mcar_data)$coefficients["trtnew","Estimate"]
lm_se_delta_data.mcar <- summary(lm_mcar_data)$coefficients["trtnew","Std. Error"]
lm_ci_delta_data.mcar <- confint(lm_mcar_data)["trtnew",]
lm_delta_data.mcar.sum <- c(lm_delta_data.mcar,lm_se_delta_data.mcar,lm_ci_delta_data.mcar)
names(lm_delta_data.mcar.sum) <- c("Estimate","SE","lower.CL","upper.CL")
em_lm_mu_data.mcar <- emmeans(lm_mcar_data, ~ trt)

#introduce MAR missingness given u
library(boot)
set.seed(2345)
eta0_mar <- -9
eta_1_mar <- 14.5
eta_2_mar <- 0
eta_3_mar <- 0
p_mar <- inv.logit(eta0_mar + eta_1_mar*full.df$u + eta_2_mar*full.df$QALY + eta_3_mar*as.numeric(full.df$trt))
m_mar <- rbinom(n_full, p_mar, size = 1)
full.mar <- full.df
full.mar$m <- m_mar
full.mar$QALY_obs <- ifelse(full.mar$m==0,full.mar$QALY,NA)
full.mar$QALY_mis <- ifelse(full.mar$m==1,full.mar$QALY,NA)
lm1_mar_data <- lm(QALY_obs ~ trt, data = full.mar, na.action = na.omit)
lm2_mar_data <- lm(QALY_obs ~ trt + u, data = full.mar, na.action = na.omit)
lm1_delta_data.mar <- summary(lm1_mar_data)$coefficients["trtnew","Estimate"]
lm1_se_delta_data.mar <- summary(lm1_mar_data)$coefficients["trtnew","Std. Error"]
lm1_ci_delta_data.mar <- confint(lm1_mar_data)["trtnew",]
lm1_delta_data.mar.sum <- c(lm1_delta_data.mar,lm1_se_delta_data.mar,lm1_ci_delta_data.mar)
names(lm1_delta_data.mar.sum) <- c("Estimate","SE","lower.CL","upper.CL")
em_lm1_mu_data.mar <- emmeans(lm1_mar_data, ~ trt)
lm2_delta_data.mar <- summary(lm2_mar_data)$coefficients["trtnew","Estimate"]
lm2_se_delta_data.mar <- summary(lm2_mar_data)$coefficients["trtnew","Std. Error"]
lm2_ci_delta_data.mar <- confint(lm2_mar_data)["trtnew",]
lm2_delta_data.mar.sum <- c(lm2_delta_data.mar,lm2_se_delta_data.mar,lm2_ci_delta_data.mar)
names(lm2_delta_data.mar.sum) <- c("Estimate","SE","lower.CL","upper.CL")
em_lm2_mu_data.mar <- emmeans(lm2_mar_data, ~ trt)

#introduce MNAR missingness given QALY mis
set.seed(2345)
eta0_mnar <- -14
eta_1_mnar <- 0
eta_2_mnar <- 15.5
eta_3_mnar <- 0
p_mnar <- inv.logit(eta0_mnar + eta_1_mnar*full.df$u + eta_2_mnar*full.df$QALY + eta_3_mnar*as.numeric(full.df$trt))
m_mnar <- rbinom(n_full, p_mnar, size = 1)
full.mnar <- full.df
full.mnar$m <- m_mnar
full.mnar$QALY_obs <- ifelse(full.mnar$m==0,full.mnar$QALY,NA)
full.mnar$QALY_mis <- ifelse(full.mnar$m==1,full.mnar$QALY,NA)
lm_mnar_data <- lm(QALY_obs ~ trt + u, data = full.mnar, na.action = na.omit)
lm_delta_data.mnar <- summary(lm_mnar_data)$coefficients["trtnew","Estimate"]
lm_se_delta_data.mnar <- summary(lm_mnar_data)$coefficients["trtnew","Std. Error"]
lm_ci_delta_data.mnar <- confint(lm_mnar_data)["trtnew",]
lm_delta_data.mnar.sum <- c(lm_delta_data.mnar,lm_se_delta_data.mnar,lm_ci_delta_data.mnar)
names(lm_delta_data.mnar.sum) <- c("Estimate","SE","lower.CL","upper.CL")
em_lm_mu_data.mnar <- emmeans(lm_mnar_data, ~ trt)

#look at empirical data
full_e_mean <- mean(full.df$QALY, na.rm = T)
full_e_sd <- sd(full.df$QALY, na.rm = T)
mcar_e_meano <- mean(full.mcar$QALY_obs, na.rm = T)
mcar_e_sdo <- sd(full.mcar$QALY_obs, na.rm = T)
mar_e_meano <- mean(full.mar$QALY_obs, na.rm = T)
mar_e_sdo <- sd(full.mar$QALY_obs, na.rm = T)
mnar_e_meano <- mean(full.mnar$QALY_obs, na.rm = T)
mnar_e_sdo <- sd(full.mnar$QALY_obs, na.rm = T)
mcar_e_meanm <- mean(full.mcar$QALY_mis, na.rm = T)
mcar_e_sdm <- sd(full.mcar$QALY_mis, na.rm = T)
mar_e_meanm <- mean(full.mar$QALY_mis, na.rm = T)
mar_e_sdm <- sd(full.mar$QALY_mis, na.rm = T)
mnar_e_meanm <- mean(full.mnar$QALY_mis, na.rm = T)
mnar_e_sdm <- sd(full.mnar$QALY_mis, na.rm = T)
full.mcar$m <- ifelse(full.mcar$m==0,"obs","mis")
full.mcar$m <- factor(full.mcar$m, levels = c("obs","mis"))
full.mar$m <- ifelse(full.mar$m==0,"obs","mis")
full.mar$m <- factor(full.mar$m, levels = c("obs","mis"))
full.mnar$m <- ifelse(full.mnar$m==0,"obs","mis")
full.mnar$m <- factor(full.mnar$m, levels = c("obs","mis"))

full_u_mean <- mean(full.df$u, na.rm = T)
full_u_sd <- sd(full.df$u, na.rm = T)
mcar_u_meano <- mean(full.mcar$u[full.mcar$m=="obs"], na.rm = T)
mcar_u_sdo <- sd(full.mcar$u[full.mcar$m=="obs"], na.rm = T)
mar_u_meano <- mean(full.mar$u[full.mar$m=="obs"], na.rm = T)
mar_u_sdo <- sd(full.mar$u[full.mar$m=="obs"], na.rm = T)
mnar_u_meano <- mean(full.mnar$u[full.mnar$m=="obs"], na.rm = T)
mnar_u_sdo <- sd(full.mnar$u[full.mnar$m=="obs"], na.rm = T)
mcar_u_meanm <- mean(full.mcar$u[full.mcar$m=="mis"], na.rm = T)
mcar_u_sdm <- sd(full.mcar$u[full.mcar$m=="mis"], na.rm = T)
mar_u_meanm <- mean(full.mar$u[full.mar$m=="mis"], na.rm = T)
mar_u_sdm <- sd(full.mar$u[full.mar$m=="mis"], na.rm = T)
mnar_u_meanm <- mean(full.mnar$u[full.mnar$m=="mis"], na.rm = T)
mnar_u_sdm <- sd(full.mnar$u[full.mnar$m=="mis"], na.rm = T)



#prepare data for plotting

full.df.value <- c(full.df$QALY,full.df$u)
full.df.trt <- c(full.df$trt,full.df$trt)
full.df.outcome <- c(rep("QALY",length(full.df$QALY)),rep("u",length(full.df$u)))
full.df.gg <- data.frame(full.df.value,full.df.trt,full.df.outcome)
names(full.df.gg) <- c("Value","trt","outcome")
full.df.gg$outcome <- factor(full.df.gg$outcome, levels = c("QALY","u"))
mcar.df.value <- c(full.mcar$QALY,full.mcar$u)
mcar.df.trt <- c(full.mcar$trt,full.mcar$trt)
mcar.df.m <- c(full.mcar$m,full.mcar$m)
mcar.df.outcome <- c(rep("QALY",length(full.mcar$QALY)),rep("u",length(full.mcar$u)))
mcar.df.gg <- data.frame(mcar.df.value,mcar.df.trt,mcar.df.m,mcar.df.outcome)
names(mcar.df.gg) <- c("Value","trt","m","outcome")
mcar.df.gg$m <- factor(mcar.df.gg$m, levels = c("obs","mis"))
mcar.df.gg$outcome <- factor(mcar.df.gg$outcome, levels = c("QALY","u"))
mar.df.value <- c(full.mar$QALY,full.mar$u)
mar.df.trt <- c(full.mar$trt,full.mar$trt)
mar.df.m <- c(full.mar$m,full.mar$m)
mar.df.outcome <- c(rep("QALY",length(full.mar$QALY)),rep("u",length(full.mar$u)))
mar.df.gg <- data.frame(mar.df.value,mar.df.trt,mar.df.m,mar.df.outcome)
names(mar.df.gg) <- c("Value","trt","m","outcome")
mar.df.gg$m <- factor(mar.df.gg$m, levels = c("obs","mis"))
mar.df.gg$outcome <- factor(mar.df.gg$outcome, levels = c("QALY","u"))
mnar.df.value <- c(full.mnar$QALY,full.mnar$u)
mnar.df.trt <- c(full.mnar$trt,full.mnar$trt)
mnar.df.m <- c(full.mnar$m,full.mnar$m)
mnar.df.outcome <- c(rep("QALY",length(full.mnar$QALY)),rep("u",length(full.mnar$u)))
mnar.df.gg <- data.frame(mnar.df.value,mnar.df.trt,mnar.df.m,mnar.df.outcome)
names(mnar.df.gg) <- c("Value","trt","m","outcome")
mnar.df.gg$m <- factor(mnar.df.gg$m, levels = c("obs","mis"))
mnar.df.gg$outcome <- factor(mnar.df.gg$outcome, levels = c("QALY","u"))

dummy.full <- data.frame(outcome = c("QALY", "u"), Z = c(full_e_mean, full_u_mean))
dummy.mcar <- data.frame(outcome = c("QALY", "u"), 
                         Z1 = c(mcar_e_meano, mcar_u_meano), Z2 = c(mcar_e_meanm, mcar_u_meanm))
dummy.mar <- data.frame(outcome = c("QALY", "u"), 
                         Z1 = c(mar_e_meano, mar_u_meano), Z2 = c(mar_e_meanm, mar_u_meanm))
dummy.mnar <- data.frame(outcome = c("QALY", "u"), 
                         Z1 = c(mnar_e_meano, mnar_u_meano), Z2 = c(mnar_e_meanm, mnar_u_meanm))
  
#generate histograms of obs vs mis data
gghist_full_e <- ggplot(full.df.gg, aes(x=Value)) + 
  geom_histogram(color="black",fill="white", binwidth=0.07) +
  xlab("") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,55)) +
  scale_x_continuous(limits = c(0,1.5)) +
  facet_wrap(~outcome, scales = "free") +
#  geom_vline(data=dummy.full, aes(xintercept = Z), colour="black", linewidth=1) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "none")


gghist_mcar_e <- ggplot(mcar.df.gg, aes(Value, fill = m)) +
  geom_histogram(binwidth=0.07, color="white", alpha = 0.7) +
  scale_fill_manual(name="", labels=c("obs","mis"), values=c("lightblue", "coral")) +
  xlab("") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,55)) +
  scale_x_continuous(limits = c(0,1.5)) +
  facet_wrap(~outcome, scales = "free") +
  geom_vline(data=dummy.mcar, aes(xintercept=Z1), linewidth=1, color="blue") +
  geom_vline(data=dummy.mcar, aes(xintercept=Z2), linewidth=1, color="red") +
  theme_classic() + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "right")

gghist_mar_e <- ggplot(mar.df.gg, aes(Value, fill = m)) +
  geom_histogram(binwidth=0.07, color="white", alpha = 0.7) +
  scale_fill_manual(name="", labels=c("obs","mis"), values=c("lightblue", "coral")) +
  xlab("") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,55)) +
  scale_x_continuous(limits = c(0,1.5)) +
  facet_wrap(~outcome, scales = "free") +
  geom_vline(data=dummy.mar, aes(xintercept=Z1), linewidth=1, color="blue") +
  geom_vline(data=dummy.mar, aes(xintercept=Z2), linewidth=1, color="red") +
  theme_classic() + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "right")

gghist_mnar_e <- ggplot(mnar.df.gg, aes(Value, fill = m)) +
  geom_histogram(binwidth=0.07, color="white", alpha = 0.7) +
  scale_fill_manual(name="", labels=c("obs","mis"), values=c("lightblue", "coral")) +
  xlab("") + ylab("Frequency") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,55)) +
  scale_x_continuous(limits = c(0,1.5)) +
  facet_wrap(~outcome, scales = "free") +
  geom_vline(data=dummy.mnar, aes(xintercept=Z1), linewidth=1, color="blue") +
  geom_vline(data=dummy.mnar, aes(xintercept=Z2), linewidth=1, color="red") +
  theme_classic() + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"), 
        strip.text.x = element_text(size = 12, color = "black", face = "bold"),
        strip.text.y = element_text(size = 12, color = "black", face = "bold"),
        legend.position = "right")


```

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 6.5
#| fig-height: 4.5 

gghist_full_e
```

:::

:::{#secondcol}

\small

- QALYs \& utilities \myblue \textbf{fully observed} \black

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

tbl_full_eu <- cbind.data.frame(full_e_mean,full_e_sd,full_u_mean,full_u_sd, length(full.df$QALY))
names(tbl_full_eu) <- c("Mean(e)","Sd(e)","Mean(u)","Sd(u)","n")
kable(tbl_full_eu, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'black', bold = FALSE, italic = FALSE) %>% 
  column_spec(c(1,3), bold = TRUE, color = 'black', italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = TRUE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down")

```


:::

::::


## Missing data - an example

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 6.5
#| fig-height: 4.5 

gghist_mcar_e
```

:::

:::{#secondcol}

\small

- QALYs under \myred \textbf{MCAR} \black \& utilities

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

tbl_mcar_eu <- cbind.data.frame(c(mcar_e_meano,mcar_e_meanm),c(mcar_e_sdo,mcar_e_sdm),c(mcar_u_meano,mcar_u_meanm),c(mcar_u_sdo,mcar_u_sdm),c(length(full.mcar$QALY[full.mcar$m=="obs"]),length(full.mcar$QALY[full.mcar$m=="mis"])))
names(tbl_mcar_eu) <- c("Mean(e)","Sd(e)","Mean(u)","Sd(u)","n")
kable(tbl_mcar_eu, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'blue', bold = FALSE, italic = FALSE) %>% 
  row_spec(2, color = 'red', bold = FALSE, italic = FALSE) %>% 
  column_spec(c(1,3), bold = TRUE, italic = FALSE) %>%
  column_spec(c(3,4), color = 'blue', italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = TRUE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down")

```


:::

::::


## Missing data - an example

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 6.5
#| fig-height: 4.5 

gghist_mar_e
```

:::

:::{#secondcol}

\small

- QALYs under \myred \textbf{MAR} \black \& utilities

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

tbl_mar_eu <- cbind.data.frame(c(mar_e_meano,mar_e_meanm),c(mar_e_sdo,mar_e_sdm),c(mar_u_meano,mar_u_meanm),c(mar_u_sdo,mar_u_sdm),c(length(full.mar$QALY[full.mar$m=="obs"]),length(full.mar$QALY[full.mar$m=="mis"])))
names(tbl_mar_eu) <- c("Mean(e)","Sd(e)","Mean(u)","Sd(u)","n")
kable(tbl_mar_eu, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'blue', bold = FALSE, italic = FALSE) %>% 
  row_spec(2, color = 'red', bold = FALSE, italic = FALSE) %>% 
  column_spec(c(1,3), bold = TRUE, italic = FALSE) %>%
  column_spec(c(3,4), color = 'blue', italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = TRUE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down")

```


:::

::::

## Missing data - an example

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 6.5
#| fig-height: 4.5 

gghist_mnar_e
```

:::

:::{#secondcol}

\small

- QALYs under \myred \textbf{MNAR} \black \& utilities

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

tbl_mnar_eu <- cbind.data.frame(c(mnar_e_meano,mnar_e_meanm),c(mnar_e_sdo,mnar_e_sdm),c(mnar_u_meano,mnar_u_meanm),c(mnar_u_sdo,mnar_u_sdm),c(length(full.mnar$QALY[full.mnar$m=="obs"]),length(full.mnar$QALY[full.mnar$m=="mis"])))
names(tbl_mnar_eu) <- c("Mean(e)","Sd(e)","Mean(u)","Sd(u)","n")
kable(tbl_mnar_eu, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'blue', bold = FALSE, italic = FALSE) %>% 
  row_spec(2, color = 'red', bold = FALSE, italic = FALSE) %>% 
  column_spec(c(1,3), bold = TRUE, italic = FALSE) %>%
  column_spec(c(3,4), color = 'blue', italic = FALSE) %>%
  column_spec(5, bold = FALSE, color = 'black', italic = TRUE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down")

```

:::

::::


## Missing data - alternative methods

- \olive \textbf{Complete Case Analysis} \black (CCA):

  + \myred \textbf{Eliminate} \black partially-observed cases $y^{\text{mis}}$
  + Reduce **efficiency** and may **bias** estimates

. . .

- \olive \textbf{Single Imputation} \black  (SI):

  + Impute $y^{\text{mis}}$ with a \myred \textbf{single value} \black $y^{\text{mis}}=y^{\star}$ (eg mean, zero, etc.)
  + \myred \textbf{Ignores} \black uncertainty with *restrictive* assumptions

. . .

- \olive \textbf{Multiple Imputation} \black (MI):

  + \myblue \textbf{Impute} \black $y^{\text{mis}}$ $M$ times with an *imputation model*
  + \myblue \textbf{Analyse} \black each dataset and derive estimates $\hat{\beta}_m$ for $m=1,\ldots,M$
  + \myblue \textbf{Combine} \black $M$ estimates into a single quantity $\hat{\beta}$
  + Validity relies on **correct** model specification



## Missing data - alternative methods

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| cache: false

#simulate data and missing under different mechanisms

set.seed(2345)
n_full <- 250
mu_x <- 0.6
sd_x <- 0.1
tau_x <- (mu_x*(1-mu_x)/sd_x^2-1)
shape1_x <- mu_x*tau_x
shape2_x <- (1-mu_x)*tau_x
x_data <- rbeta(n_full, shape1_x, shape2_x)
p_trt <- 0.5
trt_data <- rbinom(n_full, p_trt, size = 1)
beta0_data <- 0.2
beta1_data <- 0.15
beta2_data <- 1
mu_res.e <- 0.7
sd_res.e <- 0.05
tau_res.e <- (mu_res.e*(1-mu_res.e)/sd_res.e^2-1)
shape1_res.e <- mu_res.e*tau_res.e
shape2_res.e <- (1-mu_res.e)*tau_res.e
y1_data <- beta0_data + beta1_data*trt_data + beta2_data*x_data + rbeta(n_full, shape1_res.e, shape2_res.e) -1
mu_c <- 100 
sd_c <- 87
shape_c <- mu_c^2/sd_c^2
scale_c <- sd_c^2/sd_c
set.seed(2345)
z_data <- rgamma(n_full, shape = shape_c, scale = scale_c)
alpha0_data <- 50
alpha1_data <- 14
alpha2_data <- 0.5
mu_res.c <- 25 
sd_res.c <- 30
shape_res.c <- mu_res.c^2/sd_res.c^2
scale_res.c <- sd_res.c^2/sd_res.c
y2_data <- alpha0_data + alpha1_data*trt_data + alpha2_data*z_data + rgamma(n_full, shape = shape_res.c, scale = scale_res.c)
full.df <- data.frame(y1_data, y2_data,trt_data,x_data, z_data)
names(full.df) <- c("QALY","TC","trt","u","c")
full.df$trt <- ifelse(full.df$trt==0,"old","new")
full.df$trt <- factor(full.df$trt, levels = c("old","new"))
lm_full_data.e <- lm(QALY ~ trt + u, data = full.df)
lm_full_data.c <- lm(TC ~ trt + c, data = full.df)
lm_delta_data.e <- summary(lm_full_data.e)$coefficients["trtnew","Estimate"]
lm_se_delta_data.e <- summary(lm_full_data.e)$coefficients["trtnew","Std. Error"]
lm_ci_delta_data.e <- confint(lm_full_data.e)["trtnew",]
lm_delta_data.sum.e <- c(lm_delta_data.e,lm_se_delta_data.e,lm_ci_delta_data.e)
names(lm_delta_data.sum.e) <- c("Estimate","SE","lower.CL","upper.CL")
em_lm_mu_data.e <- emmeans(lm_full_data.e, ~ trt)
lm_delta_data.c <- summary(lm_full_data.c)$coefficients["trtnew","Estimate"]
lm_se_delta_data.c <- summary(lm_full_data.c)$coefficients["trtnew","Std. Error"]
lm_ci_delta_data.c <- confint(lm_full_data.c)["trtnew",]
lm_delta_data.sum.c <- c(lm_delta_data.c,lm_se_delta_data.c,lm_ci_delta_data.c)
names(lm_delta_data.sum.c) <- c("Estimate","SE","lower.CL","upper.CL")
em_lm_mu_data.c <- emmeans(lm_full_data.c, ~ trt)

#introduce MAR missingness given u and c
library(boot)
set.seed(2345)
eta0_mar <- -14.5
eta_1_mar <- 25
eta_2_mar <- 0
eta_3_mar <- 0
p_mar.e <- inv.logit(eta0_mar + eta_1_mar*full.df$u + eta_2_mar*full.df$QALY + eta_3_mar*as.numeric(full.df$trt))
m_mar.e <- rbinom(n_full, p_mar.e, size = 1)
zeta0_mar <- -15
zeta_1_mar <- 14.5
zeta_2_mar <- 0
zeta_3_mar <- 0
p_mar.c <- inv.logit(zeta0_mar + zeta_1_mar*full.df$c/100 + zeta_2_mar*full.df$TC/100 + zeta_3_mar*as.numeric(full.df$trt))
m_mar.c <- rbinom(n_full, p_mar.c, size = 1)
full.mar <- full.df
full.mar$m.e <- m_mar.e
full.mar$QALY_obs <- ifelse(full.mar$m.e==0,full.mar$QALY,NA)
full.mar$QALY_mis <- ifelse(full.mar$m.e==1,full.mar$QALY,NA)
full.mar$m.c <- m_mar.c
full.mar$TC_obs <- ifelse(full.mar$m.c==0,full.mar$TC,NA)
full.mar$TC_mis <- ifelse(full.mar$m.c==1,full.mar$TC,NA)

#compare results from different methods
#CCA
full.mar.CCA <- full.mar
lme_cca_data <- lm(QALY_obs ~ trt + u, data = full.mar.CCA, na.action = na.omit)
lme_delta_data.cca <- summary(lme_cca_data)$coefficients["trtnew","Estimate"]
lme_se_delta_data.cca <- summary(lme_cca_data)$coefficients["trtnew","Std. Error"]
lme_ci_delta_data.cca <- confint(lme_cca_data)["trtnew",]
lme_delta_data.cca.sum <- c(lme_delta_data.cca,lme_se_delta_data.cca,lme_ci_delta_data.cca)
names(lme_delta_data.cca.sum) <- c("Estimate","SE","lower.CL","upper.CL")
em_lme_mu_data.cca <- emmeans(lme_cca_data, ~ trt)
lmc_cca_data <- lm(TC_obs ~ trt + c, data = full.mar.CCA, na.action = na.omit)
lmc_delta_data.cca <- summary(lmc_cca_data)$coefficients["trtnew","Estimate"]
lmc_se_delta_data.cca <- summary(lmc_cca_data)$coefficients["trtnew","Std. Error"]
lmc_ci_delta_data.cca <- confint(lmc_cca_data)["trtnew",]
lmc_delta_data.cca.sum <- c(lmc_delta_data.cca,lmc_se_delta_data.cca,lmc_ci_delta_data.cca)
names(lmc_delta_data.cca.sum) <- c("Estimate","SE","lower.CL","upper.CL")
em_lmc_mu_data.cca <- emmeans(lmc_cca_data, ~ trt)


#SI
full.mar.SI <- full.mar
full.mar.SI$QALY_obs <- ifelse(is.na(full.mar.SI$QALY_obs),mean(full.mar.SI$QALY_obs,na.rm = T),full.mar.SI$QALY_obs)
full.mar.SI$TC_obs <- ifelse(is.na(full.mar.SI$TC_obs),0,full.mar.SI$TC_obs)
lme_si_data <- lm(QALY_obs ~ trt + u, data = full.mar.SI, na.action = na.omit)
lme_delta_data.si <- summary(lme_si_data)$coefficients["trtnew","Estimate"]
lme_se_delta_data.si <- summary(lme_si_data)$coefficients["trtnew","Std. Error"]
lme_ci_delta_data.si <- confint(lme_si_data)["trtnew",]
lme_delta_data.si.sum <- c(lme_delta_data.si,lme_se_delta_data.si,lme_ci_delta_data.si)
names(lme_delta_data.si.sum) <- c("Estimate","SE","lower.CL","upper.CL")
em_lme_mu_data.si <- emmeans(lme_si_data, ~ trt)
lmc_si_data <- lm(TC_obs ~ trt + c, data = full.mar.SI, na.action = na.omit)
lmc_delta_data.si <- summary(lmc_si_data)$coefficients["trtnew","Estimate"]
lmc_se_delta_data.si <- summary(lmc_si_data)$coefficients["trtnew","Std. Error"]
lmc_ci_delta_data.si <- confint(lmc_si_data)["trtnew",]
lmc_delta_data.si.sum <- c(lmc_delta_data.si,lmc_se_delta_data.si,lmc_ci_delta_data.si)
names(lmc_delta_data.si.sum) <- c("Estimate","SE","lower.CL","upper.CL")
em_lmc_mu_data.si <- emmeans(lmc_si_data, ~ trt)


#MICE + pmm
library(mice)
full.mar.MI <- full.mar[,c("QALY_obs","TC_obs","trt","u","c")]
set.seed(2345)
mice0_data <- mice(full.mar.MI, print = FALSE, method = 'pmm', maxit = 0)
pM <- mice0_data$predictorMatrix
meth <- mice0_data$method
mice_data <- mice(full.mar.MI, predictorMatrix = pM, method=meth,m = 20, maxit = 15, print = FALSE)
lme_mice_data <- with(mice_data, lm(QALY_obs ~ trt + u))
lme_pool_mice_data <- pool(lme_mice_data)
lme_delta_data.mi <- summary(lme_pool_mice_data)[2,"estimate"]
lme_se_delta_data.mi <- summary(lme_pool_mice_data)[2,"std.error"]
lme_ci_delta_data.mi <- c(unlist(summary(lme_pool_mice_data, conf.int = TRUE)[2,c("conf.low","conf.high")]))
lme_delta_data.mi.sum <- c(lme_delta_data.mi,lme_se_delta_data.mi,lme_ci_delta_data.mi)
names(lme_delta_data.mi.sum) <- c("Estimate","SE","lower.CL","upper.CL")
lmc_mice_data <- with(mice_data, lm(TC_obs ~ trt + c))
lmc_pool_mice_data <- pool(lmc_mice_data)
lmc_delta_data.mi <- summary(lmc_pool_mice_data)[2,"estimate"]
lmc_se_delta_data.mi <- summary(lmc_pool_mice_data)[2,"std.error"]
lmc_ci_delta_data.mi <- c(unlist(summary(lmc_pool_mice_data, conf.int = TRUE)[2,c("conf.low","conf.high")]))
lmc_delta_data.mi.sum <- c(lmc_delta_data.mi,lmc_se_delta_data.mi,lmc_ci_delta_data.mi)
names(lmc_delta_data.mi.sum) <- c("Estimate","SE","lower.CL","upper.CL")
em_lme_mu_data.mi <- emmeans(lme_mice_data, ~ trt)
em_lmc_mu_data.mi <- emmeans(lmc_mice_data, ~ trt)


#combine results in data frame
df.delta.estimate <- c(lme_delta_data.cca,lme_delta_data.si,lme_delta_data.mi,lmc_delta_data.cca,lmc_delta_data.si,lmc_delta_data.mi)
df.delta.CI.low <- c(lme_ci_delta_data.cca[1],lme_ci_delta_data.si[1],lme_ci_delta_data.mi[1],lmc_ci_delta_data.cca[1],lmc_ci_delta_data.si[1],lmc_ci_delta_data.mi[1])
df.delta.CI.high <- c(lme_ci_delta_data.cca[2],lme_ci_delta_data.si[2],lme_ci_delta_data.mi[2],lmc_ci_delta_data.cca[2],lmc_ci_delta_data.si[2],lmc_ci_delta_data.mi[2])
df.delta.method <- c("CCA","SI","MI","CCA","SI","MI")
df.delta.outcome <- c("QALY","QALY","QALY","TC","TC","TC")
df.delta.mis <- cbind.data.frame(df.delta.estimate,df.delta.CI.low,df.delta.CI.high,df.delta.method,df.delta.outcome)
names(df.delta.mis) <- c("Estimate","CI.low","CI.high","method","outcome")


df.mu.e.estimate <- c(summary(em_lme_mu_data.cca)$emmean[1],summary(em_lme_mu_data.si)$emmean[1],summary(em_lme_mu_data.mi)$emmean[1],summary(em_lme_mu_data.cca)$emmean[2],summary(em_lme_mu_data.si)$emmean[2],summary(em_lme_mu_data.mi)$emmean[2])
df.mu.e.CI.low <- c(summary(em_lme_mu_data.cca)$lower.CL[1],summary(em_lme_mu_data.si)$lower.CL[1],summary(em_lme_mu_data.mi)$lower.CL[1],summary(em_lme_mu_data.cca)$lower.CL[2],summary(em_lme_mu_data.si)$lower.CL[2],summary(em_lme_mu_data.mi)$lower.CL[2])
df.mu.e.CI.high <- c(summary(em_lme_mu_data.cca)$upper.CL[1],summary(em_lme_mu_data.si)$upper.CL[1],summary(em_lme_mu_data.mi)$upper.CL[1],summary(em_lme_mu_data.cca)$upper.CL[2],summary(em_lme_mu_data.si)$upper.CL[2],summary(em_lme_mu_data.mi)$upper.CL[2])
df.mu.arm <- c("Old","Old","Old","New","New","New")
df.mu.method <- c("CCA","SI","MI","CCA","SI","MI")
df.mu.e.mis <- cbind.data.frame(df.mu.e.estimate,df.mu.e.CI.low,df.mu.e.CI.high,df.mu.method,df.mu.arm)
names(df.mu.e.mis) <- c("Estimate","CI.low","CI.high","method","arm")

df.mu.c.cstimate <- c(summary(em_lmc_mu_data.cca)$emmean[1],summary(em_lmc_mu_data.si)$emmean[1],summary(em_lmc_mu_data.mi)$emmean[1],summary(em_lmc_mu_data.cca)$emmean[2],summary(em_lmc_mu_data.si)$emmean[2],summary(em_lmc_mu_data.mi)$emmean[2])
df.mu.c.CI.low <- c(summary(em_lmc_mu_data.cca)$lower.CL[1],summary(em_lmc_mu_data.si)$lower.CL[1],summary(em_lmc_mu_data.mi)$lower.CL[1],summary(em_lmc_mu_data.cca)$lower.CL[2],summary(em_lmc_mu_data.si)$lower.CL[2],summary(em_lmc_mu_data.mi)$lower.CL[2])
df.mu.c.CI.high <- c(summary(em_lmc_mu_data.cca)$upper.CL[1],summary(em_lmc_mu_data.si)$upper.CL[1],summary(em_lmc_mu_data.mi)$upper.CL[1],summary(em_lmc_mu_data.cca)$upper.CL[2],summary(em_lmc_mu_data.si)$upper.CL[2],summary(em_lmc_mu_data.mi)$upper.CL[2])
df.mu.arm <- c("Old","Old","Old","New","New","New")
df.mu.method <- c("CCA","SI","MI","CCA","SI","MI")
df.mu.c.mis <- cbind.data.frame(df.mu.c.cstimate,df.mu.c.CI.low,df.mu.c.CI.high,df.mu.method,df.mu.arm)
names(df.mu.c.mis) <- c("Estimate","CI.low","CI.high","method","arm")

```


:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 4.5 

#plot diff estimates
library(ggplot2)
df.delta.mis$Estimate <- as.numeric(df.delta.mis$Estimate)
df.delta.mis$CI.low <- as.numeric(df.delta.mis$CI.low)
df.delta.mis$CI.high <- as.numeric(df.delta.mis$CI.high)
df.delta.mis$method <- factor(df.delta.mis$method, levels = c("CCA","SI","MI"))
df.delta.mis$outcome <- factor(df.delta.mis$outcome, levels = c("QALY","TC"))
df.delta.mis.QALY <- df.delta.mis[df.delta.mis$outcome=="QALY",-5]
df.delta.mis.TC <- df.delta.mis[df.delta.mis$outcome=="TC", -5]
dummy <- data.frame(outcome = c("QALY", "TC"), Z = c(lm_delta_data.e, lm_delta_data.c))
dummy$outcome <- factor(dummy$outcome, levels = c("QALY","TC"))

ggplot(df.delta.mis, aes(x=factor(method, levels = c("CCA","SI","MI")), y=Estimate, colour=factor(outcome, levels = c("QALY","TC")))) +
  geom_point(position=position_dodge(width=0.4), size=2) +
  geom_hline(data = dummy, aes(yintercept = Z)) + 
  geom_errorbar(aes(ymin=CI.low, ymax=CI.high), width=.1, position = position_dodge(width = 0.4)) + facet_wrap(~factor(outcome, levels = c("QALY","TC")), scales = "free") +
  ylab("Mean Difference") + scale_colour_manual(name="outcome", labels=c("QALY","TC"), values=c("purple", "purple")) +
  xlab("") +
  theme_classic() + 
  theme(legend.position = "none",
        text = element_text(size = 10),
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \myblue \textbf{Mean QALY difference} $\Delta_e$ \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(df.delta.mis.QALY, booktabs = TRUE, row.names = FALSE ,digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'purple', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'purple', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

\small

- \myred \textbf{Mean TC difference} $\Delta_c$ \black

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(df.delta.mis.TC, booktabs = TRUE, row.names = FALSE, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'purple', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'purple', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 6, latex_options = "scale_down") 
```

:::

::::


## Missing data - alternative methods

:::: {layout="[0.5, 0.5]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 6
#| fig-height: 6 

#plot QALY estimates
mu.e_mis_gg <- c(summary(em_lme_mu_data.cca)$emmean[1],summary(em_lme_mu_data.si)$emmean[1],summary(em_lme_mu_data.mi)$emmean[1],summary(em_lme_mu_data.cca)$emmean[2],summary(em_lme_mu_data.si)$emmean[2],summary(em_lme_mu_data.mi)$emmean[2])
mu.e_lci_mis_gg <- c(summary(em_lme_mu_data.cca)$lower.CL[1],summary(em_lme_mu_data.si)$lower.CL[1],summary(em_lme_mu_data.mi)$lower.CL[1],summary(em_lme_mu_data.cca)$lower.CL[2],summary(em_lme_mu_data.si)$lower.CL[2],summary(em_lme_mu_data.mi)$lower.CL[2])
mu.e_uci_mis_gg <- c(summary(em_lme_mu_data.cca)$upper.CL[1],summary(em_lme_mu_data.si)$upper.CL[1],summary(em_lme_mu_data.mi)$upper.CL[1],summary(em_lme_mu_data.cca)$upper.CL[2],summary(em_lme_mu_data.si)$upper.CL[2],summary(em_lme_mu_data.mi)$upper.CL[2])
mu.e_mis_arm_gg <- c(rep("Old",3),rep("New",3))
mu.e_mis_meth_gg <- rep(c("CCA","SI","MI"),2)
mu_mis.e_gg <- cbind.data.frame(mu.e_mis_gg,mu.e_lci_mis_gg,mu.e_uci_mis_gg,mu.e_mis_meth_gg,mu.e_mis_arm_gg)
names(mu_mis.e_gg) <- c("Estimate","CI.low","CI.high","method","arm")
mu_mis.e_gg$arm <- factor(mu_mis.e_gg$arm, levels = c("Old","New"))
mu_mis.e_gg$method <- factor(mu_mis.e_gg$method, levels = c("CCA","SI","MI"))

ggplot(mu_mis.e_gg, aes(x=method, y=as.numeric(Estimate), colour=arm)) + 
  geom_point(position=position_dodge(width=0.4), size=2) +
geom_errorbar(aes(ymin=as.numeric(CI.low), ymax=as.numeric(CI.high)), width=.1, position = position_dodge(width = 0.4)) +
  scale_colour_manual(name="Arm", labels=c("Old","New"), values=c("red", "blue")) + 
  ylab("Mean QALY") + ylim(0.4,0.7) +
  geom_hline(yintercept = summary(em_lm_mu_data.e)$emmean[1], col = "red4") +
  geom_hline(yintercept = summary(em_lm_mu_data.e)$emmean[2], col = "blue4") +
  xlab("Method") +
  theme_classic() + 
  theme(legend.position = "right",
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \red \textbf{Mean QALY} for arm = "Old" \black

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(mu_mis.e_gg[c(1:3),1:4], booktabs = TRUE, row.names = F, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'red', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'red', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8)
```

\small 

- \blue \textbf{Mean QALY} for arm = "New" \black

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(mu_mis.e_gg[c(4:6),1:4], booktabs = TRUE, row.names = F, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'blue', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8)
```
:::

::::




## Missing data - alternative methods

:::: {layout="[0.5, 0.5]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 6
#| fig-height: 6 

#plot TC estimates
mu.c_mis_gg <- c(summary(em_lmc_mu_data.cca)$emmean[1],summary(em_lmc_mu_data.si)$emmean[1],summary(em_lmc_mu_data.mi)$emmean[1],summary(em_lmc_mu_data.cca)$emmean[2],summary(em_lmc_mu_data.si)$emmean[2],summary(em_lmc_mu_data.mi)$emmean[2])
mu.c_lci_mis_gg <- c(summary(em_lmc_mu_data.cca)$lower.CL[1],summary(em_lmc_mu_data.si)$lower.CL[1],summary(em_lmc_mu_data.mi)$lower.CL[1],summary(em_lmc_mu_data.cca)$lower.CL[2],summary(em_lmc_mu_data.si)$lower.CL[2],summary(em_lmc_mu_data.mi)$lower.CL[2])
mu.c_uci_mis_gg <- c(summary(em_lmc_mu_data.cca)$upper.CL[1],summary(em_lmc_mu_data.si)$upper.CL[1],summary(em_lmc_mu_data.mi)$upper.CL[1],summary(em_lmc_mu_data.cca)$upper.CL[2],summary(em_lmc_mu_data.si)$upper.CL[2],summary(em_lmc_mu_data.mi)$upper.CL[2])
mu.c_mis_arm_gg <- c(rep("Old",3),rep("New",3))
mu.c_mis_meth_gg <- rep(c("CCA","SI","MI"),2)
mu_mis.c_gg <- cbind.data.frame(mu.c_mis_gg,mu.c_lci_mis_gg,mu.c_uci_mis_gg,mu.c_mis_meth_gg,mu.c_mis_arm_gg)
names(mu_mis.c_gg) <- c("Estimate","CI.low","CI.high","method","arm")
mu_mis.c_gg$arm <- factor(mu_mis.c_gg$arm, levels = c("Old","New"))
mu_mis.c_gg$method <- factor(mu_mis.c_gg$method, levels = c("CCA","SI","MI"))

ggplot(mu_mis.c_gg, aes(x=method, y=as.numeric(Estimate), colour=arm)) + 
  geom_point(position=position_dodge(width=0.4), size=2) +
geom_errorbar(aes(ymin=as.numeric(CI.low), ymax=as.numeric(CI.high)), width=.1, position = position_dodge(width = 0.4)) +
  scale_colour_manual(name="Arm", labels=c("Old","New"), values=c("red", "blue")) + 
  ylab("Mean TC") + ylim(50,150) +
  geom_hline(yintercept = summary(em_lm_mu_data.c)$emmean[1], col = "red4") +
  geom_hline(yintercept = summary(em_lm_mu_data.c)$emmean[2], col = "blue4") +
  xlab("Method") +
  theme_classic() + 
  theme(legend.position = "right",
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

:::

:::{#secondcol}

\small

- \red \textbf{Mean TC} for arm = "Old" \black

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(mu_mis.c_gg[c(1:3),1:4], booktabs = TRUE, row.names = F, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'red', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'red', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8)
```

\small 

- \blue \textbf{Mean TC} for arm = "New" \black

\scriptsize
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

kable(mu_mis.c_gg[c(4:6),1:4], booktabs = TRUE, row.names = F, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1:3, color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = 'blue', italic = FALSE) %>%
  column_spec(4, bold = FALSE, color = 'black', italic = FALSE) %>%
  kable_styling(font_size = 8)
```
:::

::::


## Missing data - things to consider

- "Simple" methods \olive \textbf{(CCA/SI)}\black:

  + \myblue \textbf{Easy} \black to implement but likely \myred \textbf{inefficient} \black and/or \myred \textbf{biased} \black 
  + Often valid under *quite restrictive* assumptions (eg MCAR)

. . .

- "Advanced" methods \olive \textbf{(MI)}\black:

  + Account for missingness \myblue \textbf{uncertainty} \black
  + Require specification of \myred \textbf{imputation model} \black for each variable (MICE)
  + Valid under *less restrictive* assumptions (eg MAR)

. . .

- \myred \textbf{Further issues} \black to address:

  + Check \textbf{sensitivity} of results to departures (eg MNAR)
    + Use specific *MNAR approaches* (Leurent et al. 2018) 
    
  + Imputation of \textbf{longitudinal} variables $(u_{ij},c_{ij})$ challenging
    + Use mixed models under *MAR* (Gabrio et al. 2022)
    
  + "Best" way to **combine** MI/bootstrap \textit{unclear} (Brand et al. 2019)


## Are we still alive?

![](figure\meloni6b.jpg){width=80% fig-align="center"}


# Reporting of CEAs

## Data \& Methods

```{=latex}
\begin{itemize}
\setlength\itemsep{0.2em}
\item \olive \textbf{Patient characteristics} \black (eg baseline var) \& \olive \textbf{effectiveness} \black by arm
\pause
\item \olive \textbf{Costs} \black \& \olive \textbf{Quality of Life} \black:
\begin{itemize}
\item[-] \textbf{Prices} (with year) and \textbf{volumes} of all cost components
\item[-] QoL \textbf{instrument} and summary of \textbf{measurement moments}
\item[-] Valuation of health states and methods used (if applicable)
\end{itemize}
\pause
\item \olive \textbf{Missing Data} \black:
\begin{itemize}
\item[-] Description of \textbf{amounts} and \textbf{patterns}
\item[-] How it was handled (including \textit{type of imputation})
\end{itemize}
\pause
\item \olive \textbf{Extrapolation} \black \& \olive \textbf{Validation} \black:
\begin{itemize}
\item[-] Measures for checking the validity of extrapolation (time-to-event data)
\item[-] \textit{AdVISHE}\footnote<.(1)->{Assessment of the Validation Status of Health-Economic} checklist (validation of input data and outcomes)
\end{itemize}
\end{itemize}
```


## Results: base-case analysis

- \olive \textbf{Costs} \black \& \olive \textbf{Effects} \black:
  + *Absolute* \& *incremental* estimates with CIs
  + *Absolute* \& *incremental* costs by cost category and total sums
  + *Absolute* \& *incremental* QoL by health state (if applicable)

. . .

- \olive \textbf{CE quantities} \black:
  + \myblue \textbf{Incremental Cost-Effectiveness Ratio} \black: $\text{ICER}=\frac{\Delta_e}{\Delta_c}$
  + \myblue \textbf{Net Monetary Benefit} \black: $\text{NMB}=k\times \Delta_e - \Delta_c$
    + Use \myred \textbf{reference CE threshold} $k$ \black --> \olive \textbf{CE in practice Manual} \black 
    
. . .

- \olive \textbf{Subgroup analyses} \black (if applicable):
  + All CE results *presented separately* for each subgroup

## Results: base-case analysis - an example

- Summary of CE results in **table** format:

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

#make example of reporting CE results base-case
set.seed(2345)
full.df$QALY[full.df$trt=="new"] <- full.df$QALY[full.df$trt=="new"] + rnorm(n_full,-0.1,0.2)
full.df$TC[full.df$trt=="new"] <- full.df$TC[full.df$trt=="new"] + rnorm(n_full,10,2)
lm_full_data.e <- lm(QALY ~ trt + u, data = full.df)
lm_full_data.c <- lm(TC ~ trt + c, data = full.df)
em_lm_mu_data.e <- emmeans(lm_full_data.e, ~ trt)
em_lm_mu_data.c <- emmeans(lm_full_data.c, ~ trt)
lm_delta_data.e <- summary(lm_full_data.e)$coefficients["trtnew","Estimate"]
lm_se_delta_data.e <- summary(lm_full_data.e)$coefficients["trtnew","Std. Error"]
lm_ci_delta_data.e <- confint(lm_full_data.e)["trtnew",]
lm_delta_data.sum.e <- c(lm_delta_data.e,lm_se_delta_data.e,lm_ci_delta_data.e)
names(lm_delta_data.sum.e) <- c("Estimate","SE","lower.CL","upper.CL")
lm_delta_data.c <- summary(lm_full_data.c)$coefficients["trtnew","Estimate"]
lm_se_delta_data.c <- summary(lm_full_data.c)$coefficients["trtnew","Std. Error"]
lm_ci_delta_data.c <- confint(lm_full_data.c)["trtnew",]
lm_delta_data.sum.c <- c(lm_delta_data.c,lm_se_delta_data.c,lm_ci_delta_data.c)
names(lm_delta_data.sum.c) <- c("Estimate","SE","lower.CL","upper.CL")

tbl_bc_em <- cbind.data.frame(summary(em_lm_mu_data.e)$emmean,summary(em_lm_mu_data.e)$SE,summary(em_lm_mu_data.e)$lower.CL,summary(em_lm_mu_data.e)$upper.CL)
tbl_bc_cm <- cbind.data.frame(summary(em_lm_mu_data.c)$emmean,summary(em_lm_mu_data.c)$SE,summary(em_lm_mu_data.c)$lower.CL,summary(em_lm_mu_data.c)$upper.CL)
tbl_bc_e_delta <- lm_delta_data.sum.e
tbl_bc_c_delta <- lm_delta_data.sum.c
k_ref <- 1000
tbl_bc_nmb <- cbind.data.frame(k_ref*lm_delta_data.sum.e[1] - lm_delta_data.sum.c[1],NA,NA,NA)
tbl_bc_icer <- cbind.data.frame(lm_delta_data.sum.c[1]/lm_delta_data.sum.e[1],NA,NA,NA)
names(tbl_bc_em) <- names(tbl_bc_cm) <- names(tbl_bc_e_delta) <- names(tbl_bc_c_delta) <- names(tbl_bc_nmb) <- names(tbl_bc_icer) <- c("Mean","SE","CI(low)","CI(high)")
tbl_bc <- rbind.data.frame(tbl_bc_em,tbl_bc_cm,tbl_bc_e_delta,tbl_bc_c_delta,tbl_bc_nmb,tbl_bc_icer)
tbl_bc <- round(tbl_bc, digits = 3)
rownames(tbl_bc) <- c("Old(QALY)","New(QALY)","Old(TC)","New(TC)","Incr(QALY)","Incr(TC)","NMB(k=5000)","ICER")

options(knitr.kable.NA = '')

kable(tbl_bc, booktabs = TRUE, row.names = T, digits = 3) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(c(1,3), color = 'red', bold = FALSE, italic = TRUE) %>% 
  row_spec(c(2,4), color = 'blue', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = "black", italic = FALSE) %>%
  column_spec(2, bold = TRUE, italic = FALSE) %>%
  kable_styling(font_size = 8)
```

. . .

- In \olive \textbf{Base-Case} \black analysis, focus on:
  + **Point** \& **CI** estimates for QALY/TC by arm (over the study period)
  + **Point** \& **CI** estimates for incremental QALY/TC (New-Old)
  + **Point** estimate for *ICER* and *NMB* (assuming \myred \textbf{reference value} \black for $k$)


## Results: sensitivity analyses

- \olive \textbf{Deterministic} \black \& \olive \textbf{scenario} \black analyses (*model-based*):

  + Chosen parameter distribution 
  + ICER and incremental quantities lower/upper values
  + Always compared with base-case results

. . .

- \olive \textbf{Probabilistic} \black analyses:
  + Graphically presented using:
    + \myblue \textbf{Cost-Effectiveness Plane} \black (*CE plane*)
    + \myblue \textbf{Cost-Effectiveness Acceptability Curve} \black (*CEAC*)

. . .

- \olive \textbf{Value of Information} \black analyses (*model-based*):
  + \myred \textbf{Expected Value of (Partial) Perfect Information} \black (*EV(P)PI*) plot
  + EVSI and ENBS results may be presented --> \myred \textbf{VoI analyses Manual} \black


```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| cache: true
#| fig-width: 6
#| fig-height: 6 

#obtain PSA results and plot CE plane and CEAC
#bootstrap analysis
library(data.table)
library(bootstrap)
dataset.full.dt <- data.table(full.df)
n <- dim(dataset.full.dt)[1]
B <- 5000
data_ec_b_list <- list()
data_delta_c_b <- data_delta_e_b <- c()
data_mu0_c_b <- data_mu0_e_b <- c()
data_mu1_c_b <- data_mu1_e_b <- c()
for(i in 1:B){
  data_ec_b_list[[i]] <- dataset.full.dt[sample(.N, n, replace = T)]
  data_lm_c_coef_b <- coef(lm(TC ~ trt + c, data = data_ec_b_list[[i]]))
  data_lm_e_coef_b <- coef(lm(QALY ~ trt + u, data = data_ec_b_list[[i]]))
  data_mu0_c_b[i] <- data_lm_c_coef_b["(Intercept)"]+data_lm_c_coef_b["trtnew"]*0+data_lm_c_coef_b["c"]*mean(data_ec_b_list[[i]]$c)
  data_mu1_c_b[i] <- data_lm_c_coef_b["(Intercept)"]+data_lm_c_coef_b["trtnew"]*1+data_lm_c_coef_b["c"]*mean(data_ec_b_list[[i]]$c)
  data_mu0_e_b[i] <- data_lm_e_coef_b["(Intercept)"]+data_lm_e_coef_b["trtnew"]*0+data_lm_e_coef_b["u"]*mean(data_ec_b_list[[i]]$u)
  data_mu1_e_b[i] <- data_lm_e_coef_b["(Intercept)"]+data_lm_e_coef_b["trtnew"]*1+data_lm_e_coef_b["u"]*mean(data_ec_b_list[[i]]$u)  
}
#set data for plots
library(BCEA)
boo.mu.e <- cbind(data_mu0_e_b,data_mu1_e_b) 
boo.mu.c <- cbind(data_mu0_c_b,data_mu1_c_b) 
cea_res <- bcea(eff = boo.mu.e, cost = boo.mu.c, Kmax = 25000, ref = 2)
boot.dataset.cep <- data.frame(cea_res$e[,1],cea_res$e[,2],cea_res$c[,1],cea_res$c[,2],cea_res$delta_e,cea_res$delta_c)
names(boot.dataset.cep) <- c("mu0_e","mu1_e","mu0_c","mu1_c","delta_e","delta_c")
boot.icer <- round(cea_res$ICER,0)
boot.delta_e <- mean(boot.dataset.cep$delta_e)
boot.delta_c <- mean(boot.dataset.cep$delta_c)

#CEP
gg_cep <- ggplot(boot.dataset.cep, aes(x=delta_e, y=delta_c)) +
  geom_point(position=position_dodge(width=0.4), width=.1, size=2, alpha=1, shape=1) +
  ylab("Mean TC Difference") + ylim(0,40) + xlim(-0.2,0.20) +
  xlab("Mean QALY Diffference") +
  geom_vline(xintercept = 0, colour="black", linewidth=0.25) +
  geom_hline(yintercept = 0, colour="black", linewidth=0.25) +
  geom_abline(intercept = 0, slope = k_ref, colour="red", linewidth=0.5) +
  annotate(geom="text", x=0.04, y=1, label=paste("K=",k_ref, sep=""), color="red") + 
  annotate("point", x = boot.delta_e, y = boot.delta_c, colour = "red", size = 1.5, shape=16) +
  annotate(geom="text", x=0.16, y=39, label=paste("ICER=",boot.icer, sep=""), color="red") + 
#  annotate("rect", xmin = 3, xmax = 4.2, ymin = 12, ymax = 21, alpha = .2)
  theme_classic() + 
  theme(legend.position = "none",
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))


#NMB
nmb_avg <- apply(cea_res$ib[,,1],1,mean) 
nmb_lci <- apply(cea_res$ib[,,1],1,quantile, probs=0.025) 
nmb_uci <- apply(cea_res$ib[,,1],1,quantile, probs=0.975) 
k_val <- cea_res$k
boot.dataset.nmb <- data.frame(nmb_avg,nmb_lci,nmb_uci,k_val)
names(boot.dataset.nmb) <- c("NMB","lower.CI","upper.CI","k")

gg_nmb <- ggplot(boot.dataset.nmb, aes(x=k, y=NMB)) +
  geom_line(size=0.5) +
  geom_line(data=boot.dataset.nmb,aes(x=k, y=lower.CI), size=0.5, linetype=2) +
  geom_line(data=boot.dataset.nmb,aes(x=k, y=upper.CI), size=0.5, linetype=2) +
  ylab("Expected Incremental Benefit") + ylim(-100,300) + xlim(0,2000) +
  xlab("Acceptance threshold") +
  geom_hline(yintercept = 0, colour="black", linewidth=0.5) +
  geom_vline(xintercept = k_ref, colour="red", linewidth=0.5) +
  theme_classic() + 
  theme(legend.position = "none",
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))



#CEAC
boot.dataset.ceac <- data.frame(cea_res$ceac,k_val)
names(boot.dataset.ceac) <- c("CEAC","k")

gg_ceac <- ggplot(boot.dataset.ceac, aes(x=k, y=CEAC)) +
  geom_line(size=0.5) +
  ylab("Expected Incremental Benefit") + ylim(0,1) + xlim(0,5000) +
  xlab("Acceptance threshold") +
  geom_vline(xintercept = k_ref, colour="red", linewidth=0.5) +
  theme_classic() + 
  theme(legend.position = "none",
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5))

```

## Results: probabilistic analyses - an example

:::: {layout="[0.45, 0.55]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 3.5
#| fig-height: 4.5 

gg_cep
```

:::

:::{#secondcol}

\scriptsize

- \olive \textbf{CE plane}  \black
  + Scatter plot of **boostrapped** estimates $(\Delta^b_e,\Delta^b_c)$ 
  + Red line slope equal to \myred \textbf{reference value} \black for $K$
  + $\color{red}{\text{ICER}}=\frac{\text{E}[\Delta^b_c]}{\text{E}[\Delta^b_e]}$

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

#compute relevant info for CE plane
delta_e_b_avg <- round(mean(unlist(cea_res$delta_e)),3)
delta_c_b_avg <- round(mean(unlist(cea_res$delta_c)),3)
icer_b_avg <- round(mean(unlist(cea_res$delta_c))/mean(unlist(cea_res$delta_e)),3)
prop_b_NE <- length(cea_res$delta_e[cea_res$delta_e>0 & cea_res$delta_c>0])/B
prop_b_NW <- length(cea_res$delta_e[cea_res$delta_e<0 & cea_res$delta_c>0])/B
prop_b_SE <- length(cea_res$delta_e[cea_res$delta_e>0 & cea_res$delta_c<0])/B
prop_b_SW <- length(cea_res$delta_e[cea_res$delta_e<0 & cea_res$delta_c<0])/B
icer_b <- unlist(cea_res$delta_c)/unlist(cea_res$delta_e)
prop_b_ce_k <- round(length(icer_b[icer_b<k_ref])/B,3)
prop_b <- c(NA,prop_b_NE,prop_b_NW,prop_b_SE,prop_b_SW,prop_b_ce_k)
tbl_cep <- rbind(prop_b,c(delta_e_b_avg,NA,NA,NA,NA,NA),c(delta_c_b_avg,NA,NA,NA,NA,NA),c(icer_b_avg,NA,NA,NA,NA,NA))
colnames(tbl_cep) <- c("Mean","NE","NW","SE","SW",paste("K=",k_ref, sep=""))
rownames(tbl_cep) <- c("%","QALY","TC","ICER")

options(knitr.kable.NA = '')

kable(tbl_cep, booktabs = TRUE, digits = 3, row.names = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, bold = FALSE, color = "black",italic = TRUE) %>%
  column_spec(1, bold = TRUE, color = "black",italic = FALSE) %>%
  column_spec(7, bold = TRUE, color = "red") %>%
  kable_styling(font_size = 6, latex_options="scale_down") 
```

:::

::::


## Results: probabilistic analyses - an example

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4
#| fig-height: 4 

gg_nmb
```

:::

:::{#secondcol}

\scriptsize

- \olive \textbf{NMB}  \black
  + Plot of **bootstrapped** $\text{NMB}^b$ estimates for $K\in [0,K_{\text{max}}]$
  + Red line equal to \myred \textbf{reference value} \black for $K$
  + Dashed lines are $95\%$ interval based on **bootstrapped** estimates
  + $\text{NMB}^b=K\times \Delta^b_e-\Delta_c^b$

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

#compute relevant info for EIB 
nmb_avg_k <- round(mean(cea_res$ib[cea_res$k==1000,,1]),3)
nmb_avg_lower <- round(quantile(cea_res$ib[cea_res$k==1000,,1],probs = 0.025),3)
nmb_avg_upper <- round(quantile(cea_res$ib[cea_res$k==1000,,1],probs = 0.975),3)
nmb_icer <- unlist(cea_res$delta_e)*icer_b_avg-unlist(cea_res$delta_c)
nmb0_avg_k <- round(mean(nmb_icer),3)
nmb0_avg_lower <- round(quantile(nmb_icer,probs = 0.025),3)
nmb0_avg_upper <- round(quantile(nmb_icer,probs = 0.975),3)
tbl_nmb <- cbind.data.frame(c(nmb_avg_k,nmb0_avg_k),c(nmb_avg_lower,nmb0_avg_lower),c(nmb_avg_upper,nmb0_avg_upper))
colnames(tbl_nmb) <- c("Mean","CI(low)","CI(high)")
row.names(tbl_nmb) <- c(paste("K=",k_ref, sep=""),paste("K=",icer_b_avg, sep=""))

kable(tbl_nmb, booktabs = TRUE, digits = 3, row.names = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'red', bold = FALSE, italic = TRUE) %>% 
  row_spec(2, color = 'black', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = "black",italic = FALSE) %>%
  kable_styling(font_size = 6) 
```

:::

::::


## Results: probabilistic analyses - an example

:::: {layout="[0.55, 0.45]"}

:::{#firstcol}

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4
#| fig-height: 4 

gg_ceac
```

:::

:::{#secondcol}

\scriptsize

- \olive \textbf{CEAC}  \black
  + Plot of $\%$ of **boostrapped** estimates $\frac{\Delta^b_c}{\Delta^b_e}$ below $K$ for $K\in [0,K_{\text{max}}]$
  + Often interpreted as \myred \textbf{"probability"} \black that New is CE compared to Old
  + Red line equal to \myred \textbf{reference value} \black for $K$

\tiny
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| output: asis

#compute relevant info for CEAC
prob_ce_k_low <- cea_res$ceac[cea_res$k==k_ref/2]
prob_ce_k_ref <- cea_res$ceac[cea_res$k==k_ref]
prob_ce_k_high <- cea_res$ceac[cea_res$k==k_ref*2]
tbl_ceac <- cbind.data.frame(prob_ce_k_low,prob_ce_k_ref,prob_ce_k_high)
colnames(tbl_ceac) <- c(paste("K=",k_ref/2, sep=""),paste("K=",k_ref, sep=""),paste("K=",k_ref*2, sep=""))
row.names(tbl_ceac) <- c("% CE")

kable(tbl_ceac, booktabs = TRUE, digits = 3, row.names = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(1, color = 'black', bold = FALSE, italic = TRUE) %>% 
  column_spec(1, bold = TRUE, color = "black", italic = FALSE) %>%
  column_spec(3, bold = TRUE, color = "red") %>%
  kable_styling(font_size = 6) 
```

:::

::::


# Conclusions

## Summary

- Trial-based analysis considered the \myblue \textbf{gold standard} \black for evaluating effectiveness and cost-effectiveness of new interventions

  + Randomisation \& ITT analysis minimises chance of **bias** 
  + Provide *prospective* patient-level cost and effect data

. . .

- Use of \myred \textbf{invalid} \black stat methods may still lead to bias

  + **Distort** CE conclusions with "waste" of resources
  + *Statistical quality* of analyses is generally poor (Gabrio et al., 2017; Ling et al. 2022)

. . .

- Methods for health effects often \myred \textbf{not appropriate} \black for CEA:

  + Many *complexities* present simultaneously in CEA:
    + Baseline imbalance, Correlation, Skewness, Clustering, Missing data
  + Require a **combination** of different statistical methods use

. . .

- Important to identify \myred \textbf{barriers} \black and \myblue \textbf{facilitators} \black of methods

## R you still using Excel/SPSS?

![](figure\meloni1.jpg){width=80% fig-align="center"}


## R you still using Excel? (Incerti et. al 2019)

- Historically, HTAs conducted with \myred \textbf{commercial software} \black (eg SPSS) or \myred \textbf{spreadsheet software} \black (eg Excel) which:

  + Are sufficient for simple analyses **BUT**
  + Put \myred \textbf{constraints} \black that limit credibility and relevance

. . .

- \myblue \textbf{Modern programming languages} \black (eg R) facilitate the development of models that are:

  + Increasingly sophisticated and realistic
  + Capable of quantifying decision **uncertainty**
  + Tansparent and reproducible
  + Reusable and adaptable

. . .

- \olive \textbf{R} \black user/developer communities well suited to: 

  + Develop/implement HTA models in a **single software environment**
  + Catch up with **methodological advances** 
  + Spot and correct code errors via **open-source** nature of packages

 
## A path forward for HTA
 
- Still a general lack of \myred \textbf{software experience} \black in the HTA community:

  + *Insufficient* training in script-based prog software
  + *Limited* guidance on how to implement standard models

. . .

- Critical to \myblue \textbf{train} \black the next generation of health economists in *state of the art* methods and *software* to implement them

. . .

- **How to do this**?

  + Developing university *courses* \& *workshops*
  + Writing *tutorial papers*
  + Making code *freely available* on repositories (eg *GitHub*)
  + *Encouraging* the use of programming languages among researchers

## Key references

\scriptsize 

::: {#refs}

:::

# Appendix - R code 

## Appendix - R code - Baseline adjustment

- Full code available [\blue \@\textbf{AnGabrio GitHub} \black](https://github.com/AnGabrio/Code/tree/master/RHTAmethods) 

```{r}
#| echo: true 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#fit QALY OLS model adjusting for baseline utilities
lm2 <- lm(QALY ~ trt + u, data = dataset)
#get mean QALY in each trt group 
lm2em <- emmeans(lm2, ~ trt)
#get mean difference between groups
contrast2_1vs0 <- list("New vs Old" = c(-1, 1))
#summarise estimates
confint(contrast(lm2em, contrast2_1vs0))
```

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#fit OLS/SUR model and get bootrap estimates
source("code_functions.R")
```

## Appendix - R code - Dealing with correlation

- Full code available [\blue \@\textbf{AnGabrio GitHub} \black](https://github.com/AnGabrio/Code/tree/master/RHTAmethods) 

```{r}
#| echo: true 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#fit SUR model to QALY and TC
sur <- systemfit(list(QALYreg = QALY ~ trt + u, 
    TCreg = TC ~ trt + c), method="SUR", data=dataset)
#get mean QALY difference CI
sur_e.trt.ci <- confint(sur, level=0.95)[2,]
#summarise mean QALY difference between groups 
sur_e.trt.sum <- c(coef(summary(sur))[2, 
    c("Estimate", "Std. Error")],sur_e.trt.ci)
sur_e.trt.sum
```

## Appendix - R code - Dealing with correlation

- Full code available [\blue \@\textbf{AnGabrio GitHub} \black](https://github.com/AnGabrio/Code/tree/master/RHTAmethods) 

```{r}
#| echo: true 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#fit OLS/SUR model and get bootrap estimates
boot_res <- boot_ec(dataset, QALYreg = QALY ~ trt + u,
    TCreg = TC ~ trt + c, method = "OLS", B=200)
summary(boot_res$QALY_boot$Delta_e)
#compute percentile or BCa CIs
boot_ci_bca <- boot_ci(x = boot_res, method = "BCa")
boot_ci_bca$Delta_e
```

## Appendix - R code - Dealing with skewness

- Full code available [\blue \@\textbf{AnGabrio GitHub} \black](https://github.com/AnGabrio/Code/tree/master/RHTAmethods) 

```{r}
#| echo: true 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#fit GLM  model for TC
glm_c <- glm(TC ~ trt + c, data = dataset_sam_skew.df, 
  family = Gamma(link = "identity"))
#get mean TC in each trt group 
glm_c.em <- emmeans(glm_c, ~ trt)
#get mean difference between groups
contrast1_1vs0 <- list("New vs Old" = c(-1, 1))
#summarise estimates
confint(contrast(glm_c.em, contrast1_1vs0))
```

## Appendix - R code - Dealing with clustering

- Full code available [\blue \@\textbf{AnGabrio GitHub} \black](https://github.com/AnGabrio/Code/tree/master/RHTAmethods) 

```{r}
#| echo: true 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#fit MLM  model for QALY
mlm_e <- lme(QALY ~ trt, random = ~1|cluster, 
    data = data.clus.df)
#get mean QALY in each trt group 
mlm1em_e <- emmeans(mlm_e, ~ trt)
#get mean difference between groups
contrast1_1vs0 <- list("New vs Old" = c(-1, 1))
confint(contrast(mlm1em_e, contrast1_1vs0))
```

## Appendix - R code - Dealing with clustering

- Full code available [\blue \@\textbf{AnGabrio GitHub} \black](https://github.com/AnGabrio/Code/tree/master/RHTAmethods) 

```{r}
#| echo: true 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#fit OLS/SUR model and get TSB estimates
tsboot_res <- tsboot_ec(data = data.clus.df, 
  QALYreg = QALY ~ trt, TCreg = TC ~ trt, 
  cluster = "cluster", B=200)
summary(tsboot_res$QALY_boot$Delta_e)
#compute percentile or BCa CIs
tsboot_ci_bca <- boot_ci(x = tsboot_res, method = "BCa")
tsboot_ci_bca$Delta_e
```

## Appendix - R code - Dealing with missing data 

- Full code available [\blue \@\textbf{AnGabrio GitHub} \black](https://github.com/AnGabrio/Code/tree/master/RHTAmethods) 

```{r}
#| echo: true 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#impute data using MICE with pmm
mice_data <- mice(full.mar.MI, predictorMatrix = pM, 
  method='pmm', m = 20, print = FALSE)
#analyse imputed data with OLS for QALY
lme_mice_data <- with(mice_data, lm(QALY_obs ~ trt + u))
#get pooled mean QALY per group
em_lme_mu_data.mi <- emmeans(lme_mice_data, ~ trt)
#get pooled mean difference between groups
contrast1_1vs0 <- list("New vs Old" = c(-1, 1))
confint(contrast(em_lme_mu_data.mi, contrast1_1vs0))
```

## Appendix - R code - probabilistic analysis

\tiny
```{r}
#| echo: true 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#get CEA output from bootstrapped estimates
library(BCEA)
cea_res <- bcea(eff = boo.mu.e, cost = boo.mu.c, 
    Kmax = 25000, ref = 2)
summary(cea_res)
```

## Appendix - R code - probabilistic analysis

\tiny
```{r}
#| echo: true 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 3 

ceplane.plot(cea_res, graph = "ggplot2", wtp = 5000) + labs(title="")
```

## Appendix - R code - probabilistic analysis

\tiny
```{r}
#| echo: true 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 3 

eib.plot(cea_res, graph = "ggplot2", plot.cri = TRUE) + labs(title="")
```

## Appendix - R code - probabilistic analysis

\tiny
```{r}
#| echo: true 
#| eval: true
#| message: false
#| warning: false
#| error: false 
#| fig-width: 4.5
#| fig-height: 3 

ceac.plot(cea_res, graph = "ggplot2") + labs(title="")
```

